Implementation smell,Namespace,Class,File,Method,Description
Long Method,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The method has 111 lines of code.
Long Method,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The method has 290 lines of code.
Long Parameter List,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteAttachmentMetadata,The method has 5 parameters. Parameters: writer' hash' size' name' contentType
Long Parameter List,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Write,The method has 8 parameters. Parameters: mem' sizeInBytes' documentsWriter' revisionsWriter' conflictsWritet' context' startOffest' tableType
Long Parameter List,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteDocument,The method has 5 parameters. Parameters: mem' sizeInBytes' writer' context' startOffest
Long Parameter List,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteRevision,The method has 5 parameters. Parameters: mem' sizeInBytes' writer' context' startOffest
Long Parameter List,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteConflict,The method has 5 parameters. Parameters: mem' sizeInBytes' writer' context' startOffest
Long Identifier,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the parameter initialContextLongLivedSizeInKbArg is 34.
Long Statement,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the statement  "                var outputFileNameArg = cmd.Option("--OutputFileName"' "Will overwrite the default file name () with your own file name (under output directory)."' CommandOptionType.SingleValue); " is 179.
Long Statement,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the statement  "                var pageSizeInKbArg = cmd.Option("--PageSizeInKB"' "Will set the recovery tool to work with page sizes other than 4kb."' CommandOptionType.SingleValue); " is 152.
Long Statement,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the statement  "                var initialContextSizeInMbArg = cmd.Option("--InitialContextSizeInMB"' "Will set the recovery tool to use a context of the provided size in MB."' CommandOptionType.SingleValue); " is 177.
Long Statement,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the statement  "                var initialContextLongLivedSizeInKbArg = cmd.Option("--InitialContextLongLivedSizeInKB"' "Will set the recovery tool to use a long lived context size of the provided size in KB."' CommandOptionType.SingleValue); " is 211.
Long Statement,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the statement  "                var progressIntervalInSecArg = cmd.Option("--ProgressIntervalInSec"' "Will set the recovery tool refresh to console rate interval in seconds."' CommandOptionType.SingleValue); " is 175.
Long Statement,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the statement  "                var disableCopyOnWriteModeArg = cmd.Option("--DisableCopyOnWriteMode"' "Default is false."' CommandOptionType.SingleValue); " is 123.
Long Statement,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the statement  "                var loggingModeArg = cmd.Option("--LoggingMode"' "Logging mode: Operations or Information."' CommandOptionType.SingleValue); " is 124.
Long Statement,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the statement  "                    config.OutputFileName = Path.Combine(recoverDirectory' outputFileNameArg.HasValue() ? outputFileNameArg.Value() : RecoveryFileName); " is 132.
Long Statement,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The length of the statement  "                            return ExitWithError($"{nameof(config.InitialContextLongLivedSizeInKB)} argumnet value ({longLivedContextSize}) is invalid"' cmd); " is 130.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "            using (var destinationStreamDocuments = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-2-Documents" + Path.GetExtension(_output)))) " is 190.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "            using (var destinationStreamRevisions = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-3-Revisions" + Path.GetExtension(_output)))) " is 190.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "            using (var destinationStreamConflicts = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-4-Conflicts" + Path.GetExtension(_output)))) " is 190.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "            using (var context = new JsonOperationContext(_initialContextSize' _initialContextLongLivedSize' SharedMultipleUseFlag.None)) " is 125.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "                                $"{now:hh:MM:ss}: Recovering page at position {currPos:#'#;;0}/{eofPos:#'#;;0} ({(double)currPos / eofPos:p}) - Last recovered doc is {_lastRecoveredDocumentKey}"); " is 164.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "                                $"page #{pageHeader->PageNumber} (offset={GetFilePosition(startOffset' mem)}) has both Overflow and Single flag turned"; " is 120.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "                                            _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to initialize Sodium for hash computation will skip this page."); " is 152.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "                                                _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute chunk hash' will skip it."); " is 126.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "                                                _logger.Operations($"page #{nextPage->PageNumber} (offset={(long)nextPage}) was suppose to be a stream chunck but isn't marked as Overflow | Stream"); " is 150.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "                                            _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute attachment hash' will skip it."); " is 131.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "                                $"RawDataSmallPage #{rawHeader->PageNumber} at {GetFilePosition(startOffset' mem)} next allocation is larger than {_pageSize} bytes"; " is 133.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "                    WriteDummyDocumentForAttachment(documentsWriter' _lastAttachmentInfo.hash' _lastAttachmentInfo.size' _lastAttachmentInfo.tag); " is 126.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The length of the statement  "                    _logger.Operations($"Discovered a total of {_numberOfDocumentsRetrieved:#'#;00} documents within {sw.Elapsed.TotalSeconds::#'#.#;;00} seconds." + Environment.NewLine + " is 167.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,ReportOrphanAttachmentsAndMissingAttachments,The length of the statement  "                            _logger.Operations($"Document {_documentsAttachments[index].docId} contians atachment with hash {documentHash} but we were not able to recover such attachment."); " is 162.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,ValidateOverflowPage,The length of the statement  "            var endOfOverflow = (byte*)pageHeader + VirtualPagerLegacyExtensions.GetNumberOfOverflowPages(pageHeader->OverflowSize) * _pageSize; " is 132.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,ValidateOverflowPage,The length of the statement  "            checksum = StorageEnvironment.CalculatePageChecksum((byte*)pageHeader' pageHeader->PageNumber' pageHeader->Flags' pageHeader->OverflowSize); " is 140.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,ValidateOverflowPage,The length of the statement  "                    $"Invalid checksum for overflow page {pageHeader->PageNumber}' expected hash to be {pageHeader->Checksum} but was {checksum}"; " is 126.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteDocument,The length of the statement  "                        _logger.Operations($"Found invalid blittable document at pos={GetFilePosition(startOffest' mem)} with key={document?.Id ?? "null"}{Environment.NewLine}{e}"); " is 157.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteDocument,The length of the statement  "                    _logger.Operations($"Unexpected exception while writing document at position {GetFilePosition(startOffest' mem)}: {e}"); " is 120.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,HandleDocumentAttachments,The length of the statement  "                        _logger.Operations($"Document {document.Id} has attachment flag set but was unable to read its metadata and retrieve the attachments hashes"); " is 142.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteRevision,The length of the statement  "                    revision = RevisionsStorage.ParseRawDataSectionRevisionWithValidation(context' ref tvr' sizeInBytes' out var changeVector); " is 123.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteRevision,The length of the statement  "                            _logger.Operations($"Failed to convert table value to revision document at position {GetFilePosition(startOffest' mem)}"); " is 122.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteRevision,The length of the statement  "                        _logger.Operations($"Found invalid blittable revision document at pos={GetFilePosition(startOffest' mem)} with key={revision?.Id ?? "null"}{Environment.NewLine}{e}"); " is 166.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteRevision,The length of the statement  "                    _logger.Operations($"Unexpected exception while writing revision document at position {GetFilePosition(startOffest' mem)}: {e}"); " is 129.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteConflict,The length of the statement  "                    conflict = ConflictsStorage.ParseRawDataSectionConflictWithValidation(context' ref tvr' sizeInBytes' out var changeVector); " is 123.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteConflict,The length of the statement  "                            _logger.Operations($"Failed to convert table value to conflict document at position {GetFilePosition(startOffest' mem)}"); " is 122.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteConflict,The length of the statement  "                        _logger.Operations($"Found invalid blittable conflict document at pos={GetFilePosition(startOffest' mem)} with key={conflict?.Id ?? "null"}{Environment.NewLine}{e}"); " is 166.
Long Statement,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteConflict,The length of the statement  "                    _logger.Operations($"Unexpected exception while writing conflict document at position {GetFilePosition(startOffest' mem)}: {e}"); " is 129.
Magic Number,Voron.Recovery,CommandLineApp,C:\repos\ravendb_ravendb\tools\Voron.Recovery\CommandLineApp.cs,ConfigureRecoveryCommand,The following statement contains a magic number: _app.Command("recover"' cmd =>              {                  cmd.ExtendedHelpText = cmd.Description = "Recovering a database into recovery.ravendump.";                  cmd.HelpOption(HelpOptionString);                    var dataFileDirectoryArg = cmd.Argument("DataFileDirectory"' "The database directory which contains the data file");                  var recoverDirectoryArg = cmd.Argument("RecoverDirectory"' "The directory to recover the recovery.ravendump file");                    var outputFileNameArg = cmd.Option("--OutputFileName"' "Will overwrite the default file name () with your own file name (under output directory)."' CommandOptionType.SingleValue);                  var pageSizeInKbArg = cmd.Option("--PageSizeInKB"' "Will set the recovery tool to work with page sizes other than 4kb."' CommandOptionType.SingleValue);                  var initialContextSizeInMbArg = cmd.Option("--InitialContextSizeInMB"' "Will set the recovery tool to use a context of the provided size in MB."' CommandOptionType.SingleValue);                  var initialContextLongLivedSizeInKbArg = cmd.Option("--InitialContextLongLivedSizeInKB"' "Will set the recovery tool to use a long lived context size of the provided size in KB."' CommandOptionType.SingleValue);                  var progressIntervalInSecArg = cmd.Option("--ProgressIntervalInSec"' "Will set the recovery tool refresh to console rate interval in seconds."' CommandOptionType.SingleValue);                  var disableCopyOnWriteModeArg = cmd.Option("--DisableCopyOnWriteMode"' "Default is false."' CommandOptionType.SingleValue);                  var loggingModeArg = cmd.Option("--LoggingMode"' "Logging mode: Operations or Information."' CommandOptionType.SingleValue);                    cmd.OnExecute(() =>                  {                      VoronRecoveryConfiguration config = new VoronRecoveryConfiguration                      {                          DataFileDirectory = dataFileDirectoryArg.Value'                      };                        if (string.IsNullOrWhiteSpace(config.DataFileDirectory) ||                          Directory.Exists(config.DataFileDirectory) == false ||                          File.Exists(Path.Combine(config.DataFileDirectory' DatafileName)))                      {                          return ExitWithError($"Missing {nameof(config.DataFileDirectory)} argument"' cmd);                      }                      config.PathToDataFile = Path.Combine(config.DataFileDirectory' DatafileName);                        var recoverDirectory = recoverDirectoryArg.Value;                      if (string.IsNullOrWhiteSpace(recoverDirectory))                      {                          return ExitWithError("Missing RecoverDirectory argument"' cmd);                      }                                            config.OutputFileName = Path.Combine(recoverDirectory' outputFileNameArg.HasValue() ? outputFileNameArg.Value() : RecoveryFileName);                      try                      {                          if (!Directory.Exists(recoverDirectory))                              Directory.CreateDirectory(recoverDirectory);                          File.WriteAllText(config.OutputFileName' "I have write permission!");                          File.Delete(config.OutputFileName);                      }                      catch                      {                          return ExitWithError($"Cannot write to the output directory ({recoverDirectory}). " +                                               "Permissions issue?"' cmd);                      }                        if (pageSizeInKbArg.HasValue())                      {                          if (int.TryParse(pageSizeInKbArg.Value()' out var pageSize) == false ||                              pageSize < 1)                              return ExitWithError($"{nameof(config.PageSizeInKB)} argument value ({pageSize}) is invalid"' cmd);                          config.PageSizeInKB = pageSize;                      }                        if (initialContextSizeInMbArg.HasValue())                      {                          if (int.TryParse(initialContextSizeInMbArg.Value()' out var contextSize) == false ||                              contextSize < 1)                              return ExitWithError($"{nameof(config.InitialContextSizeInMB)} argumnet value ({contextSize}) is invalid"' cmd);                          config.InitialContextSizeInMB = contextSize;                      }                        if (initialContextLongLivedSizeInKbArg.HasValue())                      {                          if (int.TryParse(initialContextLongLivedSizeInKbArg.Value()' out var longLivedContextSize) == false ||                              longLivedContextSize < 1)                              return ExitWithError($"{nameof(config.InitialContextLongLivedSizeInKB)} argumnet value ({longLivedContextSize}) is invalid"' cmd);                          config.InitialContextLongLivedSizeInKB = longLivedContextSize;                      }                        if (progressIntervalInSecArg.HasValue())                      {                          if (int.TryParse(progressIntervalInSecArg.Value()' out var refreshRate) == false ||                              refreshRate < 1)                              return ExitWithError($"{nameof(config.ProgressIntervalInSec)} argumnet value ({refreshRate}) is invalid"' cmd);                          config.ProgressIntervalInSec = refreshRate;                      }                        if (disableCopyOnWriteModeArg.HasValue())                      {                          var value = disableCopyOnWriteModeArg.Value();                          if (bool.TryParse(value' out var disableCopyOnWriteMode) == false)                              return ExitWithError($"{nameof(config.DisableCopyOnWriteMode)} argumnet value ({value}) is invalid"' cmd);                          config.DisableCopyOnWriteMode = disableCopyOnWriteMode;                      }                        if (loggingModeArg.HasValue())                      {                          var value = loggingModeArg.Value();                          if (Enum.TryParse(value' out LogMode mode) == false)                              return ExitWithError($"{nameof(config.LoggingMode)} argumnet value ({value}) is invalid"' cmd);                          config.LoggingMode = mode;                      }                        var recovery = new Recovery(config);                      var cts = new CancellationTokenSource();                      Console.WriteLine("Press 'q' to quit the recovery process");                      var cancellationTask = Task.Factory.StartNew(() =>                      {                                          while (Console.Read() != 'q')                          {                          }                          cts.Cancel();                          //The reason i do an exit here is because if we are in the middle of journal recovery                           //we can't cancel it and it may take a long time.                          //That said i'm still going to give it a while to do a proper exit                          Task.Delay(5000).ContinueWith(_ =>                          {                              Environment.Exit(1);                          });                      }' cts.Token);                      recovery.Execute(cts.Token);                      cts.Cancel();                        return 0;                  });              });
Magic Number,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The following statement contains a magic number: using (var destinationStreamDocuments = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-2-Documents" + Path.GetExtension(_output))))              using (var destinationStreamRevisions = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-3-Revisions" + Path.GetExtension(_output))))              using (var destinationStreamConflicts = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-4-Conflicts" + Path.GetExtension(_output))))              using (var gZipStreamDocuments = new GZipStream(destinationStreamDocuments' CompressionMode.Compress' true))              using (var gZipStreamRevisions = new GZipStream(destinationStreamRevisions' CompressionMode.Compress' true))              using (var gZipStreamConflicts = new GZipStream(destinationStreamConflicts' CompressionMode.Compress' true))              using (var context = new JsonOperationContext(_initialContextSize' _initialContextLongLivedSize' SharedMultipleUseFlag.None))              using (var documentsWriter = new BlittableJsonTextWriter(context' gZipStreamDocuments))              using (var revisionsWriter = new BlittableJsonTextWriter(context' gZipStreamRevisions))              using (var conflictsWriter = new BlittableJsonTextWriter(context' gZipStreamConflicts))              {                  WriteSmugglerHeader(documentsWriter' 40018' "Docs");                  WriteSmugglerHeader(revisionsWriter' 40018' "RevisionDocuments");                  WriteSmugglerHeader(conflictsWriter' 40018' "ConflictDocuments");                    while (mem < eof)                  {                      try                      {                          if (ct.IsCancellationRequested)                          {                              if (_logger.IsOperationsEnabled)                                  _logger.Operations($"Cancellation requested while recovery was in position {GetFilePosition(startOffset' mem)}");                              _cancellationRequested = true;                              break;                          }                          var now = DateTime.UtcNow;                          if ((now - lastProgressReport).TotalSeconds >= _progressIntervalInSec)                          {                              if (lastProgressReport != DateTime.MinValue)                              {                                  Console.Clear();                                  Console.WriteLine("Press 'q' to quit the recovery process");                              }                              lastProgressReport = now;                              var currPos = GetFilePosition(startOffset' mem);                              var eofPos = GetFilePosition(startOffset' eof);                              Console.WriteLine(                                  $"{now:hh:MM:ss}: Recovering page at position {currPos:#'#;;0}/{eofPos:#'#;;0} ({(double)currPos / eofPos:p}) - Last recovered doc is {_lastRecoveredDocumentKey}");                          }                            var pageHeader = (PageHeader*)mem;                            //this page is not raw data section move on                          if ((pageHeader->Flags).HasFlag(PageFlags.RawData) == false && pageHeader->Flags.HasFlag(PageFlags.Stream) == false)                          {                              mem += _pageSize;                              continue;                          }                            if (pageHeader->Flags.HasFlag(PageFlags.Single) &&                              pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              var message =                                  $"page #{pageHeader->PageNumber} (offset={GetFilePosition(startOffset' mem)}) has both Overflow and Single flag turned";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                          //overflow page                          ulong checksum;                          if (pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              if (ValidateOverflowPage(pageHeader' eof' startOffset' ref mem) == false)                                  continue;                                var numberOfPages = VirtualPagerLegacyExtensions.GetNumberOfOverflowPages(pageHeader->OverflowSize);                                if (pageHeader->Flags.HasFlag(PageFlags.Stream))                              {                                  var streamPageHeader = (StreamPageHeader*)pageHeader;                                  if (streamPageHeader->StreamPageFlags.HasFlag(StreamPageFlags.First) == false)                                  {                                      mem += numberOfPages * _pageSize;                                      continue;                                  }                                    int rc;                                  fixed (byte* hashStatePtr = _streamHashState)                                  fixed (byte* hashResultPtr = _streamHashResult)                                  {                                      long totalSize = 0;                                      _attachmentChunks.Clear();                                      rc = Sodium.crypto_generichash_init(hashStatePtr' null' UIntPtr.Zero' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to initialize Sodium for hash computation will skip this page.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      // write document header' including size                                      PageHeader* nextPage = pageHeader;                                      byte* nextPagePtr = (byte*)nextPage;                                      bool valid = true;                                      string tag = null;                                      while (true) // has next                                      {                                          streamPageHeader = (StreamPageHeader*)nextPage;                                          //this is the last page and it contains only stream info + maybe the stream tag                                          if (streamPageHeader->ChunkSize == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          totalSize += streamPageHeader->ChunkSize;                                                                                  var dataStart = (byte*)nextPage + PageHeader.SizeOf;                                          _attachmentChunks.Add(((IntPtr)dataStart' (int)streamPageHeader->ChunkSize));                                          rc = Sodium.crypto_generichash_update(hashStatePtr' dataStart' (ulong)streamPageHeader->ChunkSize);                                          if (rc != 0)                                          {                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute chunk hash' will skip it.");                                              valid = false;                                              break;                                          }                                          if (streamPageHeader->StreamNextPageNumber == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          nextPage = (PageHeader*)(streamPageHeader->StreamNextPageNumber * _pageSize + startOffset);                                          //This is the case that the next page isn't a stream page                                          if (nextPage->Flags.HasFlag(PageFlags.Stream) == false || nextPage->Flags.HasFlag(PageFlags.Overflow) == false)                                          {                                              valid = false;                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{nextPage->PageNumber} (offset={(long)nextPage}) was suppose to be a stream chunck but isn't marked as Overflow | Stream");                                              break;                                          }                                          valid = ValidateOverflowPage(nextPage' eof' (long)nextPage' ref nextPagePtr);                                          if (valid == false)                                          {                                              break;                                          }                                                                                }                                      if (valid == false)                                      {                                          //The first page was valid so we can skip the entire overflow                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                        rc = Sodium.crypto_generichash_final(hashStatePtr' hashResultPtr' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute attachment hash' will skip it.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      var hash = new string(' '' 44);                                      fixed (char* p = hash)                                      {                                          var len = Base64.ConvertToBase64Array(p' hashResultPtr' 0' 32);                                          Debug.Assert(len == 44);                                      }                                        WriteAttachment(documentsWriter' totalSize' hash' tag);                                  }                                  mem += numberOfPages * _pageSize;                              }                                else if (Write((byte*)pageHeader + PageHeader.SizeOf' pageHeader->OverflowSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataOverflowPageHeader*)mem)->TableType))                              {                                    mem += numberOfPages * _pageSize;                              }                              else //write document failed                               {                                  mem += _pageSize;                              }                              continue;                          }                            checksum = StorageEnvironment.CalculatePageChecksum((byte*)pageHeader' pageHeader->PageNumber' pageHeader->Flags' 0);                            if (checksum != pageHeader->Checksum)                          {                              var message =                                  $"Invalid checksum for page {pageHeader->PageNumber}' expected hash to be {pageHeader->Checksum} but was {checksum}";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            // small raw data section                           var rawHeader = (RawDataSmallPageHeader*)mem;                            // small raw data section header                          if (rawHeader->RawDataFlags.HasFlag(RawDataPageFlags.Header))                          {                              mem += _pageSize;                              continue;                          }                          if (rawHeader->NextAllocation > _pageSize)                          {                              var message =                                  $"RawDataSmallPage #{rawHeader->PageNumber} at {GetFilePosition(startOffset' mem)} next allocation is larger than {_pageSize} bytes";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            for (var pos = PageHeader.SizeOf; pos < rawHeader->NextAllocation;)                          {                              var currMem = mem + pos;                              var entry = (RawDataSection.RawDataEntrySizes*)currMem;                              //this indicates that the current entry is invalid because it is outside the size of a page                              if (pos > _pageSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              //Allocated size of entry exceed the bound of the page next allocation                              if (entry->AllocatedSize + pos + sizeof(RawDataSection.RawDataEntrySizes) >                                  rawHeader->NextAllocation)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the allocated entry exceed the bound of the page next allocation.";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              if (entry->UsedSize > entry->AllocatedSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the size of the entry exceed the allocated size";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              pos += entry->AllocatedSize + sizeof(RawDataSection.RawDataEntrySizes);                              if (entry->AllocatedSize == 0 || entry->UsedSize == -1)                                  continue;                                if (Write(currMem + sizeof(RawDataSection.RawDataEntrySizes)' entry->UsedSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataSmallPageHeader*)mem)->TableType) == false)                                  break;                          }                          mem += _pageSize;                      }                      catch (Exception e)                      {                          var message =                              $"Unexpected exception at position {GetFilePosition(startOffset' mem)}:{Environment.NewLine} {e}";                          mem = PrintErrorAndAdvanceMem(message' mem);                      }                  }                    ReportOrphanAttachmentsAndMissingAttachments(ct' documentsWriter);                    //This will only be the case when we don't have orphan attachments and we wrote the last attachment after we wrote the                   //last document                  if (_lastWriteIsDocument == false)                  {                      WriteDummyDocumentForAttachment(documentsWriter' _lastAttachmentInfo.hash' _lastAttachmentInfo.size' _lastAttachmentInfo.tag);                  }                    documentsWriter.WriteEndArray();                  conflictsWriter.WriteEndArray();                  revisionsWriter.WriteEndArray();                                  documentsWriter.WriteEndObject();                  conflictsWriter.WriteEndObject();                  revisionsWriter.WriteEndObject();                      if (_logger.IsOperationsEnabled)                  {                      _logger.Operations($"Discovered a total of {_numberOfDocumentsRetrieved:#'#;00} documents within {sw.Elapsed.TotalSeconds::#'#.#;;00} seconds." + Environment.NewLine +                                         $"Discovered a total of {_attachmentsHashs.Count:#'#;00} attachments. " + Environment.NewLine +                                          $"Discovered a total of {_numberOfFaultedPages::#'#;00} faulted pages.");                  }              }
Magic Number,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The following statement contains a magic number: using (var destinationStreamDocuments = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-2-Documents" + Path.GetExtension(_output))))              using (var destinationStreamRevisions = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-3-Revisions" + Path.GetExtension(_output))))              using (var destinationStreamConflicts = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-4-Conflicts" + Path.GetExtension(_output))))              using (var gZipStreamDocuments = new GZipStream(destinationStreamDocuments' CompressionMode.Compress' true))              using (var gZipStreamRevisions = new GZipStream(destinationStreamRevisions' CompressionMode.Compress' true))              using (var gZipStreamConflicts = new GZipStream(destinationStreamConflicts' CompressionMode.Compress' true))              using (var context = new JsonOperationContext(_initialContextSize' _initialContextLongLivedSize' SharedMultipleUseFlag.None))              using (var documentsWriter = new BlittableJsonTextWriter(context' gZipStreamDocuments))              using (var revisionsWriter = new BlittableJsonTextWriter(context' gZipStreamRevisions))              using (var conflictsWriter = new BlittableJsonTextWriter(context' gZipStreamConflicts))              {                  WriteSmugglerHeader(documentsWriter' 40018' "Docs");                  WriteSmugglerHeader(revisionsWriter' 40018' "RevisionDocuments");                  WriteSmugglerHeader(conflictsWriter' 40018' "ConflictDocuments");                    while (mem < eof)                  {                      try                      {                          if (ct.IsCancellationRequested)                          {                              if (_logger.IsOperationsEnabled)                                  _logger.Operations($"Cancellation requested while recovery was in position {GetFilePosition(startOffset' mem)}");                              _cancellationRequested = true;                              break;                          }                          var now = DateTime.UtcNow;                          if ((now - lastProgressReport).TotalSeconds >= _progressIntervalInSec)                          {                              if (lastProgressReport != DateTime.MinValue)                              {                                  Console.Clear();                                  Console.WriteLine("Press 'q' to quit the recovery process");                              }                              lastProgressReport = now;                              var currPos = GetFilePosition(startOffset' mem);                              var eofPos = GetFilePosition(startOffset' eof);                              Console.WriteLine(                                  $"{now:hh:MM:ss}: Recovering page at position {currPos:#'#;;0}/{eofPos:#'#;;0} ({(double)currPos / eofPos:p}) - Last recovered doc is {_lastRecoveredDocumentKey}");                          }                            var pageHeader = (PageHeader*)mem;                            //this page is not raw data section move on                          if ((pageHeader->Flags).HasFlag(PageFlags.RawData) == false && pageHeader->Flags.HasFlag(PageFlags.Stream) == false)                          {                              mem += _pageSize;                              continue;                          }                            if (pageHeader->Flags.HasFlag(PageFlags.Single) &&                              pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              var message =                                  $"page #{pageHeader->PageNumber} (offset={GetFilePosition(startOffset' mem)}) has both Overflow and Single flag turned";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                          //overflow page                          ulong checksum;                          if (pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              if (ValidateOverflowPage(pageHeader' eof' startOffset' ref mem) == false)                                  continue;                                var numberOfPages = VirtualPagerLegacyExtensions.GetNumberOfOverflowPages(pageHeader->OverflowSize);                                if (pageHeader->Flags.HasFlag(PageFlags.Stream))                              {                                  var streamPageHeader = (StreamPageHeader*)pageHeader;                                  if (streamPageHeader->StreamPageFlags.HasFlag(StreamPageFlags.First) == false)                                  {                                      mem += numberOfPages * _pageSize;                                      continue;                                  }                                    int rc;                                  fixed (byte* hashStatePtr = _streamHashState)                                  fixed (byte* hashResultPtr = _streamHashResult)                                  {                                      long totalSize = 0;                                      _attachmentChunks.Clear();                                      rc = Sodium.crypto_generichash_init(hashStatePtr' null' UIntPtr.Zero' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to initialize Sodium for hash computation will skip this page.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      // write document header' including size                                      PageHeader* nextPage = pageHeader;                                      byte* nextPagePtr = (byte*)nextPage;                                      bool valid = true;                                      string tag = null;                                      while (true) // has next                                      {                                          streamPageHeader = (StreamPageHeader*)nextPage;                                          //this is the last page and it contains only stream info + maybe the stream tag                                          if (streamPageHeader->ChunkSize == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          totalSize += streamPageHeader->ChunkSize;                                                                                  var dataStart = (byte*)nextPage + PageHeader.SizeOf;                                          _attachmentChunks.Add(((IntPtr)dataStart' (int)streamPageHeader->ChunkSize));                                          rc = Sodium.crypto_generichash_update(hashStatePtr' dataStart' (ulong)streamPageHeader->ChunkSize);                                          if (rc != 0)                                          {                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute chunk hash' will skip it.");                                              valid = false;                                              break;                                          }                                          if (streamPageHeader->StreamNextPageNumber == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          nextPage = (PageHeader*)(streamPageHeader->StreamNextPageNumber * _pageSize + startOffset);                                          //This is the case that the next page isn't a stream page                                          if (nextPage->Flags.HasFlag(PageFlags.Stream) == false || nextPage->Flags.HasFlag(PageFlags.Overflow) == false)                                          {                                              valid = false;                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{nextPage->PageNumber} (offset={(long)nextPage}) was suppose to be a stream chunck but isn't marked as Overflow | Stream");                                              break;                                          }                                          valid = ValidateOverflowPage(nextPage' eof' (long)nextPage' ref nextPagePtr);                                          if (valid == false)                                          {                                              break;                                          }                                                                                }                                      if (valid == false)                                      {                                          //The first page was valid so we can skip the entire overflow                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                        rc = Sodium.crypto_generichash_final(hashStatePtr' hashResultPtr' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute attachment hash' will skip it.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      var hash = new string(' '' 44);                                      fixed (char* p = hash)                                      {                                          var len = Base64.ConvertToBase64Array(p' hashResultPtr' 0' 32);                                          Debug.Assert(len == 44);                                      }                                        WriteAttachment(documentsWriter' totalSize' hash' tag);                                  }                                  mem += numberOfPages * _pageSize;                              }                                else if (Write((byte*)pageHeader + PageHeader.SizeOf' pageHeader->OverflowSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataOverflowPageHeader*)mem)->TableType))                              {                                    mem += numberOfPages * _pageSize;                              }                              else //write document failed                               {                                  mem += _pageSize;                              }                              continue;                          }                            checksum = StorageEnvironment.CalculatePageChecksum((byte*)pageHeader' pageHeader->PageNumber' pageHeader->Flags' 0);                            if (checksum != pageHeader->Checksum)                          {                              var message =                                  $"Invalid checksum for page {pageHeader->PageNumber}' expected hash to be {pageHeader->Checksum} but was {checksum}";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            // small raw data section                           var rawHeader = (RawDataSmallPageHeader*)mem;                            // small raw data section header                          if (rawHeader->RawDataFlags.HasFlag(RawDataPageFlags.Header))                          {                              mem += _pageSize;                              continue;                          }                          if (rawHeader->NextAllocation > _pageSize)                          {                              var message =                                  $"RawDataSmallPage #{rawHeader->PageNumber} at {GetFilePosition(startOffset' mem)} next allocation is larger than {_pageSize} bytes";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            for (var pos = PageHeader.SizeOf; pos < rawHeader->NextAllocation;)                          {                              var currMem = mem + pos;                              var entry = (RawDataSection.RawDataEntrySizes*)currMem;                              //this indicates that the current entry is invalid because it is outside the size of a page                              if (pos > _pageSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              //Allocated size of entry exceed the bound of the page next allocation                              if (entry->AllocatedSize + pos + sizeof(RawDataSection.RawDataEntrySizes) >                                  rawHeader->NextAllocation)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the allocated entry exceed the bound of the page next allocation.";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              if (entry->UsedSize > entry->AllocatedSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the size of the entry exceed the allocated size";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              pos += entry->AllocatedSize + sizeof(RawDataSection.RawDataEntrySizes);                              if (entry->AllocatedSize == 0 || entry->UsedSize == -1)                                  continue;                                if (Write(currMem + sizeof(RawDataSection.RawDataEntrySizes)' entry->UsedSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataSmallPageHeader*)mem)->TableType) == false)                                  break;                          }                          mem += _pageSize;                      }                      catch (Exception e)                      {                          var message =                              $"Unexpected exception at position {GetFilePosition(startOffset' mem)}:{Environment.NewLine} {e}";                          mem = PrintErrorAndAdvanceMem(message' mem);                      }                  }                    ReportOrphanAttachmentsAndMissingAttachments(ct' documentsWriter);                    //This will only be the case when we don't have orphan attachments and we wrote the last attachment after we wrote the                   //last document                  if (_lastWriteIsDocument == false)                  {                      WriteDummyDocumentForAttachment(documentsWriter' _lastAttachmentInfo.hash' _lastAttachmentInfo.size' _lastAttachmentInfo.tag);                  }                    documentsWriter.WriteEndArray();                  conflictsWriter.WriteEndArray();                  revisionsWriter.WriteEndArray();                                  documentsWriter.WriteEndObject();                  conflictsWriter.WriteEndObject();                  revisionsWriter.WriteEndObject();                      if (_logger.IsOperationsEnabled)                  {                      _logger.Operations($"Discovered a total of {_numberOfDocumentsRetrieved:#'#;00} documents within {sw.Elapsed.TotalSeconds::#'#.#;;00} seconds." + Environment.NewLine +                                         $"Discovered a total of {_attachmentsHashs.Count:#'#;00} attachments. " + Environment.NewLine +                                          $"Discovered a total of {_numberOfFaultedPages::#'#;00} faulted pages.");                  }              }
Magic Number,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The following statement contains a magic number: using (var destinationStreamDocuments = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-2-Documents" + Path.GetExtension(_output))))              using (var destinationStreamRevisions = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-3-Revisions" + Path.GetExtension(_output))))              using (var destinationStreamConflicts = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-4-Conflicts" + Path.GetExtension(_output))))              using (var gZipStreamDocuments = new GZipStream(destinationStreamDocuments' CompressionMode.Compress' true))              using (var gZipStreamRevisions = new GZipStream(destinationStreamRevisions' CompressionMode.Compress' true))              using (var gZipStreamConflicts = new GZipStream(destinationStreamConflicts' CompressionMode.Compress' true))              using (var context = new JsonOperationContext(_initialContextSize' _initialContextLongLivedSize' SharedMultipleUseFlag.None))              using (var documentsWriter = new BlittableJsonTextWriter(context' gZipStreamDocuments))              using (var revisionsWriter = new BlittableJsonTextWriter(context' gZipStreamRevisions))              using (var conflictsWriter = new BlittableJsonTextWriter(context' gZipStreamConflicts))              {                  WriteSmugglerHeader(documentsWriter' 40018' "Docs");                  WriteSmugglerHeader(revisionsWriter' 40018' "RevisionDocuments");                  WriteSmugglerHeader(conflictsWriter' 40018' "ConflictDocuments");                    while (mem < eof)                  {                      try                      {                          if (ct.IsCancellationRequested)                          {                              if (_logger.IsOperationsEnabled)                                  _logger.Operations($"Cancellation requested while recovery was in position {GetFilePosition(startOffset' mem)}");                              _cancellationRequested = true;                              break;                          }                          var now = DateTime.UtcNow;                          if ((now - lastProgressReport).TotalSeconds >= _progressIntervalInSec)                          {                              if (lastProgressReport != DateTime.MinValue)                              {                                  Console.Clear();                                  Console.WriteLine("Press 'q' to quit the recovery process");                              }                              lastProgressReport = now;                              var currPos = GetFilePosition(startOffset' mem);                              var eofPos = GetFilePosition(startOffset' eof);                              Console.WriteLine(                                  $"{now:hh:MM:ss}: Recovering page at position {currPos:#'#;;0}/{eofPos:#'#;;0} ({(double)currPos / eofPos:p}) - Last recovered doc is {_lastRecoveredDocumentKey}");                          }                            var pageHeader = (PageHeader*)mem;                            //this page is not raw data section move on                          if ((pageHeader->Flags).HasFlag(PageFlags.RawData) == false && pageHeader->Flags.HasFlag(PageFlags.Stream) == false)                          {                              mem += _pageSize;                              continue;                          }                            if (pageHeader->Flags.HasFlag(PageFlags.Single) &&                              pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              var message =                                  $"page #{pageHeader->PageNumber} (offset={GetFilePosition(startOffset' mem)}) has both Overflow and Single flag turned";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                          //overflow page                          ulong checksum;                          if (pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              if (ValidateOverflowPage(pageHeader' eof' startOffset' ref mem) == false)                                  continue;                                var numberOfPages = VirtualPagerLegacyExtensions.GetNumberOfOverflowPages(pageHeader->OverflowSize);                                if (pageHeader->Flags.HasFlag(PageFlags.Stream))                              {                                  var streamPageHeader = (StreamPageHeader*)pageHeader;                                  if (streamPageHeader->StreamPageFlags.HasFlag(StreamPageFlags.First) == false)                                  {                                      mem += numberOfPages * _pageSize;                                      continue;                                  }                                    int rc;                                  fixed (byte* hashStatePtr = _streamHashState)                                  fixed (byte* hashResultPtr = _streamHashResult)                                  {                                      long totalSize = 0;                                      _attachmentChunks.Clear();                                      rc = Sodium.crypto_generichash_init(hashStatePtr' null' UIntPtr.Zero' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to initialize Sodium for hash computation will skip this page.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      // write document header' including size                                      PageHeader* nextPage = pageHeader;                                      byte* nextPagePtr = (byte*)nextPage;                                      bool valid = true;                                      string tag = null;                                      while (true) // has next                                      {                                          streamPageHeader = (StreamPageHeader*)nextPage;                                          //this is the last page and it contains only stream info + maybe the stream tag                                          if (streamPageHeader->ChunkSize == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          totalSize += streamPageHeader->ChunkSize;                                                                                  var dataStart = (byte*)nextPage + PageHeader.SizeOf;                                          _attachmentChunks.Add(((IntPtr)dataStart' (int)streamPageHeader->ChunkSize));                                          rc = Sodium.crypto_generichash_update(hashStatePtr' dataStart' (ulong)streamPageHeader->ChunkSize);                                          if (rc != 0)                                          {                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute chunk hash' will skip it.");                                              valid = false;                                              break;                                          }                                          if (streamPageHeader->StreamNextPageNumber == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          nextPage = (PageHeader*)(streamPageHeader->StreamNextPageNumber * _pageSize + startOffset);                                          //This is the case that the next page isn't a stream page                                          if (nextPage->Flags.HasFlag(PageFlags.Stream) == false || nextPage->Flags.HasFlag(PageFlags.Overflow) == false)                                          {                                              valid = false;                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{nextPage->PageNumber} (offset={(long)nextPage}) was suppose to be a stream chunck but isn't marked as Overflow | Stream");                                              break;                                          }                                          valid = ValidateOverflowPage(nextPage' eof' (long)nextPage' ref nextPagePtr);                                          if (valid == false)                                          {                                              break;                                          }                                                                                }                                      if (valid == false)                                      {                                          //The first page was valid so we can skip the entire overflow                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                        rc = Sodium.crypto_generichash_final(hashStatePtr' hashResultPtr' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute attachment hash' will skip it.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      var hash = new string(' '' 44);                                      fixed (char* p = hash)                                      {                                          var len = Base64.ConvertToBase64Array(p' hashResultPtr' 0' 32);                                          Debug.Assert(len == 44);                                      }                                        WriteAttachment(documentsWriter' totalSize' hash' tag);                                  }                                  mem += numberOfPages * _pageSize;                              }                                else if (Write((byte*)pageHeader + PageHeader.SizeOf' pageHeader->OverflowSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataOverflowPageHeader*)mem)->TableType))                              {                                    mem += numberOfPages * _pageSize;                              }                              else //write document failed                               {                                  mem += _pageSize;                              }                              continue;                          }                            checksum = StorageEnvironment.CalculatePageChecksum((byte*)pageHeader' pageHeader->PageNumber' pageHeader->Flags' 0);                            if (checksum != pageHeader->Checksum)                          {                              var message =                                  $"Invalid checksum for page {pageHeader->PageNumber}' expected hash to be {pageHeader->Checksum} but was {checksum}";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            // small raw data section                           var rawHeader = (RawDataSmallPageHeader*)mem;                            // small raw data section header                          if (rawHeader->RawDataFlags.HasFlag(RawDataPageFlags.Header))                          {                              mem += _pageSize;                              continue;                          }                          if (rawHeader->NextAllocation > _pageSize)                          {                              var message =                                  $"RawDataSmallPage #{rawHeader->PageNumber} at {GetFilePosition(startOffset' mem)} next allocation is larger than {_pageSize} bytes";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            for (var pos = PageHeader.SizeOf; pos < rawHeader->NextAllocation;)                          {                              var currMem = mem + pos;                              var entry = (RawDataSection.RawDataEntrySizes*)currMem;                              //this indicates that the current entry is invalid because it is outside the size of a page                              if (pos > _pageSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              //Allocated size of entry exceed the bound of the page next allocation                              if (entry->AllocatedSize + pos + sizeof(RawDataSection.RawDataEntrySizes) >                                  rawHeader->NextAllocation)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the allocated entry exceed the bound of the page next allocation.";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              if (entry->UsedSize > entry->AllocatedSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the size of the entry exceed the allocated size";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              pos += entry->AllocatedSize + sizeof(RawDataSection.RawDataEntrySizes);                              if (entry->AllocatedSize == 0 || entry->UsedSize == -1)                                  continue;                                if (Write(currMem + sizeof(RawDataSection.RawDataEntrySizes)' entry->UsedSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataSmallPageHeader*)mem)->TableType) == false)                                  break;                          }                          mem += _pageSize;                      }                      catch (Exception e)                      {                          var message =                              $"Unexpected exception at position {GetFilePosition(startOffset' mem)}:{Environment.NewLine} {e}";                          mem = PrintErrorAndAdvanceMem(message' mem);                      }                  }                    ReportOrphanAttachmentsAndMissingAttachments(ct' documentsWriter);                    //This will only be the case when we don't have orphan attachments and we wrote the last attachment after we wrote the                   //last document                  if (_lastWriteIsDocument == false)                  {                      WriteDummyDocumentForAttachment(documentsWriter' _lastAttachmentInfo.hash' _lastAttachmentInfo.size' _lastAttachmentInfo.tag);                  }                    documentsWriter.WriteEndArray();                  conflictsWriter.WriteEndArray();                  revisionsWriter.WriteEndArray();                                  documentsWriter.WriteEndObject();                  conflictsWriter.WriteEndObject();                  revisionsWriter.WriteEndObject();                      if (_logger.IsOperationsEnabled)                  {                      _logger.Operations($"Discovered a total of {_numberOfDocumentsRetrieved:#'#;00} documents within {sw.Elapsed.TotalSeconds::#'#.#;;00} seconds." + Environment.NewLine +                                         $"Discovered a total of {_attachmentsHashs.Count:#'#;00} attachments. " + Environment.NewLine +                                          $"Discovered a total of {_numberOfFaultedPages::#'#;00} faulted pages.");                  }              }
Magic Number,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The following statement contains a magic number: using (var destinationStreamDocuments = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-2-Documents" + Path.GetExtension(_output))))              using (var destinationStreamRevisions = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-3-Revisions" + Path.GetExtension(_output))))              using (var destinationStreamConflicts = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-4-Conflicts" + Path.GetExtension(_output))))              using (var gZipStreamDocuments = new GZipStream(destinationStreamDocuments' CompressionMode.Compress' true))              using (var gZipStreamRevisions = new GZipStream(destinationStreamRevisions' CompressionMode.Compress' true))              using (var gZipStreamConflicts = new GZipStream(destinationStreamConflicts' CompressionMode.Compress' true))              using (var context = new JsonOperationContext(_initialContextSize' _initialContextLongLivedSize' SharedMultipleUseFlag.None))              using (var documentsWriter = new BlittableJsonTextWriter(context' gZipStreamDocuments))              using (var revisionsWriter = new BlittableJsonTextWriter(context' gZipStreamRevisions))              using (var conflictsWriter = new BlittableJsonTextWriter(context' gZipStreamConflicts))              {                  WriteSmugglerHeader(documentsWriter' 40018' "Docs");                  WriteSmugglerHeader(revisionsWriter' 40018' "RevisionDocuments");                  WriteSmugglerHeader(conflictsWriter' 40018' "ConflictDocuments");                    while (mem < eof)                  {                      try                      {                          if (ct.IsCancellationRequested)                          {                              if (_logger.IsOperationsEnabled)                                  _logger.Operations($"Cancellation requested while recovery was in position {GetFilePosition(startOffset' mem)}");                              _cancellationRequested = true;                              break;                          }                          var now = DateTime.UtcNow;                          if ((now - lastProgressReport).TotalSeconds >= _progressIntervalInSec)                          {                              if (lastProgressReport != DateTime.MinValue)                              {                                  Console.Clear();                                  Console.WriteLine("Press 'q' to quit the recovery process");                              }                              lastProgressReport = now;                              var currPos = GetFilePosition(startOffset' mem);                              var eofPos = GetFilePosition(startOffset' eof);                              Console.WriteLine(                                  $"{now:hh:MM:ss}: Recovering page at position {currPos:#'#;;0}/{eofPos:#'#;;0} ({(double)currPos / eofPos:p}) - Last recovered doc is {_lastRecoveredDocumentKey}");                          }                            var pageHeader = (PageHeader*)mem;                            //this page is not raw data section move on                          if ((pageHeader->Flags).HasFlag(PageFlags.RawData) == false && pageHeader->Flags.HasFlag(PageFlags.Stream) == false)                          {                              mem += _pageSize;                              continue;                          }                            if (pageHeader->Flags.HasFlag(PageFlags.Single) &&                              pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              var message =                                  $"page #{pageHeader->PageNumber} (offset={GetFilePosition(startOffset' mem)}) has both Overflow and Single flag turned";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                          //overflow page                          ulong checksum;                          if (pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              if (ValidateOverflowPage(pageHeader' eof' startOffset' ref mem) == false)                                  continue;                                var numberOfPages = VirtualPagerLegacyExtensions.GetNumberOfOverflowPages(pageHeader->OverflowSize);                                if (pageHeader->Flags.HasFlag(PageFlags.Stream))                              {                                  var streamPageHeader = (StreamPageHeader*)pageHeader;                                  if (streamPageHeader->StreamPageFlags.HasFlag(StreamPageFlags.First) == false)                                  {                                      mem += numberOfPages * _pageSize;                                      continue;                                  }                                    int rc;                                  fixed (byte* hashStatePtr = _streamHashState)                                  fixed (byte* hashResultPtr = _streamHashResult)                                  {                                      long totalSize = 0;                                      _attachmentChunks.Clear();                                      rc = Sodium.crypto_generichash_init(hashStatePtr' null' UIntPtr.Zero' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to initialize Sodium for hash computation will skip this page.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      // write document header' including size                                      PageHeader* nextPage = pageHeader;                                      byte* nextPagePtr = (byte*)nextPage;                                      bool valid = true;                                      string tag = null;                                      while (true) // has next                                      {                                          streamPageHeader = (StreamPageHeader*)nextPage;                                          //this is the last page and it contains only stream info + maybe the stream tag                                          if (streamPageHeader->ChunkSize == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          totalSize += streamPageHeader->ChunkSize;                                                                                  var dataStart = (byte*)nextPage + PageHeader.SizeOf;                                          _attachmentChunks.Add(((IntPtr)dataStart' (int)streamPageHeader->ChunkSize));                                          rc = Sodium.crypto_generichash_update(hashStatePtr' dataStart' (ulong)streamPageHeader->ChunkSize);                                          if (rc != 0)                                          {                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute chunk hash' will skip it.");                                              valid = false;                                              break;                                          }                                          if (streamPageHeader->StreamNextPageNumber == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          nextPage = (PageHeader*)(streamPageHeader->StreamNextPageNumber * _pageSize + startOffset);                                          //This is the case that the next page isn't a stream page                                          if (nextPage->Flags.HasFlag(PageFlags.Stream) == false || nextPage->Flags.HasFlag(PageFlags.Overflow) == false)                                          {                                              valid = false;                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{nextPage->PageNumber} (offset={(long)nextPage}) was suppose to be a stream chunck but isn't marked as Overflow | Stream");                                              break;                                          }                                          valid = ValidateOverflowPage(nextPage' eof' (long)nextPage' ref nextPagePtr);                                          if (valid == false)                                          {                                              break;                                          }                                                                                }                                      if (valid == false)                                      {                                          //The first page was valid so we can skip the entire overflow                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                        rc = Sodium.crypto_generichash_final(hashStatePtr' hashResultPtr' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute attachment hash' will skip it.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      var hash = new string(' '' 44);                                      fixed (char* p = hash)                                      {                                          var len = Base64.ConvertToBase64Array(p' hashResultPtr' 0' 32);                                          Debug.Assert(len == 44);                                      }                                        WriteAttachment(documentsWriter' totalSize' hash' tag);                                  }                                  mem += numberOfPages * _pageSize;                              }                                else if (Write((byte*)pageHeader + PageHeader.SizeOf' pageHeader->OverflowSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataOverflowPageHeader*)mem)->TableType))                              {                                    mem += numberOfPages * _pageSize;                              }                              else //write document failed                               {                                  mem += _pageSize;                              }                              continue;                          }                            checksum = StorageEnvironment.CalculatePageChecksum((byte*)pageHeader' pageHeader->PageNumber' pageHeader->Flags' 0);                            if (checksum != pageHeader->Checksum)                          {                              var message =                                  $"Invalid checksum for page {pageHeader->PageNumber}' expected hash to be {pageHeader->Checksum} but was {checksum}";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            // small raw data section                           var rawHeader = (RawDataSmallPageHeader*)mem;                            // small raw data section header                          if (rawHeader->RawDataFlags.HasFlag(RawDataPageFlags.Header))                          {                              mem += _pageSize;                              continue;                          }                          if (rawHeader->NextAllocation > _pageSize)                          {                              var message =                                  $"RawDataSmallPage #{rawHeader->PageNumber} at {GetFilePosition(startOffset' mem)} next allocation is larger than {_pageSize} bytes";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            for (var pos = PageHeader.SizeOf; pos < rawHeader->NextAllocation;)                          {                              var currMem = mem + pos;                              var entry = (RawDataSection.RawDataEntrySizes*)currMem;                              //this indicates that the current entry is invalid because it is outside the size of a page                              if (pos > _pageSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              //Allocated size of entry exceed the bound of the page next allocation                              if (entry->AllocatedSize + pos + sizeof(RawDataSection.RawDataEntrySizes) >                                  rawHeader->NextAllocation)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the allocated entry exceed the bound of the page next allocation.";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              if (entry->UsedSize > entry->AllocatedSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the size of the entry exceed the allocated size";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              pos += entry->AllocatedSize + sizeof(RawDataSection.RawDataEntrySizes);                              if (entry->AllocatedSize == 0 || entry->UsedSize == -1)                                  continue;                                if (Write(currMem + sizeof(RawDataSection.RawDataEntrySizes)' entry->UsedSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataSmallPageHeader*)mem)->TableType) == false)                                  break;                          }                          mem += _pageSize;                      }                      catch (Exception e)                      {                          var message =                              $"Unexpected exception at position {GetFilePosition(startOffset' mem)}:{Environment.NewLine} {e}";                          mem = PrintErrorAndAdvanceMem(message' mem);                      }                  }                    ReportOrphanAttachmentsAndMissingAttachments(ct' documentsWriter);                    //This will only be the case when we don't have orphan attachments and we wrote the last attachment after we wrote the                   //last document                  if (_lastWriteIsDocument == false)                  {                      WriteDummyDocumentForAttachment(documentsWriter' _lastAttachmentInfo.hash' _lastAttachmentInfo.size' _lastAttachmentInfo.tag);                  }                    documentsWriter.WriteEndArray();                  conflictsWriter.WriteEndArray();                  revisionsWriter.WriteEndArray();                                  documentsWriter.WriteEndObject();                  conflictsWriter.WriteEndObject();                  revisionsWriter.WriteEndObject();                      if (_logger.IsOperationsEnabled)                  {                      _logger.Operations($"Discovered a total of {_numberOfDocumentsRetrieved:#'#;00} documents within {sw.Elapsed.TotalSeconds::#'#.#;;00} seconds." + Environment.NewLine +                                         $"Discovered a total of {_attachmentsHashs.Count:#'#;00} attachments. " + Environment.NewLine +                                          $"Discovered a total of {_numberOfFaultedPages::#'#;00} faulted pages.");                  }              }
Magic Number,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The following statement contains a magic number: using (var destinationStreamDocuments = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-2-Documents" + Path.GetExtension(_output))))              using (var destinationStreamRevisions = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-3-Revisions" + Path.GetExtension(_output))))              using (var destinationStreamConflicts = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-4-Conflicts" + Path.GetExtension(_output))))              using (var gZipStreamDocuments = new GZipStream(destinationStreamDocuments' CompressionMode.Compress' true))              using (var gZipStreamRevisions = new GZipStream(destinationStreamRevisions' CompressionMode.Compress' true))              using (var gZipStreamConflicts = new GZipStream(destinationStreamConflicts' CompressionMode.Compress' true))              using (var context = new JsonOperationContext(_initialContextSize' _initialContextLongLivedSize' SharedMultipleUseFlag.None))              using (var documentsWriter = new BlittableJsonTextWriter(context' gZipStreamDocuments))              using (var revisionsWriter = new BlittableJsonTextWriter(context' gZipStreamRevisions))              using (var conflictsWriter = new BlittableJsonTextWriter(context' gZipStreamConflicts))              {                  WriteSmugglerHeader(documentsWriter' 40018' "Docs");                  WriteSmugglerHeader(revisionsWriter' 40018' "RevisionDocuments");                  WriteSmugglerHeader(conflictsWriter' 40018' "ConflictDocuments");                    while (mem < eof)                  {                      try                      {                          if (ct.IsCancellationRequested)                          {                              if (_logger.IsOperationsEnabled)                                  _logger.Operations($"Cancellation requested while recovery was in position {GetFilePosition(startOffset' mem)}");                              _cancellationRequested = true;                              break;                          }                          var now = DateTime.UtcNow;                          if ((now - lastProgressReport).TotalSeconds >= _progressIntervalInSec)                          {                              if (lastProgressReport != DateTime.MinValue)                              {                                  Console.Clear();                                  Console.WriteLine("Press 'q' to quit the recovery process");                              }                              lastProgressReport = now;                              var currPos = GetFilePosition(startOffset' mem);                              var eofPos = GetFilePosition(startOffset' eof);                              Console.WriteLine(                                  $"{now:hh:MM:ss}: Recovering page at position {currPos:#'#;;0}/{eofPos:#'#;;0} ({(double)currPos / eofPos:p}) - Last recovered doc is {_lastRecoveredDocumentKey}");                          }                            var pageHeader = (PageHeader*)mem;                            //this page is not raw data section move on                          if ((pageHeader->Flags).HasFlag(PageFlags.RawData) == false && pageHeader->Flags.HasFlag(PageFlags.Stream) == false)                          {                              mem += _pageSize;                              continue;                          }                            if (pageHeader->Flags.HasFlag(PageFlags.Single) &&                              pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              var message =                                  $"page #{pageHeader->PageNumber} (offset={GetFilePosition(startOffset' mem)}) has both Overflow and Single flag turned";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                          //overflow page                          ulong checksum;                          if (pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              if (ValidateOverflowPage(pageHeader' eof' startOffset' ref mem) == false)                                  continue;                                var numberOfPages = VirtualPagerLegacyExtensions.GetNumberOfOverflowPages(pageHeader->OverflowSize);                                if (pageHeader->Flags.HasFlag(PageFlags.Stream))                              {                                  var streamPageHeader = (StreamPageHeader*)pageHeader;                                  if (streamPageHeader->StreamPageFlags.HasFlag(StreamPageFlags.First) == false)                                  {                                      mem += numberOfPages * _pageSize;                                      continue;                                  }                                    int rc;                                  fixed (byte* hashStatePtr = _streamHashState)                                  fixed (byte* hashResultPtr = _streamHashResult)                                  {                                      long totalSize = 0;                                      _attachmentChunks.Clear();                                      rc = Sodium.crypto_generichash_init(hashStatePtr' null' UIntPtr.Zero' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to initialize Sodium for hash computation will skip this page.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      // write document header' including size                                      PageHeader* nextPage = pageHeader;                                      byte* nextPagePtr = (byte*)nextPage;                                      bool valid = true;                                      string tag = null;                                      while (true) // has next                                      {                                          streamPageHeader = (StreamPageHeader*)nextPage;                                          //this is the last page and it contains only stream info + maybe the stream tag                                          if (streamPageHeader->ChunkSize == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          totalSize += streamPageHeader->ChunkSize;                                                                                  var dataStart = (byte*)nextPage + PageHeader.SizeOf;                                          _attachmentChunks.Add(((IntPtr)dataStart' (int)streamPageHeader->ChunkSize));                                          rc = Sodium.crypto_generichash_update(hashStatePtr' dataStart' (ulong)streamPageHeader->ChunkSize);                                          if (rc != 0)                                          {                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute chunk hash' will skip it.");                                              valid = false;                                              break;                                          }                                          if (streamPageHeader->StreamNextPageNumber == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          nextPage = (PageHeader*)(streamPageHeader->StreamNextPageNumber * _pageSize + startOffset);                                          //This is the case that the next page isn't a stream page                                          if (nextPage->Flags.HasFlag(PageFlags.Stream) == false || nextPage->Flags.HasFlag(PageFlags.Overflow) == false)                                          {                                              valid = false;                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{nextPage->PageNumber} (offset={(long)nextPage}) was suppose to be a stream chunck but isn't marked as Overflow | Stream");                                              break;                                          }                                          valid = ValidateOverflowPage(nextPage' eof' (long)nextPage' ref nextPagePtr);                                          if (valid == false)                                          {                                              break;                                          }                                                                                }                                      if (valid == false)                                      {                                          //The first page was valid so we can skip the entire overflow                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                        rc = Sodium.crypto_generichash_final(hashStatePtr' hashResultPtr' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute attachment hash' will skip it.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      var hash = new string(' '' 44);                                      fixed (char* p = hash)                                      {                                          var len = Base64.ConvertToBase64Array(p' hashResultPtr' 0' 32);                                          Debug.Assert(len == 44);                                      }                                        WriteAttachment(documentsWriter' totalSize' hash' tag);                                  }                                  mem += numberOfPages * _pageSize;                              }                                else if (Write((byte*)pageHeader + PageHeader.SizeOf' pageHeader->OverflowSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataOverflowPageHeader*)mem)->TableType))                              {                                    mem += numberOfPages * _pageSize;                              }                              else //write document failed                               {                                  mem += _pageSize;                              }                              continue;                          }                            checksum = StorageEnvironment.CalculatePageChecksum((byte*)pageHeader' pageHeader->PageNumber' pageHeader->Flags' 0);                            if (checksum != pageHeader->Checksum)                          {                              var message =                                  $"Invalid checksum for page {pageHeader->PageNumber}' expected hash to be {pageHeader->Checksum} but was {checksum}";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            // small raw data section                           var rawHeader = (RawDataSmallPageHeader*)mem;                            // small raw data section header                          if (rawHeader->RawDataFlags.HasFlag(RawDataPageFlags.Header))                          {                              mem += _pageSize;                              continue;                          }                          if (rawHeader->NextAllocation > _pageSize)                          {                              var message =                                  $"RawDataSmallPage #{rawHeader->PageNumber} at {GetFilePosition(startOffset' mem)} next allocation is larger than {_pageSize} bytes";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            for (var pos = PageHeader.SizeOf; pos < rawHeader->NextAllocation;)                          {                              var currMem = mem + pos;                              var entry = (RawDataSection.RawDataEntrySizes*)currMem;                              //this indicates that the current entry is invalid because it is outside the size of a page                              if (pos > _pageSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              //Allocated size of entry exceed the bound of the page next allocation                              if (entry->AllocatedSize + pos + sizeof(RawDataSection.RawDataEntrySizes) >                                  rawHeader->NextAllocation)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the allocated entry exceed the bound of the page next allocation.";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              if (entry->UsedSize > entry->AllocatedSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the size of the entry exceed the allocated size";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              pos += entry->AllocatedSize + sizeof(RawDataSection.RawDataEntrySizes);                              if (entry->AllocatedSize == 0 || entry->UsedSize == -1)                                  continue;                                if (Write(currMem + sizeof(RawDataSection.RawDataEntrySizes)' entry->UsedSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataSmallPageHeader*)mem)->TableType) == false)                                  break;                          }                          mem += _pageSize;                      }                      catch (Exception e)                      {                          var message =                              $"Unexpected exception at position {GetFilePosition(startOffset' mem)}:{Environment.NewLine} {e}";                          mem = PrintErrorAndAdvanceMem(message' mem);                      }                  }                    ReportOrphanAttachmentsAndMissingAttachments(ct' documentsWriter);                    //This will only be the case when we don't have orphan attachments and we wrote the last attachment after we wrote the                   //last document                  if (_lastWriteIsDocument == false)                  {                      WriteDummyDocumentForAttachment(documentsWriter' _lastAttachmentInfo.hash' _lastAttachmentInfo.size' _lastAttachmentInfo.tag);                  }                    documentsWriter.WriteEndArray();                  conflictsWriter.WriteEndArray();                  revisionsWriter.WriteEndArray();                                  documentsWriter.WriteEndObject();                  conflictsWriter.WriteEndObject();                  revisionsWriter.WriteEndObject();                      if (_logger.IsOperationsEnabled)                  {                      _logger.Operations($"Discovered a total of {_numberOfDocumentsRetrieved:#'#;00} documents within {sw.Elapsed.TotalSeconds::#'#.#;;00} seconds." + Environment.NewLine +                                         $"Discovered a total of {_attachmentsHashs.Count:#'#;00} attachments. " + Environment.NewLine +                                          $"Discovered a total of {_numberOfFaultedPages::#'#;00} faulted pages.");                  }              }
Magic Number,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,Execute,The following statement contains a magic number: using (var destinationStreamDocuments = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-2-Documents" + Path.GetExtension(_output))))              using (var destinationStreamRevisions = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-3-Revisions" + Path.GetExtension(_output))))              using (var destinationStreamConflicts = File.OpenWrite(Path.Combine(Path.GetDirectoryName(_output)' Path.GetFileNameWithoutExtension(_output) + "-4-Conflicts" + Path.GetExtension(_output))))              using (var gZipStreamDocuments = new GZipStream(destinationStreamDocuments' CompressionMode.Compress' true))              using (var gZipStreamRevisions = new GZipStream(destinationStreamRevisions' CompressionMode.Compress' true))              using (var gZipStreamConflicts = new GZipStream(destinationStreamConflicts' CompressionMode.Compress' true))              using (var context = new JsonOperationContext(_initialContextSize' _initialContextLongLivedSize' SharedMultipleUseFlag.None))              using (var documentsWriter = new BlittableJsonTextWriter(context' gZipStreamDocuments))              using (var revisionsWriter = new BlittableJsonTextWriter(context' gZipStreamRevisions))              using (var conflictsWriter = new BlittableJsonTextWriter(context' gZipStreamConflicts))              {                  WriteSmugglerHeader(documentsWriter' 40018' "Docs");                  WriteSmugglerHeader(revisionsWriter' 40018' "RevisionDocuments");                  WriteSmugglerHeader(conflictsWriter' 40018' "ConflictDocuments");                    while (mem < eof)                  {                      try                      {                          if (ct.IsCancellationRequested)                          {                              if (_logger.IsOperationsEnabled)                                  _logger.Operations($"Cancellation requested while recovery was in position {GetFilePosition(startOffset' mem)}");                              _cancellationRequested = true;                              break;                          }                          var now = DateTime.UtcNow;                          if ((now - lastProgressReport).TotalSeconds >= _progressIntervalInSec)                          {                              if (lastProgressReport != DateTime.MinValue)                              {                                  Console.Clear();                                  Console.WriteLine("Press 'q' to quit the recovery process");                              }                              lastProgressReport = now;                              var currPos = GetFilePosition(startOffset' mem);                              var eofPos = GetFilePosition(startOffset' eof);                              Console.WriteLine(                                  $"{now:hh:MM:ss}: Recovering page at position {currPos:#'#;;0}/{eofPos:#'#;;0} ({(double)currPos / eofPos:p}) - Last recovered doc is {_lastRecoveredDocumentKey}");                          }                            var pageHeader = (PageHeader*)mem;                            //this page is not raw data section move on                          if ((pageHeader->Flags).HasFlag(PageFlags.RawData) == false && pageHeader->Flags.HasFlag(PageFlags.Stream) == false)                          {                              mem += _pageSize;                              continue;                          }                            if (pageHeader->Flags.HasFlag(PageFlags.Single) &&                              pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              var message =                                  $"page #{pageHeader->PageNumber} (offset={GetFilePosition(startOffset' mem)}) has both Overflow and Single flag turned";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                          //overflow page                          ulong checksum;                          if (pageHeader->Flags.HasFlag(PageFlags.Overflow))                          {                              if (ValidateOverflowPage(pageHeader' eof' startOffset' ref mem) == false)                                  continue;                                var numberOfPages = VirtualPagerLegacyExtensions.GetNumberOfOverflowPages(pageHeader->OverflowSize);                                if (pageHeader->Flags.HasFlag(PageFlags.Stream))                              {                                  var streamPageHeader = (StreamPageHeader*)pageHeader;                                  if (streamPageHeader->StreamPageFlags.HasFlag(StreamPageFlags.First) == false)                                  {                                      mem += numberOfPages * _pageSize;                                      continue;                                  }                                    int rc;                                  fixed (byte* hashStatePtr = _streamHashState)                                  fixed (byte* hashResultPtr = _streamHashResult)                                  {                                      long totalSize = 0;                                      _attachmentChunks.Clear();                                      rc = Sodium.crypto_generichash_init(hashStatePtr' null' UIntPtr.Zero' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to initialize Sodium for hash computation will skip this page.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      // write document header' including size                                      PageHeader* nextPage = pageHeader;                                      byte* nextPagePtr = (byte*)nextPage;                                      bool valid = true;                                      string tag = null;                                      while (true) // has next                                      {                                          streamPageHeader = (StreamPageHeader*)nextPage;                                          //this is the last page and it contains only stream info + maybe the stream tag                                          if (streamPageHeader->ChunkSize == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          totalSize += streamPageHeader->ChunkSize;                                                                                  var dataStart = (byte*)nextPage + PageHeader.SizeOf;                                          _attachmentChunks.Add(((IntPtr)dataStart' (int)streamPageHeader->ChunkSize));                                          rc = Sodium.crypto_generichash_update(hashStatePtr' dataStart' (ulong)streamPageHeader->ChunkSize);                                          if (rc != 0)                                          {                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute chunk hash' will skip it.");                                              valid = false;                                              break;                                          }                                          if (streamPageHeader->StreamNextPageNumber == 0)                                          {                                              ExtractTagFromLastPage(nextPage' streamPageHeader' ref tag);                                              break;                                          }                                          nextPage = (PageHeader*)(streamPageHeader->StreamNextPageNumber * _pageSize + startOffset);                                          //This is the case that the next page isn't a stream page                                          if (nextPage->Flags.HasFlag(PageFlags.Stream) == false || nextPage->Flags.HasFlag(PageFlags.Overflow) == false)                                          {                                              valid = false;                                              if (_logger.IsOperationsEnabled)                                                  _logger.Operations($"page #{nextPage->PageNumber} (offset={(long)nextPage}) was suppose to be a stream chunck but isn't marked as Overflow | Stream");                                              break;                                          }                                          valid = ValidateOverflowPage(nextPage' eof' (long)nextPage' ref nextPagePtr);                                          if (valid == false)                                          {                                              break;                                          }                                                                                }                                      if (valid == false)                                      {                                          //The first page was valid so we can skip the entire overflow                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                        rc = Sodium.crypto_generichash_final(hashStatePtr' hashResultPtr' (UIntPtr)_streamHashResult.Length);                                      if (rc != 0)                                      {                                          if (_logger.IsOperationsEnabled)                                              _logger.Operations($"page #{pageHeader->PageNumber} (offset={(long)pageHeader}) failed to compute attachment hash' will skip it.");                                          mem += numberOfPages * _pageSize;                                          continue;                                      }                                      var hash = new string(' '' 44);                                      fixed (char* p = hash)                                      {                                          var len = Base64.ConvertToBase64Array(p' hashResultPtr' 0' 32);                                          Debug.Assert(len == 44);                                      }                                        WriteAttachment(documentsWriter' totalSize' hash' tag);                                  }                                  mem += numberOfPages * _pageSize;                              }                                else if (Write((byte*)pageHeader + PageHeader.SizeOf' pageHeader->OverflowSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataOverflowPageHeader*)mem)->TableType))                              {                                    mem += numberOfPages * _pageSize;                              }                              else //write document failed                               {                                  mem += _pageSize;                              }                              continue;                          }                            checksum = StorageEnvironment.CalculatePageChecksum((byte*)pageHeader' pageHeader->PageNumber' pageHeader->Flags' 0);                            if (checksum != pageHeader->Checksum)                          {                              var message =                                  $"Invalid checksum for page {pageHeader->PageNumber}' expected hash to be {pageHeader->Checksum} but was {checksum}";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            // small raw data section                           var rawHeader = (RawDataSmallPageHeader*)mem;                            // small raw data section header                          if (rawHeader->RawDataFlags.HasFlag(RawDataPageFlags.Header))                          {                              mem += _pageSize;                              continue;                          }                          if (rawHeader->NextAllocation > _pageSize)                          {                              var message =                                  $"RawDataSmallPage #{rawHeader->PageNumber} at {GetFilePosition(startOffset' mem)} next allocation is larger than {_pageSize} bytes";                              mem = PrintErrorAndAdvanceMem(message' mem);                              continue;                          }                            for (var pos = PageHeader.SizeOf; pos < rawHeader->NextAllocation;)                          {                              var currMem = mem + pos;                              var entry = (RawDataSection.RawDataEntrySizes*)currMem;                              //this indicates that the current entry is invalid because it is outside the size of a page                              if (pos > _pageSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              //Allocated size of entry exceed the bound of the page next allocation                              if (entry->AllocatedSize + pos + sizeof(RawDataSection.RawDataEntrySizes) >                                  rawHeader->NextAllocation)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the allocated entry exceed the bound of the page next allocation.";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              if (entry->UsedSize > entry->AllocatedSize)                              {                                  var message =                                      $"RawDataSmallPage #{rawHeader->PageNumber} has an invalid entry at {GetFilePosition(startOffset' currMem)}" +                                      "the size of the entry exceed the allocated size";                                  mem = PrintErrorAndAdvanceMem(message' mem);                                  //we can't retrive entries past the invalid entry                                  break;                              }                              pos += entry->AllocatedSize + sizeof(RawDataSection.RawDataEntrySizes);                              if (entry->AllocatedSize == 0 || entry->UsedSize == -1)                                  continue;                                if (Write(currMem + sizeof(RawDataSection.RawDataEntrySizes)' entry->UsedSize' documentsWriter' revisionsWriter'                                  conflictsWriter' context' startOffset' ((RawDataSmallPageHeader*)mem)->TableType) == false)                                  break;                          }                          mem += _pageSize;                      }                      catch (Exception e)                      {                          var message =                              $"Unexpected exception at position {GetFilePosition(startOffset' mem)}:{Environment.NewLine} {e}";                          mem = PrintErrorAndAdvanceMem(message' mem);                      }                  }                    ReportOrphanAttachmentsAndMissingAttachments(ct' documentsWriter);                    //This will only be the case when we don't have orphan attachments and we wrote the last attachment after we wrote the                   //last document                  if (_lastWriteIsDocument == false)                  {                      WriteDummyDocumentForAttachment(documentsWriter' _lastAttachmentInfo.hash' _lastAttachmentInfo.size' _lastAttachmentInfo.tag);                  }                    documentsWriter.WriteEndArray();                  conflictsWriter.WriteEndArray();                  revisionsWriter.WriteEndArray();                                  documentsWriter.WriteEndObject();                  conflictsWriter.WriteEndObject();                  revisionsWriter.WriteEndObject();                      if (_logger.IsOperationsEnabled)                  {                      _logger.Operations($"Discovered a total of {_numberOfDocumentsRetrieved:#'#;00} documents within {sw.Elapsed.TotalSeconds::#'#.#;;00} seconds." + Environment.NewLine +                                         $"Discovered a total of {_attachmentsHashs.Count:#'#;00} attachments. " + Environment.NewLine +                                          $"Discovered a total of {_numberOfFaultedPages::#'#;00} faulted pages.");                  }              }
Magic Number,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteDummyDocumentForAttachment,The following statement contains a magic number: if (tag != null)              {                  //doc id | type 'd' or 'r' | name | hash | content type                  var tokens = tag.Split(TagSeparator);                  if (tokens.Length == 5)                  {                      WriteAttachmentMetadata(writer' hash' size' tokens[2]' tokens[4]);                  }                  else                  {                      WriteAttachmentMetadata(writer' hash' size' $"DummyAttachmentName{_dummyAttachmentNumber++}"' Empty);                  }              }              else              {                  WriteAttachmentMetadata(writer' hash' size' $"DummyAttachmentName{_dummyAttachmentNumber++}"' Empty);              }
Magic Number,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteDummyDocumentForAttachment,The following statement contains a magic number: if (tag != null)              {                  //doc id | type 'd' or 'r' | name | hash | content type                  var tokens = tag.Split(TagSeparator);                  if (tokens.Length == 5)                  {                      WriteAttachmentMetadata(writer' hash' size' tokens[2]' tokens[4]);                  }                  else                  {                      WriteAttachmentMetadata(writer' hash' size' $"DummyAttachmentName{_dummyAttachmentNumber++}"' Empty);                  }              }              else              {                  WriteAttachmentMetadata(writer' hash' size' $"DummyAttachmentName{_dummyAttachmentNumber++}"' Empty);              }
Magic Number,Voron.Recovery,Recovery,C:\repos\ravendb_ravendb\tools\Voron.Recovery\Recovery.cs,WriteDummyDocumentForAttachment,The following statement contains a magic number: if (tag != null)              {                  //doc id | type 'd' or 'r' | name | hash | content type                  var tokens = tag.Split(TagSeparator);                  if (tokens.Length == 5)                  {                      WriteAttachmentMetadata(writer' hash' size' tokens[2]' tokens[4]);                  }                  else                  {                      WriteAttachmentMetadata(writer' hash' size' $"DummyAttachmentName{_dummyAttachmentNumber++}"' Empty);                  }              }              else              {                  WriteAttachmentMetadata(writer' hash' size' $"DummyAttachmentName{_dummyAttachmentNumber++}"' Empty);              }
