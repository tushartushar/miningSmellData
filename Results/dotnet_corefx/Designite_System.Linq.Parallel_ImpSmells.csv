Implementation smell,Namespace,Class,File,Method,Description
Long Method,System.Linq.Parallel,AsynchronousChannelMergeEnumerator<T>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Merging\AsynchronousChannelMergeEnumerator.cs,MoveNextSlowPath,The method has 141 lines of code.
Long Method,System.Linq.Parallel,HashJoinQueryOperatorEnumerator<TLeftInput;TLeftKey;TRightInput;THashKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\HashJoinQueryOperatorEnumerator.cs,MoveNext,The method has 141 lines of code.
Long Method,System.Linq.Parallel,TakeOrSkipWhileQueryOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\TakeOrSkipWhileQueryOperator.cs,MoveNext,The method has 125 lines of code.
Long Method,System.Linq.Parallel,SortHelper<TInputOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\Sorting.cs,MergeSortCooperatively,The method has 174 lines of code.
Complex Method,System.Linq.Parallel,HashRepartitionEnumerator<TInputOutput;THashKey;TIgnoreKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\HashRepartitionEnumerator.cs,MoveNext,Cyclomatic complexity of the method is 11
Complex Method,System.Linq.Parallel,OrderedHashRepartitionEnumerator<TInputOutput;THashKey;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\OrderedHashRepartitionEnumerator.cs,MoveNext,Cyclomatic complexity of the method is 11
Complex Method,System.Linq.Parallel,PartitionedDataSource<T>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\PartitionedDataSource.cs,InitializePartitions,Cyclomatic complexity of the method is 8
Complex Method,System.Linq.Parallel,OrderedExceptQueryOperatorEnumerator<TLeftKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ExceptQueryOperator.cs,MoveNext,Cyclomatic complexity of the method is 9
Complex Method,System.Linq.Parallel,HashJoinQueryOperatorEnumerator<TLeftInput;TLeftKey;TRightInput;THashKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\HashJoinQueryOperatorEnumerator.cs,MoveNext,Cyclomatic complexity of the method is 17
Complex Method,System.Linq.Parallel,OrderedIntersectQueryOperatorEnumerator<TLeftKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\IntersectQueryOperator.cs,MoveNext,Cyclomatic complexity of the method is 8
Complex Method,System.Linq.Parallel,UnionQueryOperatorEnumerator<TLeftKey;TRightKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\UnionQueryOperator.cs,MoveNext,Cyclomatic complexity of the method is 10
Complex Method,System.Linq.Parallel,OrderedUnionQueryOperatorEnumerator<TLeftKey;TRightKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\UnionQueryOperator.cs,MoveNext,Cyclomatic complexity of the method is 9
Complex Method,System.Linq.Parallel,LastQueryOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\LastQueryOperator.cs,MoveNext,Cyclomatic complexity of the method is 8
Complex Method,System.Linq.Parallel,IndexedSelectManyQueryOperatorEnumerator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,MoveNext,Cyclomatic complexity of the method is 8
Complex Method,System.Linq.Parallel,SelectManyQueryOperatorEnumerator<TLeftKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,MoveNext,Cyclomatic complexity of the method is 8
Complex Method,System.Linq.Parallel,TakeOrSkipWhileQueryOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\TakeOrSkipWhileQueryOperator.cs,MoveNext,Cyclomatic complexity of the method is 10
Complex Method,System.Linq.Parallel,SortHelper<TInputOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\Sorting.cs,MergeSortCooperatively,Cyclomatic complexity of the method is 10
Long Parameter List,System.Linq.Parallel,AsynchronousChannel<T>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Channels\AsynchronousChannel.cs,AsynchronousChannel,The method has 5 parameters. Parameters: index' capacity' chunkSize' cancellationToken' consumerEvent
Long Parameter List,System.Linq.Parallel,DefaultMergeHelper<TInputOutput;TIgnoreKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Merging\DefaultMergeHelper.cs,DefaultMergeHelper,The method has 6 parameters. Parameters: partitions' ignoreOutput' options' taskScheduler' cancellationState' queryId
Long Parameter List,System.Linq.Parallel,MergeExecutor<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Merging\MergeExecutor.cs,Execute,The method has 7 parameters. Parameters: partitions' ignoreOutput' options' taskScheduler' isOrdered' cancellationState' queryId
Long Parameter List,System.Linq.Parallel,OrderPreservingPipeliningMergeHelper<TOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Merging\OrderPreservingPipeliningMergeHelper.cs,OrderPreservingPipeliningMergeHelper,The method has 6 parameters. Parameters: partitions' taskScheduler' cancellationState' autoBuffered' queryId' keyComparer
Long Parameter List,System.Linq.Parallel,HashRepartitionEnumerator<TInputOutput;THashKey;TIgnoreKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\HashRepartitionEnumerator.cs,HashRepartitionEnumerator,The method has 8 parameters. Parameters: source' partitionCount' partitionIndex' keySelector' repartitionStream' barrier' valueExchangeMatrix' cancellationToken
Long Parameter List,System.Linq.Parallel,OrderedHashRepartitionEnumerator<TInputOutput;THashKey;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\OrderedHashRepartitionEnumerator.cs,OrderedHashRepartitionEnumerator,The method has 9 parameters. Parameters: source' partitionCount' partitionIndex' keySelector' repartitionStream' barrier' valueExchangeMatrix' keyExchangeMatrix' cancellationToken
Long Parameter List,System.Linq.Parallel,OrderedHashRepartitionStream<TInputOutput;THashKey;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\OrderedHashRepartitionStream.cs,OrderedHashRepartitionStream,The method has 5 parameters. Parameters: inputStream' hashKeySelector' hashKeyComparer' elementComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,ContiguousChunkLazyEnumerator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\PartitionedDataSource.cs,ContiguousChunkLazyEnumerator,The method has 5 parameters. Parameters: source' exceptionTracker' sourceSyncLock' currentIndex' degreeOfParallelism
Long Parameter List,System.Linq.Parallel,UnorderedHashRepartitionStream<TInputOutput;THashKey;TIgnoreKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\UnorderedHashRepartitionStream.cs,UnorderedHashRepartitionStream,The method has 5 parameters. Parameters: inputStream' keySelector' keyComparer' elementComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,AssociativeAggregationOperator<TInput;TIntermediate;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\AssociativeAggregationOperator.cs,AssociativeAggregationOperator,The method has 9 parameters. Parameters: child' seed' seedFactory' seedIsSpecified' intermediateReduce' finalReduce' resultSelector' throwIfEmpty' options
Long Parameter List,System.Linq.Parallel,BinaryQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\BinaryQueryOperator.cs,WrapPartitionedStream,The method has 5 parameters. Parameters: leftPartitionedStream' rightPartitionedStream' outputRecipient' preferStriping' settings
Long Parameter List,System.Linq.Parallel,BinaryQueryOperatorResults,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\BinaryQueryOperator.cs,BinaryQueryOperatorResults,The method has 5 parameters. Parameters: leftChildQueryResults' rightChildQueryResults' op' settings' preferStriping
Long Parameter List,System.Linq.Parallel,RightChildResultsRecipient<TLeftKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\BinaryQueryOperator.cs,RightChildResultsRecipient,The method has 5 parameters. Parameters: outputRecipient' op' leftPartitionedStream' preferStriping' settings
Long Parameter List,System.Linq.Parallel,ConcatQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ConcatQueryOperator.cs,WrapPartitionedStream,The method has 5 parameters. Parameters: leftStream' rightStream' outputRecipient' preferStriping' settings
Long Parameter List,System.Linq.Parallel,ConcatQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ConcatQueryOperator.cs,WrapHelper,The method has 5 parameters. Parameters: leftStreamInc' rightStream' outputRecipient' settings' preferStriping
Long Parameter List,System.Linq.Parallel,ConcatQueryOperatorResults,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ConcatQueryOperator.cs,NewResults,The method has 5 parameters. Parameters: leftChildQueryResults' rightChildQueryResults' op' settings' preferStriping
Long Parameter List,System.Linq.Parallel,ConcatQueryOperatorResults,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ConcatQueryOperator.cs,ConcatQueryOperatorResults,The method has 5 parameters. Parameters: leftChildQueryResults' rightChildQueryResults' concatOp' settings' preferStriping
Long Parameter List,System.Linq.Parallel,ExceptQueryOperator<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ExceptQueryOperator.cs,WrapPartitionedStream,The method has 5 parameters. Parameters: leftStream' rightStream' outputRecipient' preferStriping' settings
Long Parameter List,System.Linq.Parallel,OrderedExceptQueryOperatorEnumerator<TLeftKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ExceptQueryOperator.cs,OrderedExceptQueryOperatorEnumerator,The method has 5 parameters. Parameters: leftSource' rightSource' comparer' leftKeyComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,GroupJoinQueryOperator<TLeftInput;TRightInput;TKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\GroupJoinQueryOperator.cs,GroupJoinQueryOperator,The method has 6 parameters. Parameters: left' right' leftKeySelector' rightKeySelector' resultSelector' keyComparer
Long Parameter List,System.Linq.Parallel,GroupJoinQueryOperator<TLeftInput;TRightInput;TKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\GroupJoinQueryOperator.cs,WrapPartitionedStream,The method has 5 parameters. Parameters: leftStream' rightStream' outputRecipient' preferStriping' settings
Long Parameter List,System.Linq.Parallel,GroupJoinQueryOperator<TLeftInput;TRightInput;TKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\GroupJoinQueryOperator.cs,WrapPartitionedStreamHelper,The method has 5 parameters. Parameters: leftHashStream' rightPartitionedStream' outputRecipient' partitionCount' cancellationToken
Long Parameter List,System.Linq.Parallel,HashJoinQueryOperatorEnumerator<TLeftInput;TLeftKey;TRightInput;THashKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\HashJoinQueryOperatorEnumerator.cs,HashJoinQueryOperatorEnumerator,The method has 6 parameters. Parameters: leftSource' rightSource' singleResultSelector' groupResultSelector' keyComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,IntersectQueryOperator<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\IntersectQueryOperator.cs,WrapPartitionedStream,The method has 5 parameters. Parameters: leftPartitionedStream' rightPartitionedStream' outputRecipient' preferStriping' settings
Long Parameter List,System.Linq.Parallel,OrderedIntersectQueryOperatorEnumerator<TLeftKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\IntersectQueryOperator.cs,OrderedIntersectQueryOperatorEnumerator,The method has 5 parameters. Parameters: leftSource' rightSource' comparer' leftKeyComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,JoinQueryOperator<TLeftInput;TRightInput;TKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\JoinQueryOperator.cs,JoinQueryOperator,The method has 6 parameters. Parameters: left' right' leftKeySelector' rightKeySelector' resultSelector' keyComparer
Long Parameter List,System.Linq.Parallel,JoinQueryOperator<TLeftInput;TRightInput;TKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\JoinQueryOperator.cs,WrapPartitionedStream,The method has 5 parameters. Parameters: leftStream' rightStream' outputRecipient' preferStriping' settings
Long Parameter List,System.Linq.Parallel,UnionQueryOperator<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\UnionQueryOperator.cs,WrapPartitionedStream,The method has 5 parameters. Parameters: leftStream' rightStream' outputRecipient' preferStriping' settings
Long Parameter List,System.Linq.Parallel,UnionQueryOperator<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\UnionQueryOperator.cs,WrapPartitionedStreamFixedLeftType,The method has 5 parameters. Parameters: leftHashStream' rightStream' outputRecipient' partitionCount' cancellationToken
Long Parameter List,System.Linq.Parallel,UnionQueryOperator<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\UnionQueryOperator.cs,WrapPartitionedStreamFixedBothTypes,The method has 5 parameters. Parameters: leftHashStream' rightHashStream' outputRecipient' partitionCount' cancellationToken
Long Parameter List,System.Linq.Parallel,OrderedUnionQueryOperatorEnumerator<TLeftKey;TRightKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\UnionQueryOperator.cs,OrderedUnionQueryOperatorEnumerator,The method has 7 parameters. Parameters: leftSource' rightSource' leftOrdered' rightOrdered' comparer' keyComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,ZipQueryOperatorResults,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ZipQueryOperator.cs,ZipQueryOperatorResults,The method has 5 parameters. Parameters: leftChildResults' rightChildResults' resultSelector' partitionCount' preferStriping
Long Parameter List,System.Linq.Parallel,CountAggregationOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\CountAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,DecimalAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\DecimalAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,DecimalMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\DecimalMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,DecimalSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\DecimalSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,DoubleAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\DoubleAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,DoubleMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\DoubleMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,DoubleSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\DoubleSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,FloatAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\FloatAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,FloatMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\FloatMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,FloatSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\FloatSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,InlinedAggregationOperator<TSource;TIntermediate;TResult>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\InlinedAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,IntAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\IntAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,IntMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\IntMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,IntSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\IntSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,LongAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\LongAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,LongCountAggregationOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\LongCountAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,LongMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\LongMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,LongSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\LongSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableDecimalAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableDecimalAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableDecimalMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableDecimalMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableDecimalSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableDecimalSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableDoubleAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableDoubleAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableDoubleMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableDoubleMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableDoubleSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableDoubleSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableFloatAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableFloatAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableFloatMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableFloatMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableFloatSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableFloatSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableIntAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableIntAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableIntMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableIntMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableIntSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableIntSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableLongAverageAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableLongAverageAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableLongMinMaxAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableLongMinMaxAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,NullableLongSumAggregationOperator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\NullableLongSumAggregationOperator.cs,CreateEnumerator,The method has 5 parameters. Parameters: index' count' source' sharedData' cancellationToken
Long Parameter List,System.Linq.Parallel,PartitionedStreamMerger<TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\PartitionedStreamMerger.cs,PartitionedStreamMerger,The method has 6 parameters. Parameters: forEffectMerge' mergeOptions' taskScheduler' outputOrdered' cancellationState' queryId
Long Parameter List,System.Linq.Parallel,QueryOperator<TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QueryOperator.cs,ExecuteAndCollectResults,The method has 5 parameters. Parameters: openedChild' partitionCount' outputOrdered' useStriping' settings
Long Parameter List,System.Linq.Parallel,QuerySettings,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QuerySettings.cs,QuerySettings,The method has 5 parameters. Parameters: taskScheduler' degreeOfParallelism' externalCancellationToken' executionMode' mergeOptions
Long Parameter List,System.Linq.Parallel,AnyAllSearchOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\AnyAllSearchOperator.cs,AnyAllSearchOperatorEnumerator,The method has 6 parameters. Parameters: source' qualification' predicate' partitionIndex' resultFoundFlag' cancellationToken
Long Parameter List,System.Linq.Parallel,ContainsSearchOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ContainsSearchOperator.cs,ContainsSearchOperatorEnumerator,The method has 6 parameters. Parameters: source' searchValue' comparer' partitionIndex' resultFoundFlag' cancellationToken
Long Parameter List,System.Linq.Parallel,DefaultIfEmptyQueryOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\DefaultIfEmptyQueryOperator.cs,DefaultIfEmptyQueryOperatorEnumerator,The method has 7 parameters. Parameters: source' defaultValue' partitionIndex' partitionCount' sharedEmptyCount' sharedLatch' cancelToken
Long Parameter List,System.Linq.Parallel,FirstQueryOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\FirstQueryOperator.cs,FirstQueryOperatorEnumerator,The method has 7 parameters. Parameters: source' predicate' operatorState' sharedBarrier' cancellationToken' keyComparer' partitionId
Long Parameter List,System.Linq.Parallel,OrderedGroupByQueryOperatorEnumerator<TSource;TGroupKey;TElement;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\GroupByQueryOperator.cs,OrderedGroupByQueryOperatorEnumerator,The method has 5 parameters. Parameters: source' keySelector' keyComparer' orderComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,OrderedGroupByIdentityQueryOperatorEnumerator<TSource;TGroupKey;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\GroupByQueryOperator.cs,OrderedGroupByIdentityQueryOperatorEnumerator,The method has 5 parameters. Parameters: source' keySelector' keyComparer' orderComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,OrderedGroupByElementSelectorQueryOperatorEnumerator<TSource;TGroupKey;TElement;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\GroupByQueryOperator.cs,OrderedGroupByElementSelectorQueryOperatorEnumerator,The method has 6 parameters. Parameters: source' keySelector' elementSelector' keyComparer' orderComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,LastQueryOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\LastQueryOperator.cs,LastQueryOperatorEnumerator,The method has 7 parameters. Parameters: source' predicate' operatorState' sharedBarrier' cancelToken' keyComparer' partitionId
Long Parameter List,System.Linq.Parallel,TakeOrSkipQueryOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\TakeOrSkipQueryOperator.cs,TakeOrSkipQueryOperatorEnumerator,The method has 6 parameters. Parameters: source' take' sharedIndices' sharedBarrier' cancellationToken' keyComparer
Long Parameter List,System.Linq.Parallel,TakeOrSkipWhileQueryOperatorEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\TakeOrSkipWhileQueryOperator.cs,TakeOrSkipWhileQueryOperatorEnumerator,The method has 8 parameters. Parameters: source' predicate' indexedPredicate' take' operatorState' sharedBarrier' cancelToken' keyComparer
Long Parameter List,System.Linq.Parallel,OrderPreservingPipeliningSpoolingTask<TOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\OrderPreservingPipeliningSpoolingTask.cs,OrderPreservingPipeliningSpoolingTask,The method has 9 parameters. Parameters: partition' taskGroupState' consumerWaiting' producerWaiting' producerDone' partitionIndex' buffers' bufferLock' autoBuffered
Long Parameter List,System.Linq.Parallel,OrderPreservingPipeliningSpoolingTask<TOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\OrderPreservingPipeliningSpoolingTask.cs,Spool,The method has 9 parameters. Parameters: groupState' partitions' consumerWaiting' producerWaiting' producerDone' buffers' bufferLocks' taskScheduler' autoBuffered
Long Parameter List,System.Linq.Parallel,ExchangeUtilities,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\ExchangeUtilities.cs,HashRepartition,The method has 5 parameters. Parameters: source' keySelector' keyComparer' elementComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,ExchangeUtilities,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\ExchangeUtilities.cs,HashRepartitionOrdered,The method has 5 parameters. Parameters: source' keySelector' keyComparer' elementComparer' cancellationToken
Long Parameter List,System.Linq.Parallel,SortHelper<TInputOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\Sorting.cs,SortHelper,The method has 10 parameters. Parameters: source' partitionCount' partitionIndex' groupState' sharedIndices' indexState' keyComparer' sharedkeys' sharedValues' sharedBarriers
Long Parameter List,System.Linq.Parallel,SortHelper<TInputOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\Sorting.cs,QuickSort,The method has 5 parameters. Parameters: left' right' keys' indices' cancelToken
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Join,The method has 5 parameters. Parameters: outer' inner' outerKeySelector' innerKeySelector' resultSelector
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Join,The method has 5 parameters. Parameters: outer' inner' outerKeySelector' innerKeySelector' resultSelector
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Join,The method has 6 parameters. Parameters: outer' inner' outerKeySelector' innerKeySelector' resultSelector' comparer
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Join,The method has 6 parameters. Parameters: outer' inner' outerKeySelector' innerKeySelector' resultSelector' comparer
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,GroupJoin,The method has 5 parameters. Parameters: outer' inner' outerKeySelector' innerKeySelector' resultSelector
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,GroupJoin,The method has 5 parameters. Parameters: outer' inner' outerKeySelector' innerKeySelector' resultSelector
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,GroupJoin,The method has 6 parameters. Parameters: outer' inner' outerKeySelector' innerKeySelector' resultSelector' comparer
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,GroupJoin,The method has 6 parameters. Parameters: outer' inner' outerKeySelector' innerKeySelector' resultSelector' comparer
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,GroupBy,The method has 5 parameters. Parameters: source' keySelector' elementSelector' resultSelector' comparer
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,PerformAggregation,The method has 6 parameters. Parameters: source' reduce' seed' seedIsSpecified' throwIfEmpty' options
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Aggregate,The method has 5 parameters. Parameters: source' seed' updateAccumulatorFunc' combineAccumulatorsFunc' resultSelector
Long Parameter List,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Aggregate,The method has 5 parameters. Parameters: source' seedFactory' updateAccumulatorFunc' combineAccumulatorsFunc' resultSelector
Long Identifier,System.Linq.Parallel,QueryOpeningEnumerator<TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QueryOpeningEnumerator.cs,,The length of the parameter _topLevelCancellationTokenSource is 32.
Long Identifier,System.Linq.Parallel,QuerySettings,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QuerySettings.cs,WithPerExecutionSettings,The length of the parameter topLevelCancellationTokenSource is 31.
Long Identifier,System.Linq.Parallel,ForAllOperator<TInput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ForAllOperator.cs,RunSynchronously,The length of the parameter dummyInternalCancellationTokenSource is 36.
Long Identifier,System.Linq.Parallel,CancellationState,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\CancellationState.cs,,The length of the parameter InternalCancellationTokenSource is 31.
Long Identifier,System.Linq.Parallel,QueryTask,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\QueryTask.cs,,The length of the parameter s_runTaskSynchronouslyDelegate is 30.
Long Identifier,System.Linq.Parallel,QueryTaskGroupState,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\QueryTaskGroupState.cs,QueryEnd,The length of the parameter allOCEsOnTrackedExternalCancellationToken is 41.
Long Identifier,System.Linq.Parallel,Scheduling,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\Scheduling.cs,,The length of the parameter DEFAULT_BOUNDED_BUFFER_CAPACITY is 31.
Long Statement,System.Linq.Parallel,MergeExecutor<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Merging\MergeExecutor.cs,Execute,The length of the statement  "            Debug.Assert(!ignoreOutput || options == ParallelMergeOptions.FullyBuffered' "Pipelining with no output is not supported."); " is 124.
Long Statement,System.Linq.Parallel,MergeExecutor<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Merging\MergeExecutor.cs,Execute,The length of the statement  "                if (options != ParallelMergeOptions.FullyBuffered && !partitions.OrdinalIndexState.IsWorseThan(OrdinalIndexState.Increasing)) " is 125.
Long Statement,System.Linq.Parallel,MergeExecutor<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Merging\MergeExecutor.cs,Execute,The length of the statement  "                    mergeExecutor._mergeHelper = new OrderPreservingMergeHelper<TInputOutput' TKey>(partitions' taskScheduler' cancellationState' queryId); " is 135.
Long Statement,System.Linq.Parallel,MergeExecutor<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Merging\MergeExecutor.cs,Execute,The length of the statement  "                mergeExecutor._mergeHelper = new DefaultMergeHelper<TInputOutput' TKey>(partitions' ignoreOutput' options' taskScheduler' cancellationState' queryId); " is 150.
Long Statement,System.Linq.Parallel,MergeExecutor<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Merging\MergeExecutor.cs,MakeAsynchronousChannels,The length of the statement  "            TraceHelpers.TraceInfo("MergeExecutor::MakeChannels: setting up {0} async channels in prep for pipeline"' partitionCount); " is 122.
Long Statement,System.Linq.Parallel,OrderedHashRepartitionEnumerator<TInputOutput;THashKey;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\OrderedHashRepartitionEnumerator.cs,EnumerateAndRedistributeElements,The length of the statement  "            ListChunk<Pair<TInputOutput' THashKey>>[] privateBuffers = new ListChunk<Pair<TInputOutput' THashKey>>[_partitionCount]; " is 120.
Long Statement,System.Linq.Parallel,ArrayIndexRangeEnumerator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\PartitionedDataSource.cs,MoveNextSlowPath,The length of the statement  "                        + (_partitionIndex < biggerChunkCount ? _partitionIndex : biggerChunkCount); // + the number of "bigger" chunks before this chunk " is 129.
Long Statement,System.Linq.Parallel,ListIndexRangeEnumerator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\PartitionedDataSource.cs,MoveNextSlowPath,The length of the statement  "                        + (_partitionIndex < biggerChunkCount ? _partitionIndex : biggerChunkCount); // + the number of "bigger" chunks before this chunk " is 129.
Long Statement,System.Linq.Parallel,AssociativeAggregationOperator<TInput;TIntermediate;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\AssociativeAggregationOperator.cs,WrapPartitionedStream,The length of the statement  "                outputStream[i] = new AssociativeAggregationOperatorEnumerator<TKey>(inputStream[i]' this' i' settings.CancellationState.MergedCancellationToken); " is 146.
Long Statement,System.Linq.Parallel,BinaryQueryOperatorResults,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\BinaryQueryOperator.cs,GivePartitionedStream,The length of the statement  "                    PartitionedStream<TOutput' int> result = ExchangeUtilities.PartitionDataSource(this' _settings.DegreeOfParallelism.Value' _preferStriping); " is 139.
Long Statement,System.Linq.Parallel,BinaryQueryOperatorResults,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\BinaryQueryOperator.cs,GivePartitionedStream,The length of the statement  "                    _leftChildQueryResults.GivePartitionedStream(new LeftChildResultsRecipient(recipient' this' _preferStriping' _settings)); " is 121.
Long Statement,System.Linq.Parallel,RightChildResultsRecipient<TLeftKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\BinaryQueryOperator.cs,Receive,The length of the statement  "                    _op.WrapPartitionedStream(_leftPartitionedStream' rightPartitionedStream' _outputRecipient' _preferStriping' _settings); " is 120.
Long Statement,System.Linq.Parallel,ConcatQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ConcatQueryOperator.cs,WrapHelper2,The length of the statement  "            var outputStream = new PartitionedStream<TSource' ConcatKey<TLeftKey' TRightKey>>(partitionCount' comparer' OrdinalIndexState); " is 127.
Long Statement,System.Linq.Parallel,OrderedExceptQueryOperatorEnumerator<TLeftKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ExceptQueryOperator.cs,MoveNext,The length of the statement  "                        if (!leftLookup.TryGetValue(wrappedLeftElement' out oldEntry) || _leftKeyComparer.Compare(leftKey' oldEntry.Second) < 0) " is 120.
Long Statement,System.Linq.Parallel,GroupJoinQueryOperator<TLeftInput;TRightInput;TKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\GroupJoinQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                    ExchangeUtilities.HashRepartitionOrdered(leftStream' _leftKeySelector' _keyComparer' null' settings.CancellationState.MergedCancellationToken)' " is 143.
Long Statement,System.Linq.Parallel,GroupJoinQueryOperator<TLeftInput;TRightInput;TKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\GroupJoinQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                    ExchangeUtilities.HashRepartition(leftStream' _leftKeySelector' _keyComparer' null' settings.CancellationState.MergedCancellationToken)' " is 136.
Long Statement,System.Linq.Parallel,HashJoinQueryOperatorEnumerator<TLeftInput;TLeftKey;TRightInput;THashKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\HashJoinQueryOperatorEnumerator.cs,MoveNext,The length of the statement  "            Debug.Assert(0 <= mutables._currentRightMatchesIndex && mutables._currentRightMatchesIndex < mutables._currentRightMatches.Count); " is 130.
Long Statement,System.Linq.Parallel,JoinQueryOperator<TLeftInput;TRightInput;TKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\JoinQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                    ExchangeUtilities.HashRepartitionOrdered(leftStream' _leftKeySelector' _keyComparer' null' settings.CancellationState.MergedCancellationToken)' " is 143.
Long Statement,System.Linq.Parallel,JoinQueryOperator<TLeftInput;TRightInput;TKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\JoinQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                    ExchangeUtilities.HashRepartition(leftStream' _leftKeySelector' _keyComparer' null' settings.CancellationState.MergedCancellationToken)' " is 136.
Long Statement,System.Linq.Parallel,UnionQueryOperator<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\UnionQueryOperator.cs,WrapPartitionedStreamFixedBothTypes,The length of the statement  "                    new PartitionedStream<TInputOutput' ConcatKey<TLeftKey' TRightKey>>(partitionCount' compoundKeyComparer' OrdinalIndexState.Shuffled); " is 133.
Long Statement,System.Linq.Parallel,UnionQueryOperatorEnumerator<TLeftKey;TRightKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\UnionQueryOperator.cs,MoveNext,The length of the statement  "                    Pair<TInputOutput' NoKeyMemoizationRequired> currentLeftElement = default(Pair<TInputOutput' NoKeyMemoizationRequired>); " is 120.
Long Statement,System.Linq.Parallel,UnionQueryOperatorEnumerator<TLeftKey;TRightKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\UnionQueryOperator.cs,MoveNext,The length of the statement  "                    Pair<TInputOutput' NoKeyMemoizationRequired> currentRightElement = default(Pair<TInputOutput' NoKeyMemoizationRequired>); " is 121.
Long Statement,System.Linq.Parallel,ZipQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ZipQueryOperator.cs,Open,The length of the statement  "            return new ZipQueryOperatorResults(leftChildResults' rightChildResults' _resultSelector' partitionCount' preferStriping); " is 121.
Long Statement,System.Linq.Parallel,ZipQueryOperatorResults,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\ZipQueryOperator.cs,GivePartitionedStream,The length of the statement  "                PartitionedStream<TOutput' int> partitionedStream = ExchangeUtilities.PartitionDataSource(this' _partitionCount' _preferStriping); " is 130.
Long Statement,System.Linq.Parallel,InlinedAggregationOperator<TSource;TIntermediate;TResult>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Inlined\InlinedAggregationOperator.cs,WrapPartitionedStream,The length of the statement  "                outputStream[i] = CreateEnumerator<TKey>(i' partitionCount' inputStream[i]' null' settings.CancellationState.MergedCancellationToken); " is 134.
Long Statement,System.Linq.Parallel,QueryOpeningEnumerator<TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QueryOpeningEnumerator.cs,MoveNext,The length of the statement  "            //Best practice is that Dispose() should only be called by the owning thread' hence this cannot occur in correct usage scenarios. " is 129.
Long Statement,System.Linq.Parallel,QueryOperator<TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QueryOperator.cs,GetOpenedEnumerator,The length of the statement  "            PartitionedStreamMerger<TOutput> merger = new PartitionedStreamMerger<TOutput>(forEffect' mergeOptions.GetValueOrDefault()' " is 123.
Long Statement,System.Linq.Parallel,QueryOperator<TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QueryOperator.cs,GetOpenedEnumerator,The length of the statement  "            queryResults.GivePartitionedStream(merger); // hook up the data flow between the operator-executors' starting from the merger. " is 126.
Long Statement,System.Linq.Parallel,QueryOperator<TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QueryOperator.cs,ExecuteAndGetResultsAsArray,The length of the statement  "                    IEnumerable<TOutput> opSequentialWithCancelChecks = CancellableEnumerable.Wrap(opSequential' querySettings.CancellationState.ExternalCancellationToken); " is 152.
Long Statement,System.Linq.Parallel,QuerySettings,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QuerySettings.cs,Merge,The length of the statement  "            if (this.CancellationState.ExternalCancellationToken.CanBeCanceled && settings2.CancellationState.ExternalCancellationToken.CanBeCanceled) " is 138.
Long Statement,System.Linq.Parallel,QuerySettings,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QuerySettings.cs,Merge,The length of the statement  "            CancellationToken externalCancellationToken = (this.CancellationState.ExternalCancellationToken.CanBeCanceled) ? this.CancellationState.ExternalCancellationToken : settings2.CancellationState.ExternalCancellationToken; " is 218.
Long Statement,System.Linq.Parallel,QuerySettings,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QuerySettings.cs,WithPerExecutionSettings,The length of the statement  "            QuerySettings settings = new QuerySettings(TaskScheduler' DegreeOfParallelism' CancellationState.ExternalCancellationToken' ExecutionMode' MergeOptions); " is 153.
Long Statement,System.Linq.Parallel,QuerySettings,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QuerySettings.cs,WithPerExecutionSettings,The length of the statement  "            Debug.Assert(topLevelCancellationTokenSource != null' "There should always be a top-level cancellation signal specified."); " is 123.
Long Statement,System.Linq.Parallel,QuerySettings,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\QuerySettings.cs,WithPerExecutionSettings,The length of the statement  "                   CancellationTokenSource.CreateLinkedTokenSource(settings.CancellationState.InternalCancellationTokenSource.Token' settings.CancellationState.ExternalCancellationToken); " is 168.
Long Statement,System.Linq.Parallel,UnaryQueryOperatorResults,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\UnaryQueryOperator.cs,GivePartitionedStream,The length of the statement  "                    PartitionedStream<TOutput' int> result = ExchangeUtilities.PartitionDataSource(this' _settings.DegreeOfParallelism.Value' _preferStriping); " is 139.
Long Statement,System.Linq.Parallel,AnyAllSearchOperator<TInput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\AnyAllSearchOperator.cs,WrapPartitionedStream,The length of the statement  "                outputStream[i] = new AnyAllSearchOperatorEnumerator<TKey>(inputStream[i]' _qualification' _predicate' i' resultFoundFlag' " is 122.
Long Statement,System.Linq.Parallel,ContainsSearchOperator<TInput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ContainsSearchOperator.cs,WrapPartitionedStream,The length of the statement  "            PartitionedStream<bool' int> outputStream = new PartitionedStream<bool' int>(partitionCount' Util.GetDefaultComparer<int>()' OrdinalIndexState.Correct); " is 152.
Long Statement,System.Linq.Parallel,ContainsSearchOperator<TInput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ContainsSearchOperator.cs,WrapPartitionedStream,The length of the statement  "                outputStream[i] = new ContainsSearchOperatorEnumerator<TKey>(inputStream[i]' _searchValue' _comparer' i' resultFoundFlag' " is 121.
Long Statement,System.Linq.Parallel,DefaultIfEmptyQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\DefaultIfEmptyQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                    inputStream[i]' _defaultValue' i' partitionCount' sharedEmptyCount' sharedLatch' settings.CancellationState.MergedCancellationToken); " is 133.
Long Statement,System.Linq.Parallel,ElementAtQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ElementAtQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                intKeyStream = ExecuteAndCollectResults(inputStream' partitionCount' Child.OutputOrdered' preferStriping' settings).GetPartitionedStream(); " is 139.
Long Statement,System.Linq.Parallel,ElementAtQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ElementAtQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                outputStream[i] = new ElementAtQueryOperatorEnumerator(intKeyStream[i]' _index' resultFoundFlag' settings.CancellationState.MergedCancellationToken); " is 149.
Long Statement,System.Linq.Parallel,ElementAtQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ElementAtQueryOperator.cs,Aggregate,The length of the statement  "            // If we were to insert a premature merge before this ElementAt' and we are executing in conservative mode' run the whole query " is 127.
Long Statement,System.Linq.Parallel,ElementAtQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ElementAtQueryOperator.cs,Aggregate,The length of the statement  "            if (LimitsParallelism && SpecifiedQuerySettings.WithDefaults().ExecutionMode.Value != ParallelExecutionMode.ForceParallelism) " is 125.
Long Statement,System.Linq.Parallel,ElementAtQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ElementAtQueryOperator.cs,Aggregate,The length of the statement  "                    IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' cancelState.ExternalCancellationToken); " is 130.
Long Statement,System.Linq.Parallel,ElementAtQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ElementAtQueryOperator.cs,Aggregate,The length of the statement  "                    IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' cancelState.ExternalCancellationToken); " is 130.
Long Statement,System.Linq.Parallel,FirstQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\FirstQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                ListQueryResults<TSource> listResults = ExecuteAndCollectResults(inputStream' inputStream.PartitionCount' Child.OutputOrdered' preferStriping' settings); " is 153.
Long Statement,System.Linq.Parallel,ForAllEnumerator<TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ForAllOperator.cs,MoveNext,The length of the statement  "                // We only need to throw a simple exception here.. marshalling logic handled via QueryTaskGroupState.QueryEnd (called by ForAllSpoolingTask) " is 140.
Long Statement,System.Linq.Parallel,GroupByQueryOperator<TSource;TGroupKey;TElement>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\GroupByQueryOperator.cs,WrapPartitionedStreamHelper,The length of the statement  "                new PartitionedStream<IGrouping<TGroupKey' TElement>' TKey>(partitionCount' hashStream.KeyComparer' OrdinalIndexState.Shuffled); " is 128.
Long Statement,System.Linq.Parallel,GroupByQueryOperator<TSource;TGroupKey;TElement>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\GroupByQueryOperator.cs,WrapPartitionedStreamHelperOrdered,The length of the statement  "                new PartitionedStream<IGrouping<TGroupKey' TElement>' TKey>(partitionCount' hashStream.KeyComparer' OrdinalIndexState.Shuffled); " is 128.
Long Statement,System.Linq.Parallel,IndexedWhereQueryOperator<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\IndexedWhereQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                ListQueryResults<TInputOutput> listResults = ExecuteAndCollectResults(inputStream' partitionCount' Child.OutputOrdered' preferStriping' settings); " is 146.
Long Statement,System.Linq.Parallel,IndexedWhereQueryOperator<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\IndexedWhereQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                outputStream[i] = new IndexedWhereQueryOperatorEnumerator(inputStreamInt[i]' _predicate' settings.CancellationState.MergedCancellationToken); " is 141.
Long Statement,System.Linq.Parallel,LastQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\LastQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                    ExecuteAndCollectResults(inputStream' inputStream.PartitionCount' Child.OutputOrdered' preferStriping' settings).GetPartitionedStream(); " is 136.
Long Statement,System.Linq.Parallel,ReverseQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ReverseQueryOperator.cs,WrapPartitionedStream,The length of the statement  "            Debug.Assert(Child.OrdinalIndexState != OrdinalIndexState.Indexable' "Don't take this code path if the child is indexable."); " is 125.
Long Statement,System.Linq.Parallel,ReverseQueryOperator<TSource>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\ReverseQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                outputStream[i] = new ReverseQueryOperatorEnumerator<TKey>(inputStream[i]' settings.CancellationState.MergedCancellationToken); " is 127.
Long Statement,System.Linq.Parallel,SelectManyQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                        QueryOperator<TLeftInput>.ExecuteAndCollectResults(inputStream' partitionCount' OutputOrdered' preferStriping' settings); " is 121.
Long Statement,System.Linq.Parallel,SelectManyQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                    QueryOperator<TLeftInput>.ExecuteAndCollectResults(inputStream' partitionCount' OutputOrdered' preferStriping' settings) " is 120.
Long Statement,System.Linq.Parallel,SelectManyQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,WrapPartitionedStreamNotIndexed,The length of the statement  "                outputStream[i] = new SelectManyQueryOperatorEnumerator<TLeftKey>(inputStream[i]' this' settings.CancellationState.MergedCancellationToken); " is 140.
Long Statement,System.Linq.Parallel,SelectManyQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,WrapPartitionedStreamIndexed,The length of the statement  "            var outputStream = new PartitionedStream<TOutput' Pair<int' int>>(inputStream.PartitionCount' keyComparer' OrdinalIndexState); " is 126.
Long Statement,System.Linq.Parallel,SelectManyQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,WrapPartitionedStreamIndexed,The length of the statement  "                outputStream[i] = new IndexedSelectManyQueryOperatorEnumerator(inputStream[i]' this' settings.CancellationState.MergedCancellationToken); " is 137.
Long Statement,System.Linq.Parallel,SelectManyQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,AsSequentialQuery,The length of the statement  "                    return CancellableEnumerable.Wrap(Child.AsSequentialQuery(token)' token).SelectMany(_rightChildSelector' _resultSelector); " is 122.
Long Statement,System.Linq.Parallel,SelectManyQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,AsSequentialQuery,The length of the statement  "                return (IEnumerable<TOutput>)CancellableEnumerable.Wrap(Child.AsSequentialQuery(token)' token).SelectMany(_rightChildSelector); " is 127.
Long Statement,System.Linq.Parallel,SelectManyQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,AsSequentialQuery,The length of the statement  "                    return CancellableEnumerable.Wrap(Child.AsSequentialQuery(token)' token).SelectMany(_indexedRightChildSelector' _resultSelector); " is 129.
Long Statement,System.Linq.Parallel,SelectManyQueryOperator<TLeftInput;TRightInput;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\SelectManyQueryOperator.cs,AsSequentialQuery,The length of the statement  "                return (IEnumerable<TOutput>)CancellableEnumerable.Wrap(Child.AsSequentialQuery(token)' token).SelectMany(_indexedRightChildSelector); " is 134.
Long Statement,System.Linq.Parallel,TakeOrSkipQueryOperator<TResult>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\TakeOrSkipQueryOperator.cs,WrapPartitionedStream,The length of the statement  "            Debug.Assert(Child.OrdinalIndexState != OrdinalIndexState.Indexable' "Don't take this code path if the child is indexable."); " is 125.
Long Statement,System.Linq.Parallel,TakeOrSkipQueryOperator<TResult>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\TakeOrSkipQueryOperator.cs,WrapHelper,The length of the statement  "            FixedMaxHeap<TKey> sharedIndices = new FixedMaxHeap<TKey>(_count' inputStream.KeyComparer); // an array used to track the sequence of indices leading up to the Nth index " is 169.
Long Statement,System.Linq.Parallel,TakeOrSkipWhileQueryOperator<TResult>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\TakeOrSkipWhileQueryOperator.cs,WrapPartitionedStream,The length of the statement  "                ListQueryResults<TResult> results = ExecuteAndCollectResults(inputStream' inputStream.PartitionCount' Child.OutputOrdered' preferStriping' settings); " is 149.
Long Statement,System.Linq.Parallel,QueryTask,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\QueryTask.cs,RunSynchronously,The length of the statement  "            Debug.Assert(taskScheduler == TaskScheduler.Default' "PLINQ queries can currently execute only on the default scheduler."); " is 123.
Long Statement,System.Linq.Parallel,QueryTask,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\QueryTask.cs,RunAsynchronously,The length of the statement  "            Debug.Assert(taskScheduler == TaskScheduler.Default' "PLINQ queries can currently execute only on the default scheduler."); " is 123.
Long Statement,System.Linq.Parallel,QueryTask,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\QueryTask.cs,RunAsynchronously,The length of the statement  "            return Task.Factory.StartNew(s_baseWorkDelegate' this' new CancellationToken()' TaskCreationOptions.AttachedToParent | TaskCreationOptions.PreferFairness' taskScheduler); " is 170.
Long Statement,System.Linq.Parallel,QueryTaskGroupState,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\QueryTaskGroupState.cs,QueryEnd,The length of the statement  "                // Case #1: Wait produced an exception that is not OCE(ct)' or an AggregateException which is not full of OCE(ct) ==>  We rethrow. " is 130.
Long Statement,System.Linq.Parallel,QueryTaskGroupState,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\QueryTaskGroupState.cs,QueryEnd,The length of the statement  "                // Case #3a: We are servicing a call to Dispose() (and possibly also external cancellation has been requested).. simply return. " is 127.
Long Statement,System.Linq.Parallel,QueryTaskGroupState,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\QueryTaskGroupState.cs,QueryEnd,The length of the statement  "                // Case #3b: The enumerator has already been disposed (and possibly also external cancellation was requested).  Throw an ODE. " is 125.
Long Statement,System.Linq.Parallel,SpoolingTask,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\SpoolingTask.cs,SpoolForAll,The length of the statement  "                    QueryTask syncTask = new ForAllSpoolingTask<TInputOutput' TIgnoreKey>(maxToRunInParallel' groupState' partitions[maxToRunInParallel]); " is 134.
Long Statement,System.Linq.Parallel,Set<TElement>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Helpers.cs,Add,The length of the statement  "            Debug.Assert(!_haveRemoved' "This class is optimised for never calling Add after Remove. If your changes need to do so' undo that optimization."); " is 146.
Long Statement,System.Linq.Parallel,ExchangeUtilities,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\ExchangeUtilities.cs,HashRepartition,The length of the statement  "            TraceHelpers.TraceInfo("PartitionStream<..>.HashRepartitionStream(..):: creating **RE**partitioned stream for nested operator"); " is 128.
Long Statement,System.Linq.Parallel,ExchangeUtilities,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\ExchangeUtilities.cs,HashRepartition,The length of the statement  "            return new UnorderedHashRepartitionStream<TElement' THashKey' TIgnoreKey>(source' keySelector' keyComparer' elementComparer' cancellationToken); " is 144.
Long Statement,System.Linq.Parallel,ExchangeUtilities,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\ExchangeUtilities.cs,HashRepartitionOrdered,The length of the statement  "            TraceHelpers.TraceInfo("PartitionStream<..>.HashRepartitionStream(..):: creating **RE**partitioned stream for nested operator"); " is 128.
Long Statement,System.Linq.Parallel,ExchangeUtilities,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\ExchangeUtilities.cs,HashRepartitionOrdered,The length of the statement  "            return new OrderedHashRepartitionStream<TElement' THashKey' TOrderKey>(source' keySelector' keyComparer' elementComparer' cancellationToken); " is 141.
Long Statement,System.Linq,AggregationMinMaxHelpers<T>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Enumerables\AggregationMinMaxHelpers.cs,Reduce,The length of the statement  "                                                                        true' intermediateReduce' finalReduce' resultSelector' default(T) != null' QueryAggregationOptions.AssociativeCommutative); " is 123.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Range,The length of the statement  "            if (count < 0 || (count > 0 && Int32.MaxValue - (count - 1) < start)) throw new ArgumentOutOfRangeException(nameof(count)); " is 123.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,GroupBy,The length of the statement  "                .Select<IGrouping<TKey' TSource>' TResult>(delegate (IGrouping<TKey' TSource> grouping) { return resultSelector(grouping.Key' grouping); }); " is 140.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,GroupBy,The length of the statement  "                .Select<IGrouping<TKey' TElement>' TResult>(delegate (IGrouping<TKey' TElement> grouping) { return resultSelector(grouping.Key' grouping); }); " is 142.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,GroupBy,The length of the statement  "                .Select<IGrouping<TKey' TElement>' TResult>(delegate (IGrouping<TKey' TElement> grouping) { return resultSelector(grouping.Key' grouping); }); " is 142.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Aggregate,The length of the statement  "            if ((~(QueryAggregationOptions.Associative | QueryAggregationOptions.Commutative) & options) != 0) throw new ArgumentOutOfRangeException(nameof(options)); " is 154.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Aggregate,The length of the statement  "            if ((~(QueryAggregationOptions.Associative | QueryAggregationOptions.Commutative) & options) != 0) throw new ArgumentOutOfRangeException(nameof(options)); " is 154.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,ToDictionary,The length of the statement  "            IEnumerator<TSource> input = (op == null) ? source.GetEnumerator() : op.GetEnumerator(ParallelMergeOptions.FullyBuffered' true); " is 128.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,ToDictionary,The length of the statement  "            IEnumerator<TSource> input = (op == null) ? source.GetEnumerator() : op.GetEnumerator(ParallelMergeOptions.FullyBuffered' true); " is 128.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,ToLookup,The length of the statement  "            IEnumerator<IGrouping<TKey' TSource>> input = (op == null) ? groupings.GetEnumerator() : op.GetEnumerator(ParallelMergeOptions.FullyBuffered); " is 142.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,ToLookup,The length of the statement  "            IEnumerator<IGrouping<TKey' TElement>> input = (op == null) ? groupings.GetEnumerator() : op.GetEnumerator(ParallelMergeOptions.FullyBuffered); " is 143.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,First,The length of the statement  "                IEnumerable<TSource> childAsSequential = queryOp.Child.AsSequentialQuery(settings.CancellationState.ExternalCancellationToken); " is 127.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,First,The length of the statement  "                IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' settings.CancellationState.ExternalCancellationToken); " is 145.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,First,The length of the statement  "                IEnumerable<TSource> childAsSequential = queryOp.Child.AsSequentialQuery(settings.CancellationState.ExternalCancellationToken); " is 127.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,First,The length of the statement  "                IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' settings.CancellationState.ExternalCancellationToken); " is 145.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,FirstOrDefault,The length of the statement  "                IEnumerable<TSource> childAsSequential = queryOp.Child.AsSequentialQuery(settings.CancellationState.ExternalCancellationToken); " is 127.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,FirstOrDefault,The length of the statement  "                IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' settings.CancellationState.ExternalCancellationToken); " is 145.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,FirstOrDefault,The length of the statement  "                IEnumerable<TSource> childAsSequential = queryOp.Child.AsSequentialQuery(settings.CancellationState.ExternalCancellationToken); " is 127.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,FirstOrDefault,The length of the statement  "                IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' settings.CancellationState.ExternalCancellationToken); " is 145.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Last,The length of the statement  "                IEnumerable<TSource> childAsSequential = queryOp.Child.AsSequentialQuery(settings.CancellationState.ExternalCancellationToken); " is 127.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Last,The length of the statement  "                IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' settings.CancellationState.ExternalCancellationToken); " is 145.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Last,The length of the statement  "                IEnumerable<TSource> childAsSequential = queryOp.Child.AsSequentialQuery(settings.CancellationState.ExternalCancellationToken); " is 127.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,Last,The length of the statement  "                IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' settings.CancellationState.ExternalCancellationToken); " is 145.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,LastOrDefault,The length of the statement  "                IEnumerable<TSource> childAsSequential = queryOp.Child.AsSequentialQuery(settings.CancellationState.ExternalCancellationToken); " is 127.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,LastOrDefault,The length of the statement  "                IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' settings.CancellationState.ExternalCancellationToken); " is 145.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,LastOrDefault,The length of the statement  "                IEnumerable<TSource> childAsSequential = queryOp.Child.AsSequentialQuery(settings.CancellationState.ExternalCancellationToken); " is 127.
Long Statement,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,LastOrDefault,The length of the statement  "                IEnumerable<TSource> childWithCancelChecks = CancellableEnumerable.Wrap(childAsSequential' settings.CancellationState.ExternalCancellationToken); " is 145.
Complex Conditional,System.Linq.Parallel,ExceptionAggregator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\ExceptionAggregator.cs,ThrowAnOCE,The conditional expression  "cancelEx != null &&                  cancelEx.CancellationToken == cancellationState.MergedCancellationToken                  && cancellationState.MergedCancellationToken.IsCancellationRequested                  && cancellationState.ExternalCancellationToken.IsCancellationRequested"  is complex.
Complex Conditional,System.Linq,AggregationMinMaxHelpers<T>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Enumerables\AggregationMinMaxHelpers.cs,MakeIntermediateReduceFunction,The conditional expression  "(default(T) != null || element != null) &&                                 (!accumulator.First || Util.Sign(comparer.Compare(element' accumulator.Second)) == sign)"  is complex.
Complex Conditional,System.Linq,ParallelEnumerable,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\ParallelEnumerable.cs,WithMergeOptions,The conditional expression  "mergeOptions != ParallelMergeOptions.Default                  && mergeOptions != ParallelMergeOptions.AutoBuffered                  && mergeOptions != ParallelMergeOptions.NotBuffered                  && mergeOptions != ParallelMergeOptions.FullyBuffered"  is complex.
Magic Number,System.Linq.Parallel,HashRepartitionEnumerator<TInputOutput;THashKey;TIgnoreKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\HashRepartitionEnumerator.cs,EnumerateAndRedistributeElements,The following statement contains a magic number: while (_source.MoveNext(ref element' ref ignoreKey))              {                  if ((loopCount++ & CancellationState.POLL_INTERVAL) == 0)                      CancellationState.ThrowIfCanceled(_cancellationToken);                    // Calculate the element's destination partition index' placing it into the                  // appropriate buffer from which partitions will later enumerate.                  int destinationIndex;                  THashKey elementHashKey = default(THashKey);                  if (_keySelector != null)                  {                      elementHashKey = _keySelector(element);                      destinationIndex = _repartitionStream.GetHashCode(elementHashKey) % _partitionCount;                  }                  else                  {                      Debug.Assert(typeof(THashKey) == typeof(NoKeyMemoizationRequired));                      destinationIndex = _repartitionStream.GetHashCode(element) % _partitionCount;                  }                    Debug.Assert(0 <= destinationIndex && destinationIndex < _partitionCount'                                  "destination partition outside of the legal range of partitions");                    // Get the buffer for the destination partition' lazily allocating if needed.  We maintain                  // this list in our own private cache so that we avoid accessing shared memory locations                  // too much.  In the original implementation' we'd access the buffer in the matrix ([N'M]'                  // where N is the current partition and M is the destination)' but some rudimentary                  // performance profiling indicates copying at the end performs better.                  ListChunk<Pair<TInputOutput' THashKey>> buffer = privateBuffers[destinationIndex];                  if (buffer == null)                  {                      const int INITIAL_PRIVATE_BUFFER_SIZE = 128;                      privateBuffers[destinationIndex] = buffer = new ListChunk<Pair<TInputOutput' THashKey>>(INITIAL_PRIVATE_BUFFER_SIZE);                  }                    buffer.Add(new Pair<TInputOutput' THashKey>(element' elementHashKey));              }
Magic Number,System.Linq.Parallel,HashRepartitionStream<TInputOutput;THashKey;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\HashRepartitionStream.cs,HashRepartitionStream,The following statement contains a magic number: const int DEFAULT_HASH_MOD_DISTRIBUTION = 503;
Magic Number,System.Linq.Parallel,HashRepartitionStream<TInputOutput;THashKey;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\HashRepartitionStream.cs,HashRepartitionStream,The following statement contains a magic number: while (_distributionMod < partitionsCount)              {                  // We use checked arithmetic here.  We'll only overflow for huge numbers of partitions                  // (quite unlikely)' so the remote possibility of an exception is fine.                  checked                  {                      _distributionMod *= 2;                  }              }
Magic Number,System.Linq.Parallel,OrderedHashRepartitionEnumerator<TInputOutput;THashKey;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\OrderedHashRepartitionEnumerator.cs,EnumerateAndRedistributeElements,The following statement contains a magic number: while (_source.MoveNext(ref element' ref key))              {                  if ((loopCount++ & CancellationState.POLL_INTERVAL) == 0)                      CancellationState.ThrowIfCanceled(_cancellationToken);                    // Calculate the element's destination partition index' placing it into the                  // appropriate buffer from which partitions will later enumerate.                  int destinationIndex;                  THashKey elementHashKey = default(THashKey);                  if (_keySelector != null)                  {                      elementHashKey = _keySelector(element);                      destinationIndex = _repartitionStream.GetHashCode(elementHashKey) % _partitionCount;                  }                  else                  {                      Debug.Assert(typeof(THashKey) == typeof(NoKeyMemoizationRequired));                      destinationIndex = _repartitionStream.GetHashCode(element) % _partitionCount;                  }                    Debug.Assert(0 <= destinationIndex && destinationIndex < _partitionCount'                                  "destination partition outside of the legal range of partitions");                    // Get the buffer for the destination partition' lazily allocating if needed.  We maintain                  // this list in our own private cache so that we avoid accessing shared memory locations                  // too much.  In the original implementation' we'd access the buffer in the matrix ([N'M]'                  // where N is the current partition and M is the destination)' but some rudimentary                  // performance profiling indicates copying at the end performs better.                  ListChunk<Pair<TInputOutput' THashKey>> buffer = privateBuffers[destinationIndex];                  ListChunk<TOrderKey> keyBuffer = privateKeyBuffers[destinationIndex];                  if (buffer == null)                  {                      const int INITIAL_PRIVATE_BUFFER_SIZE = 128;                      Debug.Assert(keyBuffer == null);                      privateBuffers[destinationIndex] = buffer = new ListChunk<Pair<TInputOutput' THashKey>>(INITIAL_PRIVATE_BUFFER_SIZE);                      privateKeyBuffers[destinationIndex] = keyBuffer = new ListChunk<TOrderKey>(INITIAL_PRIVATE_BUFFER_SIZE);                  }                    buffer.Add(new Pair<TInputOutput' THashKey>(element' elementHashKey));                  keyBuffer.Add(key);              }
Magic Number,System.Linq.Parallel,ContiguousChunkLazyEnumerator,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Partitioning\PartitionedDataSource.cs,MoveNext,The following statement contains a magic number: while (true)                  {                      // If we have elements remaining in the current chunk' return right away.                      T[] chunkBuffer = mutables._chunkBuffer;                      int currentChunkIndex = ++mutables._currentChunkIndex;                      if (currentChunkIndex < mutables._currentChunkSize)                      {                          Debug.Assert(_source != null);                          Debug.Assert(chunkBuffer != null);                          Debug.Assert(mutables._currentChunkSize > 0);                          Debug.Assert(0 <= currentChunkIndex && currentChunkIndex < chunkBuffer.Length);                          currentElement = chunkBuffer[currentChunkIndex];                          currentKey = mutables._chunkBaseIndex + currentChunkIndex;                            return true;                      }                        // Else' it could be the first time enumerating this object' or we may have                      // just reached the end of the current chunk and need to grab another one? In either                      // case' we will look for more data from the underlying enumerator.  Because we                      // share the same enumerator object' we have to do this under a lock.                        lock (_sourceSyncLock)                      {                          Debug.Assert(0 <= mutables._nextChunkMaxSize && mutables._nextChunkMaxSize <= chunkBuffer.Length);                            // Accumulate a chunk of elements from the input.                          int i = 0;                            if (_exceptionTracker.Value)                          {                              return false;                          }                            try                          {                              for (; i < mutables._nextChunkMaxSize && _source.MoveNext(); i++)                              {                                  // Read the current entry into our buffer.                                  chunkBuffer[i] = _source.Current;                              }                          }                          catch                          {                              _exceptionTracker.Value = true;                              throw;                          }                            // Store the number of elements we fetched from the data source.                          mutables._currentChunkSize = i;                            // If we've emptied the enumerator' return immediately.                          if (i == 0)                          {                              return false;                          }                            // Increment the shared index for all to see. Throw an exception on overflow.                          mutables._chunkBaseIndex = _currentIndex.Value;                          checked                          {                              _currentIndex.Value += i;                          }                      }                        // Each time we access the data source' we grow the chunk size for the next go-round.                      // We grow the chunksize once per 'chunksPerChunkSize'.                       if (mutables._nextChunkMaxSize < chunkBuffer.Length)                      {                          if ((mutables._chunkCounter++ & chunksPerChunkSize) == chunksPerChunkSize)                          {                              mutables._nextChunkMaxSize = mutables._nextChunkMaxSize * 2;                              if (mutables._nextChunkMaxSize > chunkBuffer.Length)                              {                                  mutables._nextChunkMaxSize = chunkBuffer.Length;                              }                          }                      }                        // Finally' reset our index to the beginning; loop around and we'll return the right values.                      mutables._currentChunkIndex = -1;                  }
Magic Number,System.Linq.Parallel,HashJoinQueryOperatorEnumerator<TLeftInput;TLeftKey;TRightInput;THashKey;TOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Binary\HashJoinQueryOperatorEnumerator.cs,MoveNext,The following statement contains a magic number: if (mutables == null)              {                  mutables = _mutables = new Mutables();  #if DEBUG                  int hashLookupCount = 0;                  int hashKeyCollisions = 0;  #endif                  mutables._rightHashLookup = new HashLookup<THashKey' Pair<TRightInput' ListChunk<TRightInput>>>(_keyComparer);                    Pair<TRightInput' THashKey> rightPair = default(Pair<TRightInput' THashKey>);                  int rightKeyUnused = default(int);                  int i = 0;                  while (_rightSource.MoveNext(ref rightPair' ref rightKeyUnused))                  {                      if ((i++ & CancellationState.POLL_INTERVAL) == 0)                          CancellationState.ThrowIfCanceled(_cancellationToken);                        TRightInput rightElement = rightPair.First;                      THashKey rightHashKey = rightPair.Second;                        // We ignore null keys.                      if (rightHashKey != null)                      {  #if DEBUG                          hashLookupCount++;  #endif                            // See if we've already stored an element under the current key. If not' we                          // lazily allocate a pair to hold the elements mapping to the same key.                          const int INITIAL_CHUNK_SIZE = 2;                          Pair<TRightInput' ListChunk<TRightInput>> currentValue = default(Pair<TRightInput' ListChunk<TRightInput>>);                          if (!mutables._rightHashLookup.TryGetValue(rightHashKey' ref currentValue))                          {                              currentValue = new Pair<TRightInput' ListChunk<TRightInput>>(rightElement' null);                                if (_groupResultSelector != null)                              {                                  // For group joins' we also add the element to the list. This makes                                  // it easier later to yield the list as-is.                                  currentValue.Second = new ListChunk<TRightInput>(INITIAL_CHUNK_SIZE);                                  currentValue.Second.Add(rightElement);                              }                                mutables._rightHashLookup.Add(rightHashKey' currentValue);                          }                          else                          {                              if (currentValue.Second == null)                              {                                  // Lazily allocate a list to hold all but the 1st value. We need to                                  // re-store this element because the pair is a value type.                                  currentValue.Second = new ListChunk<TRightInput>(INITIAL_CHUNK_SIZE);                                  mutables._rightHashLookup[rightHashKey] = currentValue;                              }                                currentValue.Second.Add(rightElement);  #if DEBUG                              hashKeyCollisions++;  #endif                          }                      }                  }    #if DEBUG                  TraceHelpers.TraceInfo("ParallelJoinQueryOperator::MoveNext - built hash table [count = {0}' collisions = {1}]"'                      hashLookupCount' hashKeyCollisions);  #endif              }
Magic Number,System.Linq.Parallel,GroupByIdentityQueryOperatorEnumerator<TSource;TGroupKey;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\GroupByQueryOperator.cs,BuildHashLookup,The following statement contains a magic number: while (_source.MoveNext(ref sourceElement' ref sourceKeyUnused))              {                  if ((i++ & CancellationState.POLL_INTERVAL) == 0)                      CancellationState.ThrowIfCanceled(_cancellationToken);                    // Generate a key and place it into the hashtable.                  Wrapper<TGroupKey> key = new Wrapper<TGroupKey>(sourceElement.Second);                    // If the key already exists' we just append it to the existing list --                  // otherwise we will create a new one and add it to that instead.                  ListChunk<TSource> currentValue = null;                  if (!hashlookup.TryGetValue(key' ref currentValue))                  {                      const int INITIAL_CHUNK_SIZE = 2;                      currentValue = new ListChunk<TSource>(INITIAL_CHUNK_SIZE);                      hashlookup.Add(key' currentValue);                  }                  Debug.Assert(currentValue != null);                    // Call to the base class to yield the current value.                  currentValue.Add(sourceElement.First);              }
Magic Number,System.Linq.Parallel,GroupByElementSelectorQueryOperatorEnumerator<TSource;TGroupKey;TElement;TOrderKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\QueryOperators\Unary\GroupByQueryOperator.cs,BuildHashLookup,The following statement contains a magic number: while (_source.MoveNext(ref sourceElement' ref sourceKeyUnused))              {                  if ((i++ & CancellationState.POLL_INTERVAL) == 0)                      CancellationState.ThrowIfCanceled(_cancellationToken);                    // Generate a key and place it into the hashtable.                  Wrapper<TGroupKey> key = new Wrapper<TGroupKey>(sourceElement.Second);                    // If the key already exists' we just append it to the existing list --                  // otherwise we will create a new one and add it to that instead.                  ListChunk<TElement> currentValue = null;                  if (!hashlookup.TryGetValue(key' ref currentValue))                  {                      const int INITIAL_CHUNK_SIZE = 2;                      currentValue = new ListChunk<TElement>(INITIAL_CHUNK_SIZE);                      hashlookup.Add(key' currentValue);                  }                  Debug.Assert(currentValue != null);                    // Call to the base class to yield the current value.                  currentValue.Add(_elementSelector(sourceElement.First));              }
Magic Number,System.Linq.Parallel,Scheduling,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Scheduling\Scheduling.cs,GetDefaultChunkSize,The following statement contains a magic number: if (default(T) != null || Nullable.GetUnderlyingType(typeof(T)) != null)              {                  // Marshal.SizeOf fails for value types that don't have explicit layouts. We                  // just fall back to some arbitrary constant in that case. Is there a better way?                  {                      // We choose '128' because this ensures' no matter the actual size of the value type'                      // the total bytes used will be a multiple of 128. This ensures it's cache aligned.                      chunkSize = 128;                  }              }              else              {                  Debug.Assert((DEFAULT_BYTES_PER_CHUNK % IntPtr.Size) == 0' "bytes per chunk should be a multiple of pointer size");                  chunkSize = (DEFAULT_BYTES_PER_CHUNK / IntPtr.Size);              }
Magic Number,System.Linq.Parallel,Set<TElement>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Helpers.cs,Resize,The following statement contains a magic number: int newSize = checked(_count * 2 + 1);
Magic Number,System.Linq.Parallel,FixedMaxHeap<TElement>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\FixedMaxHeap.cs,HeapifyRoot,The following statement contains a magic number: while (i < n)              {                  // Calculate the current child node indexes.                  int n0 = ((i + 1) * 2) - 1;                  int n1 = n0 + 1;                    if (n0 < n && _comparer.Compare(_elements[i]' _elements[n0]) < 0)                  {                      // We have to select the bigger of the two subtrees' and float                      // the current element down. This maintains the max-heap property.                      if (n1 < n && _comparer.Compare(_elements[n0]' _elements[n1]) < 0)                      {                          Swap(i' n1);                          i = n1;                      }                      else                      {                          Swap(i' n0);                          i = n0;                      }                  }                  else if (n1 < n && _comparer.Compare(_elements[i]' _elements[n1]) < 0)                  {                      // Float down the "right" subtree. We needn't compare this subtree                      // to the "left"' because if the element was smaller than that' the                      // first if statement's predicate would have evaluated to true.                      Swap(i' n1);                      i = n1;                  }                  else                  {                      // Else' the current key is in its final position. Break out                      // of the current loop and return.                      break;                  }              }
Magic Number,System.Linq.Parallel,FixedMaxHeap<TElement>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\FixedMaxHeap.cs,HeapifyLastLeaf,The following statement contains a magic number: while (i > 0)              {                  int j = ((i + 1) / 2) - 1;                    if (_comparer.Compare(_elements[i]' _elements[j]) > 0)                  {                      Swap(i' j);                      i = j;                  }                  else                  {                      break;                  }              }
Magic Number,System.Linq.Parallel,GrowingArray<T>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\GrowingArray.cs,Add,The following statement contains a magic number: if (_count >= _array.Length)              {                  GrowArray(2 * _array.Length);              }
Magic Number,System.Linq.Parallel,HashLookup<TKey;TValue>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\HashLookup.cs,HashLookup,The following statement contains a magic number: buckets = new int[7];
Magic Number,System.Linq.Parallel,HashLookup<TKey;TValue>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\HashLookup.cs,HashLookup,The following statement contains a magic number: slots = new Slot[7];
Magic Number,System.Linq.Parallel,HashLookup<TKey;TValue>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\HashLookup.cs,Resize,The following statement contains a magic number: int newSize = checked(count * 2 + 1);
Magic Number,System.Linq.Parallel,ListChunk<TInputOutput>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\ListChunk.cs,Add,The following statement contains a magic number: if (tail._chunkCount == tail._chunk.Length)              {                  _tailChunk = new ListChunk<TInputOutput>(tail._chunkCount * 2);                  tail = (tail._nextChunk = _tailChunk);              }
Magic Number,System.Linq.Parallel,SortHelper<TInputOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\Sorting.cs,GenerateSortHelpers,The following statement contains a magic number: if (degreeOfParallelism > 1)              {                  // Initialize the barriers we need.  Due to the logarithmic reduction' we don't                  // need to populate the whole matrix.                  int offset = 1;                  for (int i = 0; i < sharedBarriers.Length; i++)                  {                      // We have jagged arrays.                      for (int j = 0; j < sharedBarriers[i].Length; j++)                      {                          // As the phases increase' the barriers required become more and more sparse.                          if ((j % offset) == 0)                          {                              sharedBarriers[i][j] = new Barrier(2);                          }                      }                      offset *= 2;                  }              }
Magic Number,System.Linq.Parallel,SortHelper<TInputOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\Sorting.cs,GenerateSortHelpers,The following statement contains a magic number: if (degreeOfParallelism > 1)              {                  // Initialize the barriers we need.  Due to the logarithmic reduction' we don't                  // need to populate the whole matrix.                  int offset = 1;                  for (int i = 0; i < sharedBarriers.Length; i++)                  {                      // We have jagged arrays.                      for (int j = 0; j < sharedBarriers[i].Length; j++)                      {                          // As the phases increase' the barriers required become more and more sparse.                          if ((j % offset) == 0)                          {                              sharedBarriers[i][j] = new Barrier(2);                          }                      }                      offset *= 2;                  }              }
Magic Number,System.Linq.Parallel,SortHelper<TInputOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\Sorting.cs,MergeSortCooperatively,The following statement contains a magic number: for (int phase = 0; phase < phaseCount; phase++)              {                  bool isLastPhase = (phase == (phaseCount - 1));                    // Calculate our partner for this phase and the next.                  int partnerIndex = ComputePartnerIndex(phase);                    // If we have a partner (see above for non power of 2 cases and why the index returned might                  // be out of bounds)' we will coordinate with the partner to produce the merged output.                  if (partnerIndex < _partitionCount)                  {                      // Cache references to our local data.                      int[] myIndices = _sharedIndices[_partitionIndex];                      GrowingArray<TKey> myKeys = _sharedKeys[_partitionIndex];                      TKey[] myKeysArr = myKeys.InternalArray;                        TInputOutput[] myValues = _sharedValues[_partitionIndex];                          // First we must rendezvous with our merge partner so we know the previous sort                      // and merge phase has been completed.  By convention' we always use the left-most                      // partner's barrier for this; all that matters is that both uses the same.                      _sharedBarriers[phase][Math.Min(_partitionIndex' partnerIndex)].SignalAndWait(cancelToken);                        // Grab the two sorted inputs and then merge them cooperatively into one list.  One                      // worker merges from left-to-right until it's placed elements up to the half-way                      // point' and the other worker does the same' but only from right-to-left.                      if (_partitionIndex < partnerIndex)                      {                          // Before moving on to the actual merge' the left-most partition will allocate data                          // to hold the merged indices and key/value pairs.                            // First' remember a copy of all of the partner's lists.                          int[] rightIndices = _sharedIndices[partnerIndex];                          TKey[] rightKeys = _sharedKeys[partnerIndex].InternalArray;                          TInputOutput[] rightValues = _sharedValues[partnerIndex];                            // We copy the our own items into the right's (overwriting its values) so that it can                          // retrieve them after the barrier.  This is an exchange operation.                          _sharedIndices[partnerIndex] = myIndices;                          _sharedKeys[partnerIndex] = myKeys;                          _sharedValues[partnerIndex] = myValues;                            int leftCount = myValues.Length;                          int rightCount = rightValues.Length;                          int totalCount = leftCount + rightCount;                            // Now allocate the lists into which the merged data will go.  Share this                          // with the other thread so that it can place data into it as well.                          int[] mergedIndices = null;                          TInputOutput[] mergedValues = new TInputOutput[totalCount];                            // Only on the last phase do we need to remember indices and keys.                          if (!isLastPhase)                          {                              mergedIndices = new int[totalCount];                          }                            // Publish our newly allocated merged data structures.                          _sharedIndices[_partitionIndex] = mergedIndices;                          _sharedKeys[_partitionIndex] = myKeys;                          _sharedValues[_partitionIndex] = mergedValues;                            Debug.Assert(myKeysArr != null);                            _sharedBarriers[phase][_partitionIndex].SignalAndWait(cancelToken);                            // Merge the left half into the shared merged space.  This is a normal merge sort with                          // the caveat that we stop merging once we reach the half-way point (since our partner                          // is doing the same for the right half).  Note that during the last phase we only                          // copy the values and not the indices or keys.                          int m = (totalCount + 1) / 2;                          int i = 0' j0 = 0' j1 = 0;                          while (i < m)                          {                              if ((i & CancellationState.POLL_INTERVAL) == 0)                                  CancellationState.ThrowIfCanceled(cancelToken);                                if (j0 < leftCount && (j1 >= rightCount ||                                                     _keyComparer.Compare(myKeysArr[myIndices[j0]]'                                                                           rightKeys[rightIndices[j1]]) <= 0))                              {                                  if (isLastPhase)                                  {                                      mergedValues[i] = myValues[myIndices[j0]];                                  }                                  else                                  {                                      mergedIndices[i] = myIndices[j0];                                  }                                  j0++;                              }                              else                              {                                  if (isLastPhase)                                  {                                      mergedValues[i] = rightValues[rightIndices[j1]];                                  }                                  else                                  {                                      mergedIndices[i] = leftCount + rightIndices[j1];                                  }                                  j1++;                              }                              i++;                          }                            // If it's not the last phase' we just bulk propagate the keys and values.                          if (!isLastPhase && leftCount > 0)                          {                              Array.Copy(myValues' 0' mergedValues' 0' leftCount);                          }                            // And now just wait for the second half.  We never reuse the same barrier across multiple                          // phases' so we can always dispose of it when we wake up.                          _sharedBarriers[phase][_partitionIndex].SignalAndWait(cancelToken);                      }                      else                      {                          // Wait for the other partition to allocate the shared data.                          _sharedBarriers[phase][partnerIndex].SignalAndWait(cancelToken);                            // After the barrier' the other partition will have made two things available to us:                          // (1) its own indices' keys' and values' stored in the cell that used to hold our data'                          // and (2) the arrays into which merged data will go' stored in its shared array cells.                            // We will snag references to all of these things.                          int[] leftIndices = _sharedIndices[_partitionIndex];                          TKey[] leftKeys = _sharedKeys[_partitionIndex].InternalArray;                          TInputOutput[] leftValues = _sharedValues[_partitionIndex];                          int[] mergedIndices = _sharedIndices[partnerIndex];                          GrowingArray<TKey> mergedKeys = _sharedKeys[partnerIndex];                          TInputOutput[] mergedValues = _sharedValues[partnerIndex];                            Debug.Assert(leftValues != null);                          Debug.Assert(leftKeys != null);                            int leftCount = leftValues.Length;                          int rightCount = myValues.Length;                          int totalCount = leftCount + rightCount;                            // Merge the right half into the shared merged space.  This is a normal merge sort with                          // the caveat that we stop merging once we reach the half-way point (since our partner                          // is doing the same for the left half).  Note that during the last phase we only                          // copy the values and not the indices or keys.                          int m = (totalCount + 1) / 2;                          int i = totalCount - 1' j0 = leftCount - 1' j1 = rightCount - 1;                          while (i >= m)                          {                              if ((i & CancellationState.POLL_INTERVAL) == 0)                                  CancellationState.ThrowIfCanceled(cancelToken);                                if (j0 >= 0 && (j1 < 0 ||                                              _keyComparer.Compare(leftKeys[leftIndices[j0]]'                                                                    myKeysArr[myIndices[j1]]) > 0))                              {                                  if (isLastPhase)                                  {                                      mergedValues[i] = leftValues[leftIndices[j0]];                                  }                                  else                                  {                                      mergedIndices[i] = leftIndices[j0];                                  }                                  j0--;                              }                              else                              {                                  if (isLastPhase)                                  {                                      mergedValues[i] = myValues[myIndices[j1]];                                  }                                  else                                  {                                      mergedIndices[i] = leftCount + myIndices[j1];                                  }                                  j1--;                              }                              i--;                          }                            // If it's not the last phase' we just bulk propagate the keys and values.                          if (!isLastPhase && myValues.Length > 0)                          {                              mergedKeys.CopyFrom(myKeysArr' myValues.Length);                              Array.Copy(myValues' 0' mergedValues' leftCount' myValues.Length);                          }                            // Wait for our partner to finish copying too.                          _sharedBarriers[phase][partnerIndex].SignalAndWait(cancelToken);                            // Now the greater of the two partners can leave' it's done.                          break;                      }                  }              }
Magic Number,System.Linq.Parallel,SortHelper<TInputOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\Sorting.cs,MergeSortCooperatively,The following statement contains a magic number: for (int phase = 0; phase < phaseCount; phase++)              {                  bool isLastPhase = (phase == (phaseCount - 1));                    // Calculate our partner for this phase and the next.                  int partnerIndex = ComputePartnerIndex(phase);                    // If we have a partner (see above for non power of 2 cases and why the index returned might                  // be out of bounds)' we will coordinate with the partner to produce the merged output.                  if (partnerIndex < _partitionCount)                  {                      // Cache references to our local data.                      int[] myIndices = _sharedIndices[_partitionIndex];                      GrowingArray<TKey> myKeys = _sharedKeys[_partitionIndex];                      TKey[] myKeysArr = myKeys.InternalArray;                        TInputOutput[] myValues = _sharedValues[_partitionIndex];                          // First we must rendezvous with our merge partner so we know the previous sort                      // and merge phase has been completed.  By convention' we always use the left-most                      // partner's barrier for this; all that matters is that both uses the same.                      _sharedBarriers[phase][Math.Min(_partitionIndex' partnerIndex)].SignalAndWait(cancelToken);                        // Grab the two sorted inputs and then merge them cooperatively into one list.  One                      // worker merges from left-to-right until it's placed elements up to the half-way                      // point' and the other worker does the same' but only from right-to-left.                      if (_partitionIndex < partnerIndex)                      {                          // Before moving on to the actual merge' the left-most partition will allocate data                          // to hold the merged indices and key/value pairs.                            // First' remember a copy of all of the partner's lists.                          int[] rightIndices = _sharedIndices[partnerIndex];                          TKey[] rightKeys = _sharedKeys[partnerIndex].InternalArray;                          TInputOutput[] rightValues = _sharedValues[partnerIndex];                            // We copy the our own items into the right's (overwriting its values) so that it can                          // retrieve them after the barrier.  This is an exchange operation.                          _sharedIndices[partnerIndex] = myIndices;                          _sharedKeys[partnerIndex] = myKeys;                          _sharedValues[partnerIndex] = myValues;                            int leftCount = myValues.Length;                          int rightCount = rightValues.Length;                          int totalCount = leftCount + rightCount;                            // Now allocate the lists into which the merged data will go.  Share this                          // with the other thread so that it can place data into it as well.                          int[] mergedIndices = null;                          TInputOutput[] mergedValues = new TInputOutput[totalCount];                            // Only on the last phase do we need to remember indices and keys.                          if (!isLastPhase)                          {                              mergedIndices = new int[totalCount];                          }                            // Publish our newly allocated merged data structures.                          _sharedIndices[_partitionIndex] = mergedIndices;                          _sharedKeys[_partitionIndex] = myKeys;                          _sharedValues[_partitionIndex] = mergedValues;                            Debug.Assert(myKeysArr != null);                            _sharedBarriers[phase][_partitionIndex].SignalAndWait(cancelToken);                            // Merge the left half into the shared merged space.  This is a normal merge sort with                          // the caveat that we stop merging once we reach the half-way point (since our partner                          // is doing the same for the right half).  Note that during the last phase we only                          // copy the values and not the indices or keys.                          int m = (totalCount + 1) / 2;                          int i = 0' j0 = 0' j1 = 0;                          while (i < m)                          {                              if ((i & CancellationState.POLL_INTERVAL) == 0)                                  CancellationState.ThrowIfCanceled(cancelToken);                                if (j0 < leftCount && (j1 >= rightCount ||                                                     _keyComparer.Compare(myKeysArr[myIndices[j0]]'                                                                           rightKeys[rightIndices[j1]]) <= 0))                              {                                  if (isLastPhase)                                  {                                      mergedValues[i] = myValues[myIndices[j0]];                                  }                                  else                                  {                                      mergedIndices[i] = myIndices[j0];                                  }                                  j0++;                              }                              else                              {                                  if (isLastPhase)                                  {                                      mergedValues[i] = rightValues[rightIndices[j1]];                                  }                                  else                                  {                                      mergedIndices[i] = leftCount + rightIndices[j1];                                  }                                  j1++;                              }                              i++;                          }                            // If it's not the last phase' we just bulk propagate the keys and values.                          if (!isLastPhase && leftCount > 0)                          {                              Array.Copy(myValues' 0' mergedValues' 0' leftCount);                          }                            // And now just wait for the second half.  We never reuse the same barrier across multiple                          // phases' so we can always dispose of it when we wake up.                          _sharedBarriers[phase][_partitionIndex].SignalAndWait(cancelToken);                      }                      else                      {                          // Wait for the other partition to allocate the shared data.                          _sharedBarriers[phase][partnerIndex].SignalAndWait(cancelToken);                            // After the barrier' the other partition will have made two things available to us:                          // (1) its own indices' keys' and values' stored in the cell that used to hold our data'                          // and (2) the arrays into which merged data will go' stored in its shared array cells.                            // We will snag references to all of these things.                          int[] leftIndices = _sharedIndices[_partitionIndex];                          TKey[] leftKeys = _sharedKeys[_partitionIndex].InternalArray;                          TInputOutput[] leftValues = _sharedValues[_partitionIndex];                          int[] mergedIndices = _sharedIndices[partnerIndex];                          GrowingArray<TKey> mergedKeys = _sharedKeys[partnerIndex];                          TInputOutput[] mergedValues = _sharedValues[partnerIndex];                            Debug.Assert(leftValues != null);                          Debug.Assert(leftKeys != null);                            int leftCount = leftValues.Length;                          int rightCount = myValues.Length;                          int totalCount = leftCount + rightCount;                            // Merge the right half into the shared merged space.  This is a normal merge sort with                          // the caveat that we stop merging once we reach the half-way point (since our partner                          // is doing the same for the left half).  Note that during the last phase we only                          // copy the values and not the indices or keys.                          int m = (totalCount + 1) / 2;                          int i = totalCount - 1' j0 = leftCount - 1' j1 = rightCount - 1;                          while (i >= m)                          {                              if ((i & CancellationState.POLL_INTERVAL) == 0)                                  CancellationState.ThrowIfCanceled(cancelToken);                                if (j0 >= 0 && (j1 < 0 ||                                              _keyComparer.Compare(leftKeys[leftIndices[j0]]'                                                                    myKeysArr[myIndices[j1]]) > 0))                              {                                  if (isLastPhase)                                  {                                      mergedValues[i] = leftValues[leftIndices[j0]];                                  }                                  else                                  {                                      mergedIndices[i] = leftIndices[j0];                                  }                                  j0--;                              }                              else                              {                                  if (isLastPhase)                                  {                                      mergedValues[i] = myValues[myIndices[j1]];                                  }                                  else                                  {                                      mergedIndices[i] = leftCount + myIndices[j1];                                  }                                  j1--;                              }                              i--;                          }                            // If it's not the last phase' we just bulk propagate the keys and values.                          if (!isLastPhase && myValues.Length > 0)                          {                              mergedKeys.CopyFrom(myKeysArr' myValues.Length);                              Array.Copy(myValues' 0' mergedValues' leftCount' myValues.Length);                          }                            // Wait for our partner to finish copying too.                          _sharedBarriers[phase][partnerIndex].SignalAndWait(cancelToken);                            // Now the greater of the two partners can leave' it's done.                          break;                      }                  }              }
Magic Number,System.Linq.Parallel,SortHelper<TInputOutput;TKey>,C:\selectedRepos\dotnet_corefx\src\System.Linq.Parallel\src\System\Linq\Parallel\Utils\Sorting.cs,ComputePartnerIndex,The following statement contains a magic number: return _partitionIndex + ((_partitionIndex % (offset * 2)) == 0 ? offset : -offset);
