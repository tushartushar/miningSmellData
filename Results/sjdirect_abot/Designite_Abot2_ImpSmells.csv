Implementation smell,Namespace,Class,File,Method,Description
Complex Method,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,Cyclomatic complexity of the method is 10
Complex Method,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldDownloadPageContent,Cyclomatic complexity of the method is 9
Complex Method,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,ProcessPage,Cyclomatic complexity of the method is 8
Long Parameter List,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,PoliteWebCrawler,The method has 9 parameters. Parameters: crawlConfiguration' crawlDecisionMaker' threadManager' scheduler' pageRequester' htmlParser' memoryManager' domainRateLimiter' robotsDotTextFinder
Long Parameter List,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,WebCrawler,The method has 7 parameters. Parameters: crawlConfiguration' crawlDecisionMaker' threadManager' scheduler' pageRequester' htmlParser' memoryManager
Long Parameter List,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,BloomFilter,The method has 5 parameters. Parameters: capacity' errorRate' hashFunction' m' k
Long Identifier,Abot2.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\DomainRateLimiter.cs,,The length of the parameter _defaultMinCrawlDelayInMillisecs is 32.
Long Identifier,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,CrawlAsync,The length of the parameter robotsDotTextCrawlDelayInMillisecs is 34.
Long Identifier,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the parameter allPathsBelowRootAllowedByRobots is 32.
Long Identifier,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,,The length of the parameter _maxPagesToCrawlLimitReachedOrScheduled is 39.
Long Identifier,Abot2.Util,ThreadManager,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\ThreadManager.cs,RunAction,The length of the parameter decrementRunningThreadCountOnCompletion is 39.
Long Statement,Abot2.Core,AngleSharpHyperlinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\AngleSharpHyperLinkParser.cs,HasRelNoFollow,The length of the statement  "            return Config.IsRespectAnchorRelNoFollowEnabled && (e.HasAttribute("rel") && e.GetAttribute("rel").ToLower().Trim() == "nofollow"); " is 131.
Long Statement,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The length of the statement  "            if (pageToCrawl.RedirectedFrom != null && pageToCrawl.RedirectPosition > crawlContext.CrawlConfiguration.HttpRequestMaxAutoRedirects) " is 133.
Long Statement,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The length of the statement  "                return new CrawlDecision { Allow = false' Reason = string.Format("HttpRequestMaxAutoRedirects limit of [{0}] has been reached"' crawlContext.CrawlConfiguration.HttpRequestMaxAutoRedirects) }; " is 191.
Long Statement,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The length of the statement  "                return new CrawlDecision { Allow = false' Reason = string.Format("MaxPagesToCrawl limit of [{0}] has been reached"' crawlContext.CrawlConfiguration.MaxPagesToCrawl) }; " is 167.
Long Statement,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The length of the statement  "                    return new CrawlDecision { Allow = false' Reason = string.Format("MaxPagesToCrawlPerDomain limit of [{0}] has been reached for domain [{1}]"' crawlContext.CrawlConfiguration.MaxPagesToCrawlPerDomain' pageToCrawl.Uri.Authority) }; " is 229.
Long Statement,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldDownloadPageContent,The length of the statement  "                return new CrawlDecision { Allow = false' Reason = "Content type is not any of the following: " + string.Join("'"' cleanDownloadableContentTypes) }; " is 148.
Long Statement,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldDownloadPageContent,The length of the statement  "            if (crawlContext.CrawlConfiguration.MaxPageSizeInBytes > 0 && crawledPage.HttpResponseMessage.Content.Headers.ContentLength > crawlContext.CrawlConfiguration.MaxPageSizeInBytes) " is 177.
Long Statement,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldDownloadPageContent,The length of the statement  "                return new CrawlDecision { Allow = false' Reason = string.Format("Page size of [{0}] bytes is above the max allowable of [{1}] bytes"' crawledPage.HttpResponseMessage.Content.Headers.ContentLength' crawlContext.CrawlConfiguration.MaxPageSizeInBytes) }; " is 252.
Long Statement,Abot2.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\DomainRateLimiter.cs,AddDomain,The length of the statement  "            GetRateLimiter(uri' Math.Max(minCrawlDelayInMillisecs' _defaultMinCrawlDelayInMillisecs));//just calling this method adds the new domain " is 136.
Long Statement,Abot2.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\DomainRateLimiter.cs,GetRateLimiter,The length of the statement  "                    Log.Debug("Added new domain [{0}] with minCrawlDelayInMillisecs of [{1}] milliseconds"' uri.Authority' minCrawlDelayInMillisecs); " is 129.
Long Statement,Abot2.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\DomainRateLimiter.cs,GetRateLimiter,The length of the statement  "                    Log.Warning("Unable to add new domain [{0}] with minCrawlDelayInMillisecs of [{1}] milliseconds"' uri.Authority' minCrawlDelayInMillisecs); " is 139.
Long Statement,Abot2.Core,HyperLinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\HyperLinkParser.cs,GetUris,The length of the statement  "            //Using HttpWebRequest.Address instead of HttpWebResonse.ResponseUri since this is the best practice and mentioned on http://msdn.microsoft.com/en-us/library/system.net.httpwebresponse.responseuri.aspx " is 201.
Long Statement,Abot2.Core,HyperLinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\HyperLinkParser.cs,HasRobotsNoFollow,The length of the statement  "                    Log.Information("Http header X-Robots-Tag nofollow detected on uri [{0}]' will not crawl links on this page."' crawledPage.Uri); " is 128.
Long Statement,Abot2.Core,PageRequester,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\PageRequester.cs,MakeRequestAsync,The length of the statement  "                crawledPage.HttpRequestException = new HttpRequestException("Request timeout occurred"' ex);//https://stackoverflow.com/questions/10547895/how-can-i-tell-when-httpclient-has-timed-out " is 183.
Long Statement,Abot2.Core,PageRequester,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\PageRequester.cs,BuildHttpClientHandler,The length of the statement  "                cache.Add(new Uri($"https://{rootUri.Host}")' "Basic"' new NetworkCredential(_config.LoginUser' _config.LoginPassword)); " is 120.
Long Statement,Abot2.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\WebContentExtractor.cs,GetCharsetFromBody,The length of the statement  "                //find expression from : http://stackoverflow.com/questions/3458217/how-to-use-regular-expression-to-match-the-charset-string-in-html " is 133.
Long Statement,Abot2.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\WebContentExtractor.cs,GetCharsetFromBody,The length of the statement  "                var match = Regex.Match(body' @"<meta(?!\s*(?:name|value)\s*=)(?:[^>]*?content\s*=[\s""']*)?([^>]*?)[\s""';]*charset\s*=[\s""']*([^\s""'/>]*)"' RegexOptions.IgnoreCase); " is 169.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,CrawlAsync,The length of the statement  "                    robotsDotTextCrawlDelayInSecs = _robotsDotText.GetCrawlDelay(_crawlContext.CrawlConfiguration.RobotsDotTextUserAgentString); " is 124.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,CrawlAsync,The length of the statement  "            //Use whichever value is greater between the actual crawl delay value found' the max allowed crawl delay value or the minimum crawl delay required for every domain " is 163.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,CrawlAsync,The length of the statement  "            if (robotsDotTextCrawlDelayInSecs > 0 && robotsDotTextCrawlDelayInMillisecs > _crawlContext.CrawlConfiguration.MinCrawlDelayPerDomainMilliSeconds) " is 146.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,CrawlAsync,The length of the statement  "                    Log.Warning("[{0}] robot.txt file directive [Crawl-delay: {1}] is above the value set in the config value MaxRobotsDotTextCrawlDelay' will use MaxRobotsDotTextCrawlDelay value instead."' uri' _crawlContext.CrawlConfiguration.MaxRobotsDotTextCrawlDelayInSeconds); " is 262.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,CrawlAsync,The length of the statement  "                Log.Warning("[{0}] robot.txt file directive [Crawl-delay: {1}] will be respected."' uri' robotsDotTextCrawlDelayInSecs); " is 120.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                allowedByRobots = _robotsDotText.IsUrlAllowed(pageToCrawl.Uri.AbsoluteUri' _crawlContext.CrawlConfiguration.RobotsDotTextUserAgentString); " is 138.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "            //https://github.com/sjdirect/abot/issues/96 Handle scenario where the root is allowed but all the paths below are disallowed like "disallow: /*" " is 145.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                var anyPathOffRoot = pageToCrawl.Uri.AbsoluteUri.EndsWith("/") ? pageToCrawl.Uri.AbsoluteUri + "aaaaa": pageToCrawl.Uri.AbsoluteUri + "/aaaaa"; " is 143.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                allPathsBelowRootAllowedByRobots = _robotsDotText.IsUrlAllowed(anyPathOffRoot' _crawlContext.CrawlConfiguration.RobotsDotTextUserAgentString); " is 142.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                    var message = string.Format("Page [{0}] [Disallowed by robots.txt file]' however since IsIgnoreRobotsDotTextIfRootDisallowedEnabled is set to true the robots.txt file will be ignored for this site."' pageToCrawl.Uri.AbsoluteUri); " is 229.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                    var message = string.Format("All Pages below [{0}] [Disallowed by robots.txt file]' however since IsIgnoreRobotsDotTextIfRootDisallowedEnabled is set to true the robots.txt file will be ignored for this site."' pageToCrawl.Uri.AbsoluteUri); " is 240.
Long Statement,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                var message = string.Format("Page [{0}] not crawled' [Disallowed by robots.txt file]' set IsRespectRobotsDotText=false in config file if you would like to ignore robots.txt files."' pageToCrawl.Uri.AbsoluteUri); " is 211.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,CrawlAsync,The length of the statement  "                Log.Information("Starting memory usage for site [{0}] is [{1}mb]"' uri.AbsoluteUri' _crawlContext.MemoryUsageBeforeCrawlInMb); " is 126.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,CrawlAsync,The length of the statement  "                Log.Information("Ending memory usage for site [{0}] is [{1}mb]"' uri.AbsoluteUri' _crawlContext.MemoryUsageAfterCrawlInMb); " is 123.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,CrawlAsync,The length of the statement  "            Log.Information("Crawl complete for site [{0}]: Crawled [{1}] pages in [{2}]"' _crawlResult.RootUri.AbsoluteUri' _crawlResult.CrawlContext.CrawledCount' _crawlResult.Elapsed); " is 175.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,FirePageCrawlStartingEvent,The length of the statement  "                Log.Error("An unhandled exception was thrown by a subscriber of the PageCrawlStarting event for url:" + pageToCrawl.Uri.AbsoluteUri); " is 133.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,FirePageCrawlCompletedEvent,The length of the statement  "                Log.Error("An unhandled exception was thrown by a subscriber of the PageCrawlCompleted event for url:" + crawledPage.Uri.AbsoluteUri); " is 134.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,FirePageCrawlDisallowedEvent,The length of the statement  "                Log.Error("An unhandled exception was thrown by a subscriber of the PageCrawlDisallowed event for url:" + pageToCrawl.Uri.AbsoluteUri); " is 135.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,FirePageLinksCrawlDisallowedEvent,The length of the statement  "                Log.Error("An unhandled exception was thrown by a subscriber of the PageLinksCrawlDisallowed event for url:" + crawledPage.Uri.AbsoluteUri); " is 140.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,CrawlSite,The length of the statement  "                else if (!_threadManager.HasRunningThreads() && _processingPageCount < 1)//Ok that _processingPageCount could be a race condition' will be caught on the next loop iteration " is 172.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,CrawlThePage,The length of the statement  "            var crawledPage = await _pageRequester.MakeRequestAsync(pageToCrawl.Uri' ShouldDownloadPageContent).ConfigureAwait(false); " is 122.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,CrawlThePage,The length of the statement  "                Log.Information("Page crawl complete' Status:[NA] Url:[{0}] Elapsed:[{1}] Parent:[{2}] Retry:[{3}]"' crawledPage.Uri.AbsoluteUri' crawledPage.Elapsed' crawledPage.ParentUri' crawledPage.RetryCount); " is 198.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,CrawlThePage,The length of the statement  "                Log.Information("Page crawl complete' Status:[{0}] Url:[{1}] Elapsed:[{2}] Parent:[{3}] Retry:[{4}]"' Convert.ToInt32(crawledPage.HttpResponseMessage.StatusCode)' crawledPage.Uri.AbsoluteUri' crawledPage.Elapsed' crawledPage.ParentUri' crawledPage.RetryCount); " is 260.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,VerifyRequiredAvailableMemory,The length of the statement  "                throw new InsufficientMemoryException($"Process does not have the configured [{_crawlContext.CrawlConfiguration.MinAvailableMemoryRequiredInMb}mb] of available memory to crawl site [{_crawlContext.RootUri}]. This is configurable through the minAvailableMemoryRequiredInMb in app.conf or CrawlConfiguration.MinAvailableMemoryRequiredInMb."); " is 340.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,CheckMemoryUsage,The length of the statement  "                var message = string.Format("Process is using [{0}mb] of memory which is above the max configured of [{1}mb] for site [{2}]. This is configurable through the maxMemoryUsageInMb in app.conf or CrawlConfiguration.MaxMemoryUsageInMb."' currentMemoryUsage' _crawlContext.CrawlConfiguration.MaxMemoryUsageInMb' _crawlContext.RootUri); " is 329.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,HandleCrawlTimeout,The length of the statement  "            Log.Information("Crawl timeout of [{0}] seconds has been reached for [{1}]"' _crawlContext.CrawlConfiguration.CrawlTimeoutSeconds' _crawlContext.RootUri); " is 154.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,ProcessRedirect,The length of the statement  "                Log.Warning("Page [{0}] is part of a chain of 20 or more consecutive redirects' redirects for this chain will now be aborted."' crawledPage.Uri); " is 145.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,PageSizeIsAboveMax,The length of the statement  "                Log.Information("Page [{0}] has a page size of [{1}] bytes which is above the [{2}] byte max' no further processing will occur for this page"' crawledPage.Uri' crawledPage.Content.Bytes.Length' _crawlContext.CrawlConfiguration.MaxPageSizeInBytes); " is 247.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,ShouldCrawlPageLinks,The length of the statement  "                shouldCrawlPageLinksDecision = (ShouldCrawlPageLinksDecisionMaker != null) ? ShouldCrawlPageLinksDecisionMaker.Invoke(crawledPage' _crawlContext) : new CrawlDecision { Allow = true }; " is 183.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,ShouldCrawlPage,The length of the statement  "                shouldCrawlPageDecision = (ShouldCrawlPageDecisionMaker != null) ? ShouldCrawlPageDecisionMaker(pageToCrawl' _crawlContext) : new CrawlDecision { Allow = true }; " is 161.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,ShouldRecrawlPage,The length of the statement  "                shouldRecrawlPageDecision = (ShouldRecrawlPageDecisionMaker != null) ? ShouldRecrawlPageDecisionMaker(crawledPage' _crawlContext) : new CrawlDecision { Allow = true }; " is 167.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,SchedulePageLinks,The length of the statement  "                    (ShouldScheduleLinkDecisionMaker == null || ShouldScheduleLinkDecisionMaker.Invoke(hyperLink.HrefValue' crawledPage' _crawlContext))) " is 133.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,SchedulePageLinks,The length of the statement  "                    try //Added due to a bug in the Uri class related to this (http://stackoverflow.com/questions/2814951/system-uriformatexception-invalid-uri-the-hostname-could-not-be-parsed) " is 173.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,SchedulePageLinks,The length of the statement  "                            Log.Information("MaxLinksPerPage has been reached. No more links will be scheduled for current page [{0}]."' crawledPage.Uri); " is 126.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,ShouldScheduleMorePageLink,The length of the statement  "            return _crawlContext.CrawlConfiguration.MaxLinksPerPage == 0 || _crawlContext.CrawlConfiguration.MaxLinksPerPage > linksAdded; " is 126.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,ShouldDownloadPageContent,The length of the statement  "                decision = (ShouldDownloadPageContentDecisionMaker != null) ? ShouldDownloadPageContentDecisionMaker.Invoke(crawledPage' _crawlContext) : new CrawlDecision { Allow = true }; " is 173.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,WaitMinimumRetryDelay,The length of the statement  "                Log.Warning("pageToCrawl.LastRequest value is null for Url:{0}. Cannot retry without this value."' pageToCrawl.Uri.AbsoluteUri); " is 128.
Long Statement,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,WaitMinimumRetryDelay,The length of the statement  "            //TODO Cannot use RateLimiter since it currently cannot handle dynamic sleep times so using Thread.Sleep in the meantime " is 120.
Long Statement,Abot2.Util,GcMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\GcMemoryMonitor.cs,GetCurrentUsageInMb,The length of the statement  "            Log.Debug("GC reporting [{0}mb] currently thought to be allocated' took [{1}] millisecs"' currentUsageInMb' timer.ElapsedMilliseconds); " is 135.
Long Statement,Abot2.Util,MemoryManager,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\MemoryManager.cs,IsSpaceAvailable,The length of the statement  "                Log.Warning("MemoryFailPoint is not implemented on this platform. The MemoryManager.IsSpaceAvailable() will just return true."); " is 128.
Long Statement,Abot2.Util,RateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\RateLimiter.cs,ExitTimerCallback,The length of the statement  "            var timeUntilNextCheck = exitTimeValid ? Math.Min(TimeUnitMilliseconds' Math.Max(0' exitTime - Environment.TickCount)) : TimeUnitMilliseconds; " is 142.
Long Statement,Abot2.Util,TaskThreadManager,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\TaskThreadManager.cs,HandleAggregateExceptions,The length of the statement  "                    Log.Warning("CancellationRequested Aggregate Exception: {0}"' exception);//If the task was cancelled then this exception is expected happen and we dont care " is 156.
Complex Conditional,Abot2.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The conditional expression  "!pageToCrawl.IsRetry &&                  crawlContext.CrawlConfiguration.MaxPagesToCrawlPerDomain > 0 &&                  crawlContext.CrawlCountByDomain.TryGetValue(pageToCrawl.Uri.Authority' out pagesCrawledInThisDomain) &&                  pagesCrawledInThisDomain > 0"  is complex.
Complex Conditional,Abot2.Core,RobotsDotTextFinder,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\RobotsDotTextFinder.cs,FindAsync,The conditional expression  "page == null ||                   page.HttpRequestException != null ||                   page.HttpResponseMessage == null ||                   page.HttpResponseMessage.StatusCode != HttpStatusCode.OK"  is complex.
Virtual Method Call from Constructor,Abot2.Util,CachedMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\CachedMemoryMonitor.cs,CachedMemoryMonitor,The constructor "CachedMemoryMonitor" calls a virtual method "UpdateCurrentUsageValue".
Virtual Method Call from Constructor,Abot2.Util,CachedMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\CachedMemoryMonitor.cs,CachedMemoryMonitor,The constructor "CachedMemoryMonitor" calls a virtual method "UpdateCurrentUsageValue".
Empty Catch Block,Abot2.Core,HyperLinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\HyperLinkParser.cs,GetUris,The method has an empty catch block.
Empty Catch Block,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,ProcessRedirect,The method has an empty catch block.
Empty Catch Block,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,SchedulePageLinks,The method has an empty catch block.
Magic Number,Abot2.Core,BloomFilterCrawledUrlRepository,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\BloomFilterCrawledUrlRepository.cs,BloomFilterCrawledUrlRepository,The following statement contains a magic number: BloomFilter = bloomFilter ?? new BloomFilter<string>(2000001' 0.001F);
Magic Number,Abot2.Core,BloomFilterCrawledUrlRepository,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\BloomFilterCrawledUrlRepository.cs,BloomFilterCrawledUrlRepository,The following statement contains a magic number: BloomFilter = bloomFilter ?? new BloomFilter<string>(2000001' 0.001F);
Magic Number,Abot2.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\DomainRateLimiter.cs,DomainRateLimiter,The following statement contains a magic number: _defaultMinCrawlDelayInMillisecs = minCrawlDelayMillisecs + 20;
Magic Number,Abot2.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\DomainRateLimiter.cs,RateLimit,The following statement contains a magic number: timer.ElapsedMilliseconds > 10
Magic Number,Abot2.Core,PageRequester,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\PageRequester.cs,MakeRequestAsync,The following statement contains a magic number: statusCode < 200 || statusCode > 399
Magic Number,Abot2.Core,PageRequester,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\PageRequester.cs,MakeRequestAsync,The following statement contains a magic number: statusCode < 200 || statusCode > 399
Magic Number,Abot2.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\WebContentExtractor.cs,GetCharsetFromHeaders,The following statement contains a magic number: charset = ctype.Substring(ind + 8);
Magic Number,Abot2.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\WebContentExtractor.cs,GetCharsetFromBody,The following statement contains a magic number: charset = string.IsNullOrWhiteSpace(match.Groups[2].Value) ? null : match.Groups[2].Value;
Magic Number,Abot2.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Core\WebContentExtractor.cs,GetCharsetFromBody,The following statement contains a magic number: charset = string.IsNullOrWhiteSpace(match.Groups[2].Value) ? null : match.Groups[2].Value;
Magic Number,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,CrawlAsync,The following statement contains a magic number: robotsDotTextCrawlDelayInMillisecs = robotsDotTextCrawlDelayInSecs * 1000;
Magic Number,Abot2.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\PoliteWebCrawler.cs,CrawlAsync,The following statement contains a magic number: robotsDotTextCrawlDelayInMillisecs = robotsDotTextCrawlDelayInSecs * 1000;
Magic Number,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,CrawlAsync,The following statement contains a magic number: _timeoutTimer = new Timer(_crawlContext.CrawlConfiguration.CrawlTimeoutSeconds * 1000);
Magic Number,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,ProcessRedirect,The following statement contains a magic number: crawledPage.RedirectPosition >= 20
Magic Number,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,IsRedirect,The following statement contains a magic number: isRedirect = (_crawlContext.CrawlConfiguration.IsHttpRequestAutoRedirectsEnabled &&                      crawledPage.HttpResponseMessage.RequestMessage.RequestUri != null &&                      crawledPage.HttpResponseMessage.RequestMessage.RequestUri.AbsoluteUri != crawledPage.Uri.AbsoluteUri) ||                      (!_crawlContext.CrawlConfiguration.IsHttpRequestAutoRedirectsEnabled &&                      (int)crawledPage.HttpResponseMessage.StatusCode >= 300 &&                      (int)crawledPage.HttpResponseMessage.StatusCode <= 399);
Magic Number,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,IsRedirect,The following statement contains a magic number: isRedirect = (_crawlContext.CrawlConfiguration.IsHttpRequestAutoRedirectsEnabled &&                      crawledPage.HttpResponseMessage.RequestMessage.RequestUri != null &&                      crawledPage.HttpResponseMessage.RequestMessage.RequestUri.AbsoluteUri != crawledPage.Uri.AbsoluteUri) ||                      (!_crawlContext.CrawlConfiguration.IsHttpRequestAutoRedirectsEnabled &&                      (int)crawledPage.HttpResponseMessage.StatusCode >= 300 &&                      (int)crawledPage.HttpResponseMessage.StatusCode <= 399);
Magic Number,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,PrintConfigValues,The following statement contains a magic number: var indentString = new string(' '' 2);
Magic Number,Abot2.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Crawler\WebCrawler.cs,WaitMinimumRetryDelay,The following statement contains a magic number: milliToWait = pageToCrawl.RetryAfter.Value * 1000 - milliSinceLastRequest;
Magic Number,Abot2.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: MaxConcurrentThreads = 10;
Magic Number,Abot2.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: MaxPagesToCrawl = 1000;
Magic Number,Abot2.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: MaxRobotsDotTextCrawlDelayInSeconds = 5;
Magic Number,Abot2.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: HttpRequestMaxAutoRedirects = 7;
Magic Number,Abot2.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: MaxCrawlDepth = 100;
Magic Number,Abot2.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: HttpServicePointConnectionLimit = 200;
Magic Number,Abot2.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: HttpRequestTimeoutInSeconds = 15;
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,BestK,The following statement contains a magic number: return (int)Math.Round(Math.Log(2.0) * BestM(capacity' errorRate) / capacity);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,BestM,The following statement contains a magic number: return (int)Math.Ceiling(capacity * Math.Log(errorRate' (1.0 / Math.Pow(2' Math.Log(2.0)))));
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,BestM,The following statement contains a magic number: return (int)Math.Ceiling(capacity * Math.Log(errorRate' (1.0 / Math.Pow(2' Math.Log(2.0)))));
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,BestErrorRate,The following statement contains a magic number: return (float)Math.Pow(0.6185' int.MaxValue / capacity);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = ~x + (x << 15);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x ^ (x >> 12);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x + (x << 2);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x ^ (x >> 4);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x * 2057;
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x ^ (x >> 16);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash += (hash << 10);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash ^= (hash >> 6);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash += (hash << 3);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash ^= (hash >> 11);
Magic Number,Abot2.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash += (hash << 15);
Magic Number,Abot2.Util,CachedMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\CachedMemoryMonitor.cs,CachedMemoryMonitor,The following statement contains a magic number: cacheExpirationInSeconds = 5;
Magic Number,Abot2.Util,CachedMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\CachedMemoryMonitor.cs,CachedMemoryMonitor,The following statement contains a magic number: _usageRefreshTimer = new Timer(cacheExpirationInSeconds * 1000);
Magic Number,Abot2.Util,GcMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\GcMemoryMonitor.cs,GetCurrentUsageInMb,The following statement contains a magic number: var currentUsageInMb = Convert.ToInt32(GC.GetTotalMemory(false) / (1024 * 1024));
Magic Number,Abot2.Util,GcMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\GcMemoryMonitor.cs,GetCurrentUsageInMb,The following statement contains a magic number: var currentUsageInMb = Convert.ToInt32(GC.GetTotalMemory(false) / (1024 * 1024));
Magic Number,Abot2.Util,ThreadManager,D:\research\architectureSmells\repos1\sjdirect_abot\Abot2\Util\ThreadManager.cs,ThreadManager,The following statement contains a magic number: (maxThreads > 100) || (maxThreads < 1)
