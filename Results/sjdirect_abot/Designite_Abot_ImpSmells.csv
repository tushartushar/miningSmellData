Implementation smell,Namespace,Class,File,Method,Description
Complex Method,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,Cyclomatic complexity of the method is 10
Complex Method,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldDownloadPageContent,Cyclomatic complexity of the method is 9
Complex Method,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,Crawl,Cyclomatic complexity of the method is 8
Complex Method,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ProcessPage,Cyclomatic complexity of the method is 8
Long Parameter List,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,PoliteWebCrawler,The method has 9 parameters. Parameters: crawlConfiguration' crawlDecisionMaker' threadManager' scheduler' pageRequester' hyperLinkParser' memoryManager' domainRateLimiter' robotsDotTextFinder
Long Parameter List,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,WebCrawler,The method has 7 parameters. Parameters: crawlConfiguration' crawlDecisionMaker' threadManager' scheduler' pageRequester' hyperLinkParser' memoryManager
Long Parameter List,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,BloomFilter,The method has 5 parameters. Parameters: capacity' errorRate' hashFunction' m' k
Long Identifier,Abot.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\DomainRateLimiter.cs,,The length of the parameter _defaultMinCrawlDelayInMillisecs is 32.
Long Identifier,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,Crawl,The length of the parameter robotsDotTextCrawlDelayInMillisecs is 34.
Long Identifier,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the parameter allPathsBelowRootAllowedByRobots is 32.
Long Identifier,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,,The length of the parameter _maxPagesToCrawlLimitReachedOrScheduled is 39.
Long Identifier,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,,The length of the parameter _shouldDownloadPageContentDecisionMaker is 39.
Long Identifier,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,,The length of the parameter _shouldCrawlPageLinksDecisionMaker is 34.
Long Identifier,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,,The length of the parameter _shouldRecrawlPageDecisionMaker is 31.
Long Identifier,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,,The length of the parameter _shouldScheduleLinkDecisionMaker is 32.
Long Identifier,Abot.Util,ThreadManager,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\ThreadManager.cs,RunAction,The length of the parameter decrementRunningThreadCountOnCompletion is 39.
Long Statement,Abot.Core,AngleSharpHyperlinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\AngleSharpHyperLinkParser.cs,HasRelNoFollow,The length of the statement  "            return _config.IsRespectAnchorRelNoFollowEnabled && (e.HasAttribute("rel") && e.GetAttribute("rel").ToLower().Trim() == "nofollow"); " is 132.
Long Statement,Abot.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\WebContentExtractor.cs,GetCharsetFromBody,The length of the statement  "                //find expression from : http://stackoverflow.com/questions/3458217/how-to-use-regular-expression-to-match-the-charset-string-in-html " is 133.
Long Statement,Abot.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\WebContentExtractor.cs,GetCharsetFromBody,The length of the statement  "                Match match = Regex.Match(body' @"<meta(?!\s*(?:name|value)\s*=)(?:[^>]*?content\s*=[\s""']*)?([^>]*?)[\s""';]*charset\s*=[\s""']*([^\s""'/>]*)"' RegexOptions.IgnoreCase); " is 171.
Long Statement,Abot.Core,HapHyperLinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\HapHyperLinkParser.cs,GetMetaRobotsValue,The length of the statement  "            HtmlNode robotsNode = crawledPage.HtmlDocument.DocumentNode.SelectSingleNode("//meta[translate(@name''ABCDEFGHIJKLMNOPQRSTUVWXYZ'''abcdefghijklmnopqrstuvwxyz')='robots']"); " is 172.
Long Statement,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The length of the statement  "            if (pageToCrawl.RedirectedFrom != null && pageToCrawl.RedirectPosition > crawlContext.CrawlConfiguration.HttpRequestMaxAutoRedirects) " is 133.
Long Statement,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The length of the statement  "                return new CrawlDecision { Allow = false' Reason = string.Format("HttpRequestMaxAutoRedirects limit of [{0}] has been reached"' crawlContext.CrawlConfiguration.HttpRequestMaxAutoRedirects) }; " is 191.
Long Statement,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The length of the statement  "                return new CrawlDecision { Allow = false' Reason = string.Format("MaxPagesToCrawl limit of [{0}] has been reached"' crawlContext.CrawlConfiguration.MaxPagesToCrawl) }; " is 167.
Long Statement,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The length of the statement  "                    return new CrawlDecision { Allow = false' Reason = string.Format("MaxPagesToCrawlPerDomain limit of [{0}] has been reached for domain [{1}]"' crawlContext.CrawlConfiguration.MaxPagesToCrawlPerDomain' pageToCrawl.Uri.Authority) }; " is 229.
Long Statement,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldDownloadPageContent,The length of the statement  "                return new CrawlDecision { Allow = false' Reason = "Content type is not any of the following: " + string.Join("'"' cleanDownloadableContentTypes) }; " is 148.
Long Statement,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldDownloadPageContent,The length of the statement  "            if (crawlContext.CrawlConfiguration.MaxPageSizeInBytes > 0 && crawledPage.HttpWebResponse.ContentLength > crawlContext.CrawlConfiguration.MaxPageSizeInBytes) " is 157.
Long Statement,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldDownloadPageContent,The length of the statement  "                return new CrawlDecision { Allow = false' Reason = string.Format("Page size of [{0}] bytes is above the max allowable of [{1}] bytes"' crawledPage.HttpWebResponse.ContentLength' crawlContext.CrawlConfiguration.MaxPageSizeInBytes) }; " is 232.
Long Statement,Abot.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\DomainRateLimiter.cs,AddDomain,The length of the statement  "            GetRateLimiter(uri' Math.Max(minCrawlDelayInMillisecs' _defaultMinCrawlDelayInMillisecs));//just calling this method adds the new domain " is 136.
Long Statement,Abot.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\DomainRateLimiter.cs,AddOrUpdateDomain,The length of the statement  "                _logger.DebugFormat("Added/updated domain [{0}] with minCrawlDelayInMillisecs of [{1}] milliseconds"' uri.Authority' delayToUse); " is 129.
Long Statement,Abot.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\DomainRateLimiter.cs,GetRateLimiter,The length of the statement  "                    _logger.DebugFormat("Added new domain [{0}] with minCrawlDelayInMillisecs of [{1}] milliseconds"' uri.Authority' minCrawlDelayInMillisecs); " is 139.
Long Statement,Abot.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\DomainRateLimiter.cs,GetRateLimiter,The length of the statement  "                    _logger.WarnFormat("Unable to add new domain [{0}] with minCrawlDelayInMillisecs of [{1}] milliseconds"' uri.Authority' minCrawlDelayInMillisecs); " is 146.
Long Statement,Abot.Core,RobotsDotTextFinder,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\RobotsDotTextFinder.cs,Find,The length of the statement  "            if (page == null || page.WebException != null || page.HttpWebResponse == null || page.HttpWebResponse.StatusCode != HttpStatusCode.OK) " is 134.
Long Statement,Abot.Core,HyperLinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\HyperLinkParser.cs,GetLinks,The length of the statement  "            _logger.DebugFormat("{0} parsed links from [{1}] in [{2}] milliseconds"' ParserType' crawledPage.Uri' timer.ElapsedMilliseconds); " is 129.
Long Statement,Abot.Core,HyperLinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\HyperLinkParser.cs,GetUris,The length of the statement  "            //Using HttpWebRequest.Address instead of HttpWebResonse.ResponseUri since this is the best practice and mentioned on http://msdn.microsoft.com/en-us/library/system.net.httpwebresponse.responseuri.aspx " is 201.
Long Statement,Abot.Core,HyperLinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\HyperLinkParser.cs,HasRobotsNoFollow,The length of the statement  "                    _logger.InfoFormat("Http header X-Robots-Tag nofollow detected on uri [{0}]' will not crawl links on this page."' crawledPage.Uri); " is 131.
Long Statement,Abot.Core,HyperLinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\HyperLinkParser.cs,HasRobotsNoFollow,The length of the statement  "                    _logger.InfoFormat("Meta Robots nofollow tag detected on uri [{0}]' will not crawl links on this page."' crawledPage.Uri); " is 122.
Long Statement,Abot.Core,PageRequester,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\PageRequester.cs,MakeRequest,The length of the statement  "                            _logger.DebugFormat("Links on page [{0}] not crawled' [{1}]"' crawledPage.Uri.AbsoluteUri' shouldDownloadContentDecision.Reason); " is 129.
Long Statement,Abot.Core,PageRequester,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\PageRequester.cs,BuildRequestObject,The length of the statement  "                string credentials = Convert.ToBase64String(System.Text.Encoding.ASCII.GetBytes(_config.LoginUser + ":" + _config.LoginPassword)); " is 130.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,Crawl,The length of the statement  "                    robotsDotTextCrawlDelayInSecs = _robotsDotText.GetCrawlDelay(_crawlContext.CrawlConfiguration.RobotsDotTextUserAgentString); " is 124.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,Crawl,The length of the statement  "            //Use whichever value is greater between the actual crawl delay value found' the max allowed crawl delay value or the minimum crawl delay required for every domain " is 163.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,Crawl,The length of the statement  "            if (robotsDotTextCrawlDelayInSecs > 0 && robotsDotTextCrawlDelayInMillisecs > _crawlContext.CrawlConfiguration.MinCrawlDelayPerDomainMilliSeconds) " is 146.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,Crawl,The length of the statement  "                    _logger.WarnFormat("[{0}] robot.txt file directive [Crawl-delay: {1}] is above the value set in the config value MaxRobotsDotTextCrawlDelay' will use MaxRobotsDotTextCrawlDelay value instead."' uri' _crawlContext.CrawlConfiguration.MaxRobotsDotTextCrawlDelayInSeconds); " is 269.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,Crawl,The length of the statement  "                _logger.WarnFormat("[{0}] robot.txt file directive [Crawl-delay: {1}] will be respected."' uri' robotsDotTextCrawlDelayInSecs); " is 127.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                allowedByRobots = _robotsDotText.IsUrlAllowed(pageToCrawl.Uri.AbsoluteUri' _crawlContext.CrawlConfiguration.RobotsDotTextUserAgentString); " is 138.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "            //https://github.com/sjdirect/abot/issues/96 Handle scenario where the root is allowed but all the paths below are disallowed like "disallow: /*" " is 145.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                var anyPathOffRoot = pageToCrawl.Uri.AbsoluteUri.EndsWith("/") ? pageToCrawl.Uri.AbsoluteUri + "aaaaa": pageToCrawl.Uri.AbsoluteUri + "/aaaaa"; " is 143.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                allPathsBelowRootAllowedByRobots = _robotsDotText.IsUrlAllowed(anyPathOffRoot' _crawlContext.CrawlConfiguration.RobotsDotTextUserAgentString); " is 142.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                    string message = string.Format("Page [{0}] [Disallowed by robots.txt file]' however since IsIgnoreRobotsDotTextIfRootDisallowedEnabled is set to true the robots.txt file will be ignored for this site."' pageToCrawl.Uri.AbsoluteUri); " is 232.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                    string message = string.Format("All Pages below [{0}] [Disallowed by robots.txt file]' however since IsIgnoreRobotsDotTextIfRootDisallowedEnabled is set to true the robots.txt file will be ignored for this site."' pageToCrawl.Uri.AbsoluteUri); " is 243.
Long Statement,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,ShouldCrawlPage,The length of the statement  "                string message = string.Format("Page [{0}] not crawled' [Disallowed by robots.txt file]' set IsRespectRobotsDotText=false in config file if you would like to ignore robots.txt files."' pageToCrawl.Uri.AbsoluteUri); " is 214.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,Crawl,The length of the statement  "                _logger.InfoFormat("Starting memory usage for site [{0}] is [{1}mb]"' uri.AbsoluteUri' _crawlContext.MemoryUsageBeforeCrawlInMb); " is 129.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,Crawl,The length of the statement  "                _logger.InfoFormat("Ending memory usage for site [{0}] is [{1}mb]"' uri.AbsoluteUri' _crawlContext.MemoryUsageAfterCrawlInMb); " is 126.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,Crawl,The length of the statement  "            _logger.InfoFormat("Crawl complete for site [{0}]: Crawled [{1}] pages in [{2}]"' _crawlResult.RootUri.AbsoluteUri' _crawlResult.CrawlContext.CrawledCount' _crawlResult.Elapsed); " is 178.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,FirePageCrawlStartingEvent,The length of the statement  "                _logger.Error("An unhandled exception was thrown by a subscriber of the PageCrawlStarting event for url:" + pageToCrawl.Uri.AbsoluteUri); " is 137.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,FirePageCrawlCompletedEvent,The length of the statement  "                _logger.Error("An unhandled exception was thrown by a subscriber of the PageCrawlCompleted event for url:" + crawledPage.Uri.AbsoluteUri); " is 138.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,FirePageCrawlDisallowedEvent,The length of the statement  "                _logger.Error("An unhandled exception was thrown by a subscriber of the PageCrawlDisallowed event for url:" + pageToCrawl.Uri.AbsoluteUri); " is 139.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,FirePageLinksCrawlDisallowedEvent,The length of the statement  "                _logger.Error("An unhandled exception was thrown by a subscriber of the PageLinksCrawlDisallowed event for url:" + crawledPage.Uri.AbsoluteUri); " is 144.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,FirePageCrawlCompletedEventAsync,The length of the statement  "                //Must be fired synchronously to avoid main thread exiting before completion of event handler for first or last page crawled " is 124.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,FirePageCrawlCompletedEventAsync,The length of the statement  "                    _logger.Error("An unhandled exception was thrown by a subscriber of the PageCrawlCompleted event for url:" + crawledPage.Uri.AbsoluteUri); " is 138.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,VerifyRequiredAvailableMemory,The length of the statement  "                throw new InsufficientMemoryException(string.Format("Process does not have the configured [{0}mb] of available memory to crawl site [{1}]. This is configurable through the minAvailableMemoryRequiredInMb in app.conf or CrawlConfiguration.MinAvailableMemoryRequiredInMb."' _crawlContext.CrawlConfiguration.MinAvailableMemoryRequiredInMb' _crawlContext.RootUri)); " is 360.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,CheckMemoryUsage,The length of the statement  "                string message = string.Format("Process is using [{0}mb] of memory which is above the max configured of [{1}mb] for site [{2}]. This is configurable through the maxMemoryUsageInMb in app.conf or CrawlConfiguration.MaxMemoryUsageInMb."' currentMemoryUsage' _crawlContext.CrawlConfiguration.MaxMemoryUsageInMb' _crawlContext.RootUri); " is 332.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,HandleCrawlTimeout,The length of the statement  "            _logger.InfoFormat("Crawl timeout of [{0}] seconds has been reached for [{1}]"' _crawlContext.CrawlConfiguration.CrawlTimeoutSeconds' _crawlContext.RootUri); " is 157.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ProcessRedirect,The length of the statement  "                _logger.WarnFormat("Page [{0}] is part of a chain of 20 or more consecutive redirects' redirects for this chain will now be aborted."' crawledPage.Uri); " is 152.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ProcessRedirect,The length of the statement  "                _logger.DebugFormat("Page [{0}] is requesting that it be redirect to [{1}]"' crawledPage.Uri' crawledPage.RedirectedTo.Uri); " is 124.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,PageSizeIsAboveMax,The length of the statement  "                _logger.InfoFormat("Page [{0}] has a page size of [{1}] bytes which is above the [{2}] byte max' no further processing will occur for this page"' crawledPage.Uri' crawledPage.Content.Bytes.Length' _crawlContext.CrawlConfiguration.MaxPageSizeInBytes); " is 250.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ShouldCrawlPageLinks,The length of the statement  "                shouldCrawlPageLinksDecision = (_shouldCrawlPageLinksDecisionMaker != null) ? _shouldCrawlPageLinksDecisionMaker.Invoke(crawledPage' _crawlContext) : new CrawlDecision { Allow = true }; " is 185.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ShouldCrawlPageLinks,The length of the statement  "                _logger.DebugFormat("Links on page [{0}] not crawled' [{1}]"' crawledPage.Uri.AbsoluteUri' shouldCrawlPageLinksDecision.Reason); " is 128.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ShouldCrawlPage,The length of the statement  "                shouldCrawlPageDecision = (_shouldCrawlPageDecisionMaker != null) ? _shouldCrawlPageDecisionMaker.Invoke(pageToCrawl' _crawlContext) : new CrawlDecision { Allow = true }; " is 170.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ShouldRecrawlPage,The length of the statement  "                shouldRecrawlPageDecision = (_shouldRecrawlPageDecisionMaker != null) ? _shouldRecrawlPageDecisionMaker.Invoke(crawledPage' _crawlContext) : new CrawlDecision { Allow = true }; " is 176.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,CrawlThePage,The length of the statement  "                _logger.InfoFormat("Page crawl complete' Status:[NA] Url:[{0}] Elapsed:[{1}] Parent:[{2}] Retry:[{3}]"' crawledPage.Uri.AbsoluteUri' crawledPage.Elapsed' crawledPage.ParentUri' crawledPage.RetryCount); " is 201.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,CrawlThePage,The length of the statement  "                _logger.InfoFormat("Page crawl complete' Status:[{0}] Url:[{1}] Elapsed:[{2}] Parent:[{3}] Retry:[{4}]"' Convert.ToInt32(crawledPage.HttpWebResponse.StatusCode)' crawledPage.Uri.AbsoluteUri' crawledPage.Elapsed' crawledPage.ParentUri' crawledPage.RetryCount); " is 259.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,SchedulePageLinks,The length of the statement  "                    try //Added due to a bug in the Uri class related to this (http://stackoverflow.com/questions/2814951/system-uriformatexception-invalid-uri-the-hostname-could-not-be-parsed) " is 173.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,SchedulePageLinks,The length of the statement  "                            _logger.InfoFormat("MaxLinksPerPage has been reached. No more links will be scheduled for current page [{0}]."' crawledPage.Uri); " is 129.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ShouldScheduleMorePageLink,The length of the statement  "            return _crawlContext.CrawlConfiguration.MaxLinksPerPage == 0 || _crawlContext.CrawlConfiguration.MaxLinksPerPage > linksAdded; " is 126.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ShouldDownloadPageContent,The length of the statement  "                decision = (_shouldDownloadPageContentDecisionMaker != null) ? _shouldDownloadPageContentDecisionMaker.Invoke(crawledPage' _crawlContext) : new CrawlDecision { Allow = true }; " is 175.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,WaitMinimumRetryDelay,The length of the statement  "                _logger.WarnFormat("pageToCrawl.LastRequest value is null for Url:{0}. Cannot retry without this value."' pageToCrawl.Uri.AbsoluteUri); " is 135.
Long Statement,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,WaitMinimumRetryDelay,The length of the statement  "            //TODO Cannot use RateLimiter since it currently cannot handle dynamic sleep times so using Thread.Sleep in the meantime " is 120.
Long Statement,Abot.Poco,CrawledPage,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Poco\CrawledPage.cs,InitializeHtmlAgilityPackDocument,The length of the statement  "            hapDoc.OptionMaxNestedChildNodes = 5000;//did not make this an externally configurable property since it is really an internal issue to hap " is 139.
Long Statement,Abot.Util,GcMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\GcMemoryMonitor.cs,GetCurrentUsageInMb,The length of the statement  "            _logger.DebugFormat("GC reporting [{0}mb] currently thought to be allocated' took [{1}] millisecs"' currentUsageInMb' timer.ElapsedMilliseconds); " is 145.
Long Statement,Abot.Util,MemoryManager,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\MemoryManager.cs,IsSpaceAvailable,The length of the statement  "                _logger.Warn("MemoryFailPoint is not implemented on this platform. The MemoryManager.IsSpaceAvailable() will just return true."); " is 129.
Long Statement,Abot.Util,RateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\RateLimiter.cs,ExitTimerCallback,The length of the statement  "            var timeUntilNextCheck = exitTimeValid ? Math.Min(TimeUnitMilliseconds' Math.Max(0' exitTime - Environment.TickCount)) : TimeUnitMilliseconds; " is 142.
Complex Conditional,Abot.Core,CrawlDecisionMaker,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\CrawlDecisionMaker.cs,ShouldCrawlPage,The conditional expression  "!pageToCrawl.IsRetry &&                  crawlContext.CrawlConfiguration.MaxPagesToCrawlPerDomain > 0 &&                  crawlContext.CrawlCountByDomain.TryGetValue(pageToCrawl.Uri.Authority' out pagesCrawledInThisDomain) &&                  pagesCrawledInThisDomain > 0"  is complex.
Complex Conditional,Abot.Core,RobotsDotTextFinder,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\RobotsDotTextFinder.cs,Find,The conditional expression  "page == null || page.WebException != null || page.HttpWebResponse == null || page.HttpWebResponse.StatusCode != HttpStatusCode.OK"  is complex.
Virtual Method Call from Constructor,Abot.Util,CachedMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\CachedMemoryMonitor.cs,CachedMemoryMonitor,The constructor "CachedMemoryMonitor" calls a virtual method "UpdateCurrentUsageValue".
Virtual Method Call from Constructor,Abot.Util,CachedMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\CachedMemoryMonitor.cs,CachedMemoryMonitor,The constructor "CachedMemoryMonitor" calls a virtual method "UpdateCurrentUsageValue".
Empty Catch Block,Abot.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\WebContentExtractor.cs,GetEncoding,The method has an empty catch block.
Empty Catch Block,Abot.Core,HyperLinkParser,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\HyperLinkParser.cs,GetUris,The method has an empty catch block.
Empty Catch Block,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ProcessRedirect,The method has an empty catch block.
Empty Catch Block,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,SchedulePageLinks,The method has an empty catch block.
Magic Number,Abot.Core,BloomFilterCrawledUrlRepository,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\BloomFilterCrawledUrlRepository.cs,BloomFilterCrawledUrlRepository,The following statement contains a magic number: BloomFilter = bloomFilter ?? new BloomFilter<string>(2000001' 0.001F);
Magic Number,Abot.Core,BloomFilterCrawledUrlRepository,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\BloomFilterCrawledUrlRepository.cs,BloomFilterCrawledUrlRepository,The following statement contains a magic number: BloomFilter = bloomFilter ?? new BloomFilter<string>(2000001' 0.001F);
Magic Number,Abot.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\WebContentExtractor.cs,GetCharsetFromHeaders,The following statement contains a magic number: charset = ctype.Substring(ind + 8);
Magic Number,Abot.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\WebContentExtractor.cs,GetCharsetFromBody,The following statement contains a magic number: charset = string.IsNullOrWhiteSpace(match.Groups[2].Value) ? null : match.Groups[2].Value;
Magic Number,Abot.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\WebContentExtractor.cs,GetCharsetFromBody,The following statement contains a magic number: charset = string.IsNullOrWhiteSpace(match.Groups[2].Value) ? null : match.Groups[2].Value;
Magic Number,Abot.Core,WebContentExtractor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\WebContentExtractor.cs,GetRawData,The following statement contains a magic number: byte[] buffer = new byte[1024];
Magic Number,Abot.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\DomainRateLimiter.cs,DomainRateLimiter,The following statement contains a magic number: _defaultMinCrawlDelayInMillisecs = minCrawlDelayMillisecs + 20;
Magic Number,Abot.Core,DomainRateLimiter,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\DomainRateLimiter.cs,RateLimit,The following statement contains a magic number: timer.ElapsedMilliseconds > 10
Magic Number,Abot.Core,PageRequester,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Core\PageRequester.cs,BuildRequestObject,The following statement contains a magic number: request.Timeout = _config.HttpRequestTimeoutInSeconds * 1000;
Magic Number,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,Crawl,The following statement contains a magic number: robotsDotTextCrawlDelayInMillisecs = robotsDotTextCrawlDelayInSecs * 1000;
Magic Number,Abot.Crawler,PoliteWebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\PoliteWebCrawler.cs,Crawl,The following statement contains a magic number: robotsDotTextCrawlDelayInMillisecs = robotsDotTextCrawlDelayInSecs * 1000;
Magic Number,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,Crawl,The following statement contains a magic number: _timeoutTimer = new Timer(_crawlContext.CrawlConfiguration.CrawlTimeoutSeconds * 1000);
Magic Number,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,ProcessRedirect,The following statement contains a magic number: crawledPage.RedirectPosition >= 20
Magic Number,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,IsRedirect,The following statement contains a magic number: isRedirect = (_crawlContext.CrawlConfiguration.IsHttpRequestAutoRedirectsEnabled &&                      crawledPage.HttpWebResponse.ResponseUri != null &&                      crawledPage.HttpWebResponse.ResponseUri.AbsoluteUri != crawledPage.Uri.AbsoluteUri) ||                      (!_crawlContext.CrawlConfiguration.IsHttpRequestAutoRedirectsEnabled &&                      (int) crawledPage.HttpWebResponse.StatusCode >= 300 &&                      (int) crawledPage.HttpWebResponse.StatusCode <= 399);
Magic Number,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,IsRedirect,The following statement contains a magic number: isRedirect = (_crawlContext.CrawlConfiguration.IsHttpRequestAutoRedirectsEnabled &&                      crawledPage.HttpWebResponse.ResponseUri != null &&                      crawledPage.HttpWebResponse.ResponseUri.AbsoluteUri != crawledPage.Uri.AbsoluteUri) ||                      (!_crawlContext.CrawlConfiguration.IsHttpRequestAutoRedirectsEnabled &&                      (int) crawledPage.HttpWebResponse.StatusCode >= 300 &&                      (int) crawledPage.HttpWebResponse.StatusCode <= 399);
Magic Number,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,PrintConfigValues,The following statement contains a magic number: string indentString = new string(' '' 2);
Magic Number,Abot.Crawler,WebCrawler,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Crawler\WebCrawler.cs,WaitMinimumRetryDelay,The following statement contains a magic number: milliToWait = pageToCrawl.RetryAfter.Value*1000 - milliSinceLastRequest;
Magic Number,Abot.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: MaxConcurrentThreads = 10;
Magic Number,Abot.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: MaxPagesToCrawl = 1000;
Magic Number,Abot.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: MaxRobotsDotTextCrawlDelayInSeconds = 5;
Magic Number,Abot.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: HttpRequestMaxAutoRedirects = 7;
Magic Number,Abot.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: MaxCrawlDepth = 100;
Magic Number,Abot.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: HttpServicePointConnectionLimit = 200;
Magic Number,Abot.Poco,CrawlConfiguration,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Poco\CrawlConfiguration.cs,CrawlConfiguration,The following statement contains a magic number: HttpRequestTimeoutInSeconds = 15;
Magic Number,Abot.Poco,CrawledPage,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Poco\CrawledPage.cs,InitializeHtmlAgilityPackDocument,The following statement contains a magic number: hapDoc.OptionMaxNestedChildNodes = 5000;
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,BestK,The following statement contains a magic number: return (int)Math.Round(Math.Log(2.0) * BestM(capacity' errorRate) / capacity);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,BestM,The following statement contains a magic number: return (int)Math.Ceiling(capacity * Math.Log(errorRate' (1.0 / Math.Pow(2' Math.Log(2.0)))));
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,BestM,The following statement contains a magic number: return (int)Math.Ceiling(capacity * Math.Log(errorRate' (1.0 / Math.Pow(2' Math.Log(2.0)))));
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,BestErrorRate,The following statement contains a magic number: return (float)Math.Pow(0.6185' int.MaxValue / capacity);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = ~x + (x << 15);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x ^ (x >> 12);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x + (x << 2);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x ^ (x >> 4);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x * 2057;
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashInt32,The following statement contains a magic number: x = x ^ (x >> 16);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash += (hash << 10);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash ^= (hash >> 6);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash += (hash << 3);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash ^= (hash >> 11);
Magic Number,Abot.Util,BloomFilter<T>,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\BloomFilter.cs,HashString,The following statement contains a magic number: hash += (hash << 15);
Magic Number,Abot.Util,CachedMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\CachedMemoryMonitor.cs,CachedMemoryMonitor,The following statement contains a magic number: cacheExpirationInSeconds = 5;
Magic Number,Abot.Util,CachedMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\CachedMemoryMonitor.cs,CachedMemoryMonitor,The following statement contains a magic number: _usageRefreshTimer = new Timer(cacheExpirationInSeconds * 1000);
Magic Number,Abot.Util,GcMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\GcMemoryMonitor.cs,GetCurrentUsageInMb,The following statement contains a magic number: int currentUsageInMb = Convert.ToInt32(GC.GetTotalMemory(false) / (1024 * 1024));
Magic Number,Abot.Util,GcMemoryMonitor,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\GcMemoryMonitor.cs,GetCurrentUsageInMb,The following statement contains a magic number: int currentUsageInMb = Convert.ToInt32(GC.GetTotalMemory(false) / (1024 * 1024));
Magic Number,Abot.Util,ThreadManager,D:\research\architectureSmells\repos1\sjdirect_abot\Abot\Util\ThreadManager.cs,ThreadManager,The following statement contains a magic number: (maxThreads > 100) || (maxThreads < 1)
