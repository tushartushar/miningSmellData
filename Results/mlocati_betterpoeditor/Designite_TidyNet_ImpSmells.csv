Implementation smell,Namespace,Class,File,Method,Description
Long Method,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,CleanWord2000,The method has 118 lines of code.
Long Method,TidyNet,ClsStreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ClsStreamInImpl.cs,ReadChar,The method has 106 lines of code.
Long Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseEntity,The method has 107 lines of code.
Long Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,SetXhtmlDocType,The method has 107 lines of code.
Long Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FixDocType,The method has 166 lines of code.
Long Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The method has 828 lines of code.
Long Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseAttribute,The method has 118 lines of code.
Long Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseValue,The method has 256 lines of code.
Long Method,TidyNet,ParseHTMLCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 200 lines of code.
Long Method,TidyNet,ParseBodyCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 276 lines of code.
Long Method,TidyNet,ParseInlineCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 525 lines of code.
Long Method,TidyNet,ParseListCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 114 lines of code.
Long Method,TidyNet,ParseDefListCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 127 lines of code.
Long Method,TidyNet,ParsePreCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 192 lines of code.
Long Method,TidyNet,ParseBlockCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 413 lines of code.
Long Method,TidyNet,ParseTableTagCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 125 lines of code.
Long Method,TidyNet,ParseRowGroupCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 141 lines of code.
Long Method,TidyNet,ParseRowCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The method has 143 lines of code.
Long Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The method has 284 lines of code.
Long Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintAttrValue,The method has 155 lines of code.
Long Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The method has 258 lines of code.
Long Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintXmlTree,The method has 119 lines of code.
Long Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintSlide,The method has 101 lines of code.
Long Method,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,Warning,The method has 177 lines of code.
Long Method,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadCharFromStream,The method has 148 lines of code.
Long Method,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadChar,The method has 106 lines of code.
Long Method,TidyNet,Tidy,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Tidy.cs,ParseInternal,The method has 200 lines of code.
Complex Method,TidyNet,AttVal,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\AttVal.cs,CheckAttribute,Cyclomatic complexity of the method is 8
Complex Method,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,CreateProps,Cyclomatic complexity of the method is 10
Complex Method,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,CleanBodyAttrs,Cyclomatic complexity of the method is 11
Complex Method,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,MergeStyles,Cyclomatic complexity of the method is 8
Complex Method,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,Center2Div,Cyclomatic complexity of the method is 8
Complex Method,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,NestedList,Cyclomatic complexity of the method is 9
Complex Method,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,BlockStyle,Cyclomatic complexity of the method is 9
Complex Method,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,CleanNode,Cyclomatic complexity of the method is 9
Complex Method,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,CleanWord2000,Cyclomatic complexity of the method is 17
Complex Method,TidyNet,ClsStreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ClsStreamInImpl.cs,ReadChar,Cyclomatic complexity of the method is 16
Complex Method,TidyNet,DomNodeImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\DomNodeImpl.cs,InsertBefore,Cyclomatic complexity of the method is 12
Complex Method,TidyNet,DomNodeImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\DomNodeImpl.cs,ReplaceChild,Cyclomatic complexity of the method is 18
Complex Method,TidyNet,DomNodeImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\DomNodeImpl.cs,AppendChild,Cyclomatic complexity of the method is 8
Complex Method,TidyNet,ImgCheckTableCheckAttribs,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ImgCheckTableCheckAttribs.cs,Check,Cyclomatic complexity of the method is 12
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseEntity,Cyclomatic complexity of the method is 13
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,Cyclomatic complexity of the method is 16
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,SetXhtmlDocType,Cyclomatic complexity of the method is 13
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ApparentVersion,Cyclomatic complexity of the method is 11
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FixDocType,Cyclomatic complexity of the method is 30
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetCDATA,Cyclomatic complexity of the method is 14
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,Cyclomatic complexity of the method is 112
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseAttribute,Cyclomatic complexity of the method is 16
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseServerInstruction,Cyclomatic complexity of the method is 10
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseValue,Cyclomatic complexity of the method is 36
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,PopInline,Cyclomatic complexity of the method is 11
Complex Method,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,CanPrune,Cyclomatic complexity of the method is 10
Complex Method,TidyNet,Node,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Node.cs,CheckNodeIntegrity,Cyclomatic complexity of the method is 13
Complex Method,TidyNet,OutImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\OutImpl.cs,Outc,Cyclomatic complexity of the method is 15
Complex Method,TidyNet,ParserImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,parseDocument,Cyclomatic complexity of the method is 8
Complex Method,TidyNet,ParserImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,parseXMLElement,Cyclomatic complexity of the method is 14
Complex Method,TidyNet,ParserImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,parseXMLDocument,Cyclomatic complexity of the method is 10
Complex Method,TidyNet,ParseHTMLCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 29
Complex Method,TidyNet,ParseHeadCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 16
Complex Method,TidyNet,ParseTitleCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 9
Complex Method,TidyNet,ParseBodyCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 40
Complex Method,TidyNet,ParseFrameSetCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 11
Complex Method,TidyNet,ParseInlineCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 78
Complex Method,TidyNet,ParseListCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 17
Complex Method,TidyNet,ParseDefListCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 18
Complex Method,TidyNet,ParsePreCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 28
Complex Method,TidyNet,ParseBlockCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 64
Complex Method,TidyNet,ParseTableTagCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 17
Complex Method,TidyNet,ParseColGroupCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 14
Complex Method,TidyNet,ParseRowGroupCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 23
Complex Method,TidyNet,ParseRowCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 23
Complex Method,TidyNet,ParseNoFramesCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 11
Complex Method,TidyNet,ParseTextCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,Cyclomatic complexity of the method is 12
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,WrapLine,Cyclomatic complexity of the method is 9
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,WrapAttrVal,Cyclomatic complexity of the method is 8
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,Cyclomatic complexity of the method is 35
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintAttrValue,Cyclomatic complexity of the method is 23
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintAttribute,Cyclomatic complexity of the method is 13
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTag,Cyclomatic complexity of the method is 9
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,ShouldIndent,Cyclomatic complexity of the method is 11
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,Cyclomatic complexity of the method is 45
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintXmlTree,Cyclomatic complexity of the method is 22
Complex Method,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintSlide,Cyclomatic complexity of the method is 9
Complex Method,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,AttrError,Cyclomatic complexity of the method is 16
Complex Method,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,Warning,Cyclomatic complexity of the method is 39
Complex Method,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,ErrorSummary,Cyclomatic complexity of the method is 18
Complex Method,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadCharFromStream,Cyclomatic complexity of the method is 19
Complex Method,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadChar,Cyclomatic complexity of the method is 16
Complex Method,TidyNet,Tidy,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Tidy.cs,ParseInternal,Cyclomatic complexity of the method is 24
Complex Method,TidyNet,TidyOptions,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\TidyOptions.cs,Adjust,Cyclomatic complexity of the method is 8
Long Parameter List,TidyNet,AttVal,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\AttVal.cs,AttVal,The method has 5 parameters. Parameters: next' dict' delim' attribute' val
Long Parameter List,TidyNet,AttVal,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\AttVal.cs,AttVal,The method has 7 parameters. Parameters: next' dict' asp' php' delim' attribute' val
Long Parameter List,TidyNet,Dict,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Dict.cs,Dict,The method has 5 parameters. Parameters: name' versions' model' parser' checkAttribs
Long Parameter List,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,NewNode,The method has 5 parameters. Parameters: type' textarray' start' end' element
Long Parameter List,TidyNet,Node,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Node.cs,Node,The method has 6 parameters. Parameters: type' textarray' start' end' element' tt
Long Parameter List,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintText,The method has 6 parameters. Parameters: fout' mode' indent' textarray' start' end
Long Parameter List,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintAttrValue,The method has 5 parameters. Parameters: fout' indent' val' delim' wrappable
Long Parameter List,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTag,The method has 5 parameters. Parameters: lexer' fout' mode' indent' node
Long Parameter List,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The method has 5 parameters. Parameters: fout' mode' indent' lexer' node
Long Parameter List,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintXmlTree,The method has 5 parameters. Parameters: fout' mode' indent' lexer' node
Long Parameter List,TidyNet,TidyMessage,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\TidyMessage.cs,TidyMessage,The method has 6 parameters. Parameters: filename' line' column' message' level' options
Long Statement,TidyNet,AlignAttrCheck,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\AlignAttrCheck.cs,Check,The length of the statement  "			else if (!(String.Compare(val' "left") == 0 || String.Compare(val' "center") == 0 || String.Compare(val' "right") == 0 || String.Compare(val' "justify") == 0)) " is 159.
Long Statement,TidyNet,AttVal,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\AttVal.cs,CheckAttribute,The length of the statement  "			else if (!lexer.Options.XmlTags && !(node.Tag == null) && _asp == null && !(node.Tag != null && ((node.Tag.Versions & HtmlVersion.Proprietary) != HtmlVersion.Unknown))) " is 168.
Long Statement,TidyNet,AttVal,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\AttVal.cs,CheckUniqueAttribute,The length of the statement  "				if (Attribute != null && attr.Attribute != null && attr.Asp == null && attr.Php == null && String.Compare(Attribute' attr.Attribute) == 0) " is 138.
Long Statement,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,CreateProps,The length of the statement  "				prop = InsertProperty(prop' style.Substring(name_start' (name_end) - (name_start))' style.Substring(value_start' (value_end) - (value_start))); " is 143.
Long Statement,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,NiceBody,The length of the statement  "				if (body.GetAttrByName("background") != null || body.GetAttrByName("bgcolor") != null || body.GetAttrByName("text") != null || body.GetAttrByName("link") != null || body.GetAttrByName("vlink") != null || body.GetAttrByName("alink") != null) " is 240.
Long Statement,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,PurgeAttributes,The length of the statement  "				else if (attr.Attribute != null && (attr.Attribute.Equals("class") || attr.Attribute.Equals("style") || attr.Attribute.Equals("lang") || attr.Attribute.StartsWith("x:") || ((attr.Attribute.Equals("height") || attr.Attribute.Equals("width")) && (node.Tag == _tt.TagTd || node.Tag == _tt.TagTr || node.Tag == _tt.TagTh)))) " is 320.
Long Statement,TidyNet,DomNodeImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\DomNodeImpl.cs,InsertBefore,The length of the statement  "				if (newCh.Adaptee.Type != Node.StartTag && newCh.Adaptee.Type != Node.StartEndTag && newCh.Adaptee.Type != Node.CommentTag && newCh.Adaptee.Type != Node.TextNode && newCh.Adaptee.Type != Node.CDATATag) " is 201.
Long Statement,TidyNet,DomNodeImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\DomNodeImpl.cs,ReplaceChild,The length of the statement  "				if (newCh.Adaptee.Type != Node.StartTag && newCh.Adaptee.Type != Node.StartEndTag && newCh.Adaptee.Type != Node.CommentTag && newCh.Adaptee.Type != Node.TextNode && newCh.Adaptee.Type != Node.CDATATag) " is 201.
Long Statement,TidyNet,DomNodeImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\DomNodeImpl.cs,AppendChild,The length of the statement  "				if (newCh.Adaptee.Type != Node.StartTag && newCh.Adaptee.Type != Node.StartEndTag && newCh.Adaptee.Type != Node.CommentTag && newCh.Adaptee.Type != Node.TextNode && newCh.Adaptee.Type != Node.CDATATag) " is 201.
Long Statement,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,AddGenerator,The length of the statement  "							if (attval != null && attval.Val != null && attval.Val.Length >= 9 && String.Compare(attval.Val.Substring(0' 9)' "HTML Tidy") == 0) " is 131.
Long Statement,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,CheckDocTypeKeyWords,The length of the statement  "			return !(FindBadSubString("SYSTEM"' s' len) || FindBadSubString("PUBLIC"' s' len) || FindBadSubString("//DTD"' s' len) || FindBadSubString("//W3C"' s' len) || FindBadSubString("//EN"' s' len)); " is 193.
Long Statement,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The length of the statement  "					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart)); " is 140.
Long Statement,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseValue,The length of the statement  "				if (!AttributeTable.DefaultAttributeTable.IsScript(name) && !(AttributeTable.DefaultAttributeTable.IsUrl(name) && (GetString(lexbuf' start' 11)).Equals("javascript:"))) " is 168.
Long Statement,TidyNet,Node,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Node.cs,TrimInitialSpace,The length of the statement  "				if (((element.Tag.Model & ContentModel.Inline) != 0) && !((element.Tag.Model & ContentModel.Field) != 0) && element.Parent.Content != element) " is 142.
Long Statement,TidyNet,Node,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Node.cs,InsertMisc,The length of the statement  "			if (node.Type == CommentTag || node.Type == ProcInsTag || node.Type == CDATATag || node.Type == SectionTag || node.Type == AspTag || node.Type == JsteTag || node.Type == PhpTag) " is 177.
Long Statement,TidyNet,ParserImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,XMLPreserveWhiteSpace,The length of the statement  "			if (String.Compare(element.Element' "pre") == 0 || String.Compare(element.Element' "script") == 0 || String.Compare(element.Element' "style") == 0) " is 147.
Long Statement,TidyNet,ParserImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,isJavaScript,The length of the statement  "				if ((String.Compare(attr.Attribute' "language") == 0 || String.Compare(attr.Attribute' "type") == 0) && wsubstr(attr.Val' "javascript")) " is 136.
Long Statement,TidyNet,ParseInlineCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The length of the statement  "					if (node.Type == Node.StartTag && node.Tag == element.Tag && lexer.IsPushed(node) && !node.Isimplicit && !element.Isimplicit && node.Tag != null && ((node.Tag.Model & ContentModel.Inline) != 0) && node.Tag != tt.TagA && node.Tag != tt.TagFont && node.Tag != tt.TagBig && node.Tag != tt.TagSmall) " is 295.
Long Statement,TidyNet,ParseInlineCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The length of the statement  "					if (node.Tag == tt.TagP && node.Type == Node.StartTag && ((mode & Lexer.Preformatted) != 0 || element.Tag == tt.TagDt || element.IsDescendantOf(tt.TagDt))) " is 155.
Long Statement,TidyNet,ParseInlineCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The length of the statement  "						else if ((node.Tag.Model & ContentModel.Inline) != 0 && node.Tag != tt.TagA && !((node.Tag.Model & ContentModel.Object) != 0) && (element.Tag.Model & ContentModel.Inline) != 0) " is 176.
Long Statement,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintAttrs,The length of the statement  "			if (_options.XmlOut && _options.XmlSpace && ParserImpl.XMLPreserveWhiteSpace(node' _options.tt) && node.GetAttrByName("xml:space") == null) " is 139.
Long Statement,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTag,The length of the statement  "			if ((_options.XmlOut || lexer != null && lexer.isvoyager) && (node.Type == Node.StartEndTag || (node.Tag.Model & ContentModel.Empty) != 0)) " is 139.
Long Statement,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTag,The length of the statement  "						if (!((mode & NOWRAP) != 0) && (!((node.Tag.Model & ContentModel.Inline) != 0) || (node.Tag == tt.TagBr) || (((node.Tag.Model & ContentModel.Empty) != 0) && node.Next == null && node.Parent.Tag == tt.TagA))) " is 207.
Long Statement,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The length of the statement  "						else if ((node.Tag.Model & ContentModel.Html) != 0 || node.Tag == tt.TagNoframes || ((node.Tag.Model & ContentModel.Head) != 0 && !(node.Tag == tt.TagTitle))) " is 158.
Long Statement,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The length of the statement  "							if (last != null && !_options.IndentContent && last.Type == Node.TextNode && content.Tag != null && (content.Tag.Model & ContentModel.Block) != 0) " is 146.
Long Statement,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The length of the statement  "					if (ShouldIndent(node) || (((node.Tag.Model & ContentModel.Html) != 0 || node.Tag == tt.TagNoframes || ((node.Tag.Model & ContentModel.Head) != 0 && !(node.Tag == tt.TagTitle))) && _options.HideEndTags == false)) " is 212.
Long Statement,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The length of the statement  "					if (_options.IndentContent == false && node.Next != null && _options.HideEndTags == false && (node.Tag.Model & (ContentModel.Block | ContentModel.List | ContentModel.Deflist | ContentModel.Table)) != 0) " is 202.
Long Statement,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintSlide,The length of the statement  "				if (last != null && !_options.IndentContent && last.Type == Node.TextNode && content.Tag != null && (content.Tag.Model & ContentModel.Block) != 0) " is 146.
Long Statement,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,Warning,The length of the statement  "				AddMessage(lexer' String.Format(GetMessage("missing_endtag_before")' element.Element' Tag(lexer' node))' MessageLevel.Warning); " is 127.
Long Statement,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,Warning,The length of the statement  "				AddMessage(lexer' String.Format(GetMessage("non_matching_endtag_1")' Tag(lexer' node)' element.Element)' MessageLevel.Warning); " is 127.
Long Statement,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,Warning,The length of the statement  "				AddMessage(lexer' String.Format(GetMessage("tag_not_allowed_in")' Tag(lexer' node)' element.Element)' MessageLevel.Warning); " is 124.
Long Statement,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,ErrorSummary,The length of the statement  "				TidyMessage msg2 = new TidyMessage(lexer' String.Format(GetMessage("badaccess_summary")' ACCESS_URL)' MessageLevel.Info); " is 121.
Long Statement,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,ReportVersion,The length of the statement  "			lexer.messages.Add(new TidyMessage(lexer' String.Format(GetMessage("report_version")' (vers != null ? vers : "HTML proprietary"))' MessageLevel.Info)); " is 151.
Long Statement,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,ReportNumWarnings,The length of the statement  "				lexer.messages.Add(new TidyMessage(lexer' String.Format(GetMessage("num_warnings_errors")' lexer.messages.Warnings' lexer.messages.Errors)' MessageLevel.Info)); " is 160.
Long Statement,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,ReportNumWarnings,The length of the statement  "				lexer.messages.Add(new TidyMessage(lexer' String.Format(GetMessage("num_errors")' lexer.messages.Errors)' MessageLevel.Info)); " is 126.
Long Statement,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,ReportNumWarnings,The length of the statement  "				lexer.messages.Add(new TidyMessage(lexer' String.Format(GetMessage("num_warnings")' lexer.messages.Warnings)' MessageLevel.Info)); " is 130.
Long Statement,TidyNet,TagTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\TagTable.cs,DefineInlineTag,The length of the statement  "			Add(new Dict(name' HtmlVersion.Proprietary' (ContentModel.Inline | ContentModel.NoIndent | ContentModel.New)' ParserImpl.ParseBlock' null)); " is 140.
Long Statement,TidyNet,TagTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\TagTable.cs,DefineBlockTag,The length of the statement  "			Add(new Dict(name' HtmlVersion.Proprietary' (ContentModel.Block | ContentModel.NoIndent | ContentModel.New)' ParserImpl.ParseBlock' null)); " is 139.
Long Statement,TidyNet,TagTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\TagTable.cs,defineEmptyTag,The length of the statement  "			Add(new Dict(name' HtmlVersion.Proprietary' (ContentModel.Empty | ContentModel.NoIndent | ContentModel.New)' ParserImpl.ParseBlock' null)); " is 139.
Long Statement,TidyNet,TagTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\TagTable.cs,DefinePreTag,The length of the statement  "			Add(new Dict(name' HtmlVersion.Proprietary' (ContentModel.Block | ContentModel.NoIndent | ContentModel.New)' ParserImpl.ParsePre' null)); " is 137.
Long Statement,TidyNet,ValignAttrCheck,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ValignAttrCheck.cs,Check,The length of the statement  "			else if (String.Compare(val' "top") == 0 || String.Compare(val' "middle") == 0 || String.Compare(val' "bottom") == 0 || String.Compare(val' "baseline") == 0) " is 157.
Long Statement,TidyNet,ValignAttrCheck,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ValignAttrCheck.cs,Check,The length of the statement  "			else if (String.Compare(val' "texttop") == 0 || String.Compare(val' "absmiddle") == 0 || String.Compare(val' "absbottom") == 0 || String.Compare(val' "textbottom") == 0) " is 169.
Complex Conditional,TidyNet,AlignAttrCheck,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\AlignAttrCheck.cs,Check,The conditional expression  "!(String.Compare(val' "left") == 0 || String.Compare(val' "center") == 0 || String.Compare(val' "right") == 0 || String.Compare(val' "justify") == 0)"  is complex.
Complex Conditional,TidyNet,AttVal,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\AttVal.cs,CheckAttribute,The conditional expression  "!lexer.Options.XmlTags && !(node.Tag == null) && _asp == null && !(node.Tag != null && ((node.Tag.Versions & HtmlVersion.Proprietary) != HtmlVersion.Unknown))"  is complex.
Complex Conditional,TidyNet,AttVal,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\AttVal.cs,CheckUniqueAttribute,The conditional expression  "Attribute != null && attr.Attribute != null && attr.Asp == null && attr.Php == null && String.Compare(Attribute' attr.Attribute) == 0"  is complex.
Complex Conditional,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,NiceBody,The conditional expression  "body.GetAttrByName("background") != null || body.GetAttrByName("bgcolor") != null || body.GetAttrByName("text") != null || body.GetAttrByName("link") != null || body.GetAttrByName("vlink") != null || body.GetAttrByName("alink") != null"  is complex.
Complex Conditional,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,NestedEmphasis,The conditional expression  "(node.Tag == _tt.TagB || node.Tag == _tt.TagI) && node.Parent != null && node.Parent.Tag == node.Tag"  is complex.
Complex Conditional,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,List2BQ,The conditional expression  "node.Tag != null && node.Tag.Parser == ParserImpl.ParseList && node.HasOneChild() && node.Content.Isimplicit"  is complex.
Complex Conditional,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,PurgeAttributes,The conditional expression  "attr.Attribute != null && attr.Val != null && attr.Attribute.Equals("class") && attr.Val.Equals("Code")"  is complex.
Complex Conditional,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,PurgeAttributes,The conditional expression  "attr.Attribute != null && (attr.Attribute.Equals("class") || attr.Attribute.Equals("style") || attr.Attribute.Equals("lang") || attr.Attribute.StartsWith("x:") || ((attr.Attribute.Equals("height") || attr.Attribute.Equals("width")) && (node.Tag == _tt.TagTd || node.Tag == _tt.TagTr || node.Tag == _tt.TagTh)))"  is complex.
Complex Conditional,TidyNet,DomNodeImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\DomNodeImpl.cs,InsertBefore,The conditional expression  "newCh.Adaptee.Type != Node.StartTag && newCh.Adaptee.Type != Node.StartEndTag && newCh.Adaptee.Type != Node.CommentTag && newCh.Adaptee.Type != Node.TextNode && newCh.Adaptee.Type != Node.CDATATag"  is complex.
Complex Conditional,TidyNet,DomNodeImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\DomNodeImpl.cs,ReplaceChild,The conditional expression  "newCh.Adaptee.Type != Node.StartTag && newCh.Adaptee.Type != Node.StartEndTag && newCh.Adaptee.Type != Node.CommentTag && newCh.Adaptee.Type != Node.TextNode && newCh.Adaptee.Type != Node.CDATATag"  is complex.
Complex Conditional,TidyNet,DomNodeImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\DomNodeImpl.cs,AppendChild,The conditional expression  "newCh.Adaptee.Type != Node.StartTag && newCh.Adaptee.Type != Node.StartEndTag && newCh.Adaptee.Type != Node.CommentTag && newCh.Adaptee.Type != Node.TextNode && newCh.Adaptee.Type != Node.CDATATag"  is complex.
Complex Conditional,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,AddGenerator,The conditional expression  "attval != null && attval.Val != null && attval.Val.Length >= 9 && String.Compare(attval.Val.Substring(0' 9)' "HTML Tidy") == 0"  is complex.
Complex Conditional,TidyNet,Node,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Node.cs,InsertMisc,The conditional expression  "node.Type == CommentTag || node.Type == ProcInsTag || node.Type == CDATATag || node.Type == SectionTag || node.Type == AspTag || node.Type == JsteTag || node.Type == PhpTag"  is complex.
Complex Conditional,TidyNet,ParseInlineCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The conditional expression  "node.Type == Node.StartTag && node.Tag == element.Tag && lexer.IsPushed(node) && !node.Isimplicit && !element.Isimplicit && node.Tag != null && ((node.Tag.Model & ContentModel.Inline) != 0) && node.Tag != tt.TagA && node.Tag != tt.TagFont && node.Tag != tt.TagBig && node.Tag != tt.TagSmall"  is complex.
Complex Conditional,TidyNet,ParseInlineCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The conditional expression  "node.Tag == tt.TagP && node.Type == Node.StartTag && ((mode & Lexer.Preformatted) != 0 || element.Tag == tt.TagDt || element.IsDescendantOf(tt.TagDt))"  is complex.
Complex Conditional,TidyNet,ParseInlineCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The conditional expression  "(node.Tag.Model & ContentModel.Inline) != 0 && node.Tag != tt.TagA && !((node.Tag.Model & ContentModel.Object) != 0) && (element.Tag.Model & ContentModel.Inline) != 0"  is complex.
Complex Conditional,TidyNet,ParseBlockCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The conditional expression  "node.Type == Node.EndTag && node.Tag != null && (node.Tag == element.Tag || element.Was == node.Tag)"  is complex.
Complex Conditional,TidyNet,ParseSelectCheckTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ParserImpl.cs,Parse,The conditional expression  "node.Type == Node.StartTag && (node.Tag == tt.TagOption || node.Tag == tt.TagOptgroup || node.Tag == tt.TagScript)"  is complex.
Complex Conditional,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintAttrs,The conditional expression  "_options.XmlOut && _options.XmlSpace && ParserImpl.XMLPreserveWhiteSpace(node' _options.tt) && node.GetAttrByName("xml:space") == null"  is complex.
Complex Conditional,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTag,The conditional expression  "(_options.XmlOut || lexer != null && lexer.isvoyager) && (node.Type == Node.StartEndTag || (node.Tag.Model & ContentModel.Empty) != 0)"  is complex.
Complex Conditional,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTag,The conditional expression  "!((mode & NOWRAP) != 0) && (!((node.Tag.Model & ContentModel.Inline) != 0) || (node.Tag == tt.TagBr) || (((node.Tag.Model & ContentModel.Empty) != 0) && node.Next == null && node.Parent.Tag == tt.TagA))"  is complex.
Complex Conditional,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The conditional expression  "node.Tag == tt.TagBr && node.Prev != null && node.Prev.Tag != tt.TagBr && _options.BreakBeforeBR"  is complex.
Complex Conditional,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The conditional expression  "(node.Tag.Model & ContentModel.Html) != 0 || node.Tag == tt.TagNoframes || ((node.Tag.Model & ContentModel.Head) != 0 && !(node.Tag == tt.TagTitle))"  is complex.
Complex Conditional,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The conditional expression  "last != null && !_options.IndentContent && last.Type == Node.TextNode && content.Tag != null && (content.Tag.Model & ContentModel.Block) != 0"  is complex.
Complex Conditional,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The conditional expression  "ShouldIndent(node) || (((node.Tag.Model & ContentModel.Html) != 0 || node.Tag == tt.TagNoframes || ((node.Tag.Model & ContentModel.Head) != 0 && !(node.Tag == tt.TagTitle))) && _options.HideEndTags == false)"  is complex.
Complex Conditional,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintTree,The conditional expression  "_options.IndentContent == false && node.Next != null && _options.HideEndTags == false && (node.Tag.Model & (ContentModel.Block | ContentModel.List | ContentModel.Deflist | ContentModel.Table)) != 0"  is complex.
Complex Conditional,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintSlide,The conditional expression  "last != null && !_options.IndentContent && last.Type == Node.TextNode && content.Tag != null && (content.Tag.Model & ContentModel.Block) != 0"  is complex.
Complex Conditional,TidyNet,ValignAttrCheck,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ValignAttrCheck.cs,Check,The conditional expression  "String.Compare(val' "top") == 0 || String.Compare(val' "middle") == 0 || String.Compare(val' "bottom") == 0 || String.Compare(val' "baseline") == 0"  is complex.
Complex Conditional,TidyNet,ValignAttrCheck,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ValignAttrCheck.cs,Check,The conditional expression  "String.Compare(val' "texttop") == 0 || String.Compare(val' "absmiddle") == 0 || String.Compare(val' "absbottom") == 0 || String.Compare(val' "textbottom") == 0"  is complex.
Empty Catch Block,TidyNet,EntityTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\EntityTable.cs,EntityCode,The method has an empty catch block.
Empty Catch Block,TidyNet,Tidy,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Tidy.cs,Parse,The method has an empty catch block.
Empty Catch Block,TidyNet,Tidy,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Tidy.cs,Parse,The method has an empty catch block.
Empty Catch Block,TidyNet,Tidy,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Tidy.cs,ParseInternal,The method has an empty catch block.
Empty Catch Block,TidyNet,Tidy,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Tidy.cs,ParseInternal,The method has an empty catch block.
Empty Catch Block,TidyNet,Tidy,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Tidy.cs,ParseInternal,The method has an empty catch block.
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,CreatePropString,The following statement contains a magic number: len += prop.Name.Length + 2;
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,CreatePropString,The following statement contains a magic number: len += prop.Val.Length + 2;
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,FontSize2Name,The following statement contains a magic number: x *= 0.8;
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,FontSize2Name,The following statement contains a magic number: x *= 100.0;
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,FontSize2Name,The following statement contains a magic number: x *= 1.2;
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,FontSize2Name,The following statement contains a magic number: x *= 100.0;
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,BQ2Div,The following statement contains a magic number: indent_buf = "margin-left: " + (2 * indent).ToString() + "em";
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,PruneSection,The following statement contains a magic number: (Lexer.GetString(node.Textarray' node.Start' 2)).Equals("if")
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,PruneSection,The following statement contains a magic number: (Lexer.GetString(node.Textarray' node.Start' 5)).Equals("endif")
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,DropSections,The following statement contains a magic number: (Lexer.GetString(node.Textarray' node.Start' 2)).Equals("if")
Magic Number,TidyNet,Clean,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Clean.cs,NormalizeSpaces,The following statement contains a magic number: c.Val == 160
Magic Number,TidyNet,ClsStreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ClsStreamInImpl.cs,ReadChar,The following statement contains a magic number: 0 < c && c < 32
Magic Number,TidyNet,ClsStreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ClsStreamInImpl.cs,ReadChar,The following statement contains a magic number: c = Win2Unicode[c - 128];
Magic Number,TidyNet,ClsStreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ClsStreamInImpl.cs,ReadChar,The following statement contains a magic number: 127 < c && c < 160
Magic Number,TidyNet,ClsStreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ClsStreamInImpl.cs,ReadChar,The following statement contains a magic number: 127 < c && c < 160
Magic Number,TidyNet,EntityTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\EntityTable.cs,EntityCode,The following statement contains a magic number: c = Convert.ToInt32(name.Substring(3)' 16);
Magic Number,TidyNet,EntityTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\EntityTable.cs,EntityCode,The following statement contains a magic number: c = Convert.ToInt32(name.Substring(3)' 16);
Magic Number,TidyNet,EntityTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\EntityTable.cs,EntityCode,The following statement contains a magic number: name.Length >= 4 && name[2] == 'x'
Magic Number,TidyNet,EntityTable,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\EntityTable.cs,EntityCode,The following statement contains a magic number: name.Length >= 4 && name[2] == 'x'
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,AddByte,The following statement contains a magic number: this.lexlength = 8192;
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,AddCharToLexer,The following statement contains a magic number: c < 128
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,AddGenerator,The following statement contains a magic number: attval != null && attval.Val != null && attval.Val.Length >= 9 && String.Compare(attval.Val.Substring(0' 9)' "HTML Tidy") == 0
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,AddGenerator,The following statement contains a magic number: attval != null && attval.Val != null && attval.Val.Length >= 9 && String.Compare(attval.Val.Substring(0' 9)' "HTML Tidy") == 0
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: str1 = GetString(this.lexbuf' doctype.Start' 5);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: str1 = GetString(this.lexbuf' doctype.Start + 5' 7);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: str1 = GetString(this.lexbuf' doctype.Start + 5' 7);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: Array.Copy(GetBytes("SYSTEM")' 0' this.lexbuf' doctype.Start + 5' 6);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: Array.Copy(GetBytes("SYSTEM")' 0' this.lexbuf' doctype.Start + 5' 6);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: !str1.Substring(0' (6) - (0)).Equals("SYSTEM")
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: Array.Copy(GetBytes("PUBLIC ")' 0' this.lexbuf' doctype.Start + 5' 6);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: Array.Copy(GetBytes("PUBLIC ")' 0' this.lexbuf' doctype.Start + 5' 6);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: !str1.Substring(0' (6) - (0)).Equals("PUBLIC")
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: str1 = GetString(this.lexbuf' i + 1' 12);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: str2 = GetString(this.lexbuf' i + 1' 13);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: len = j - i - 13;
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FindGivenVersion,The following statement contains a magic number: p = GetString(this.lexbuf' i + 13' len);
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,SetXhtmlDocType,The following statement contains a magic number: sysid.Length + 6 >= this.Options.WrapLen
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FixXmlPI,The following statement contains a magic number: this.lexbuf[s] == (byte) 'x' && this.lexbuf[s + 1] == (byte) 'm' && this.lexbuf[s + 2] == (byte) 'l'
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetCDATA,The following statement contains a magic number: columns = input.curcol - 3;
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following statement contains a magic number: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseAsp,The following statement contains a magic number: lexsize -= 2;
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParsePhp,The following statement contains a magic number: lexsize -= 2;
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseValue,The following statement contains a magic number: !AttributeTable.DefaultAttributeTable.IsScript(name) && !(AttributeTable.DefaultAttributeTable.IsUrl(name) && (GetString(lexbuf' start' 11)).Equals("javascript:"))
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ParseValue,The following statement contains a magic number: quotewarning > 10 && seen_gt && munge
Magic Number,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,MAP,The following statement contains a magic number: return ((int) c < 128 ? (short)lexmap[(int) c] : (short)0);
Magic Number,TidyNet,Node,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Node.cs,TrimTrailingSpace,The following statement contains a magic number: c == 160 || c == (byte) ' '
Magic Number,TidyNet,OutImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\OutImpl.cs,Outc,The following statement contains a magic number: c < 128
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,GetUTF8,The following statement contains a magic number: n = c & 31;
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,GetUTF8,The following statement contains a magic number: bytes = 2;
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,GetUTF8,The following statement contains a magic number: n = (n << 6) | (c & 0x3F);
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PutUTF8,The following statement contains a magic number: c < 128
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,AddC,The following statement contains a magic number: lbufsize = 256;
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The following statement contains a magic number: c == 160 && _options.CharEncoding != CharEncoding.Raw
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The following statement contains a magic number: c == 160 && ((mode & PREFORMATTED) != 0)
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The following statement contains a magic number: c > 255
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The following statement contains a magic number: c > 126 && c < 160
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The following statement contains a magic number: c > 126 && c < 160
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The following statement contains a magic number: c > 127 && _options.CharEncoding == CharEncoding.ASCII
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The following statement contains a magic number: c > 126 || (c < ' ' && c != '\t')
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintAttrValue,The following statement contains a magic number: valueChars[1] == '%' || valueChars[1] == '@' || (new string(tmpChar' 0' 5)).Equals("<?php")
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintAttrValue,The following statement contains a magic number: valueChars != null && valueChars.Length >= 5 && valueChars[0] == '<'
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,AfterSpace,The following statement contains a magic number: c == 160 || c == ' ' || c == '\n'
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,AddTransitionEffect,The following statement contains a magic number: 0 <= effect && effect <= 23
Magic Number,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,CreateSlides,The following statement contains a magic number: AddTransitionEffect(lexer' root' EFFECT_BLEND' 3.0);
Magic Number,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,AttrError,The following statement contains a magic number: lexer.messages.Errors > 6
Magic Number,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,Warning,The following statement contains a magic number: lexer.messages.Errors > 6
Magic Number,TidyNet,Report,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Report.cs,Error,The following statement contains a magic number: lexer.messages.Errors > 6
Magic Number,TidyNet,ScriptCheckAttribs,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ScriptCheckAttribs.cs,Check,The following statement contains a magic number: str = str.Substring(0' 10);
Magic Number,TidyNet,ScriptCheckAttribs,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\ScriptCheckAttribs.cs,Check,The following statement contains a magic number: str.Length > 10
Magic Number,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadCharFromStream,The following statement contains a magic number: n = c & 31;
Magic Number,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadCharFromStream,The following statement contains a magic number: n = (n << 6) | (c & 0x3F);
Magic Number,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadChar,The following statement contains a magic number: 0 < c && c < 32
Magic Number,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadChar,The following statement contains a magic number: c = Win2Unicode[c - 128];
Magic Number,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadChar,The following statement contains a magic number: 127 < c && c < 160
Magic Number,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadChar,The following statement contains a magic number: 127 < c && c < 160
Duplicate Code,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The method contains a code clone-set at the following line numbers (starting from the method definition): ((189' 213)' (261' 285))
Duplicate Code,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintSlide,The method contains a code clone-set at the following line numbers (starting from the method definition): ((17' 37)' (80' 100))
Missing Default,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,ApparentVersion,The following switch statement is missing a default case: switch (this.doctype)  			{  			case HtmlVersion.Unknown:   				return GetHtmlVersion();    			case HtmlVersion.Html20:   				if ((this.versions & HtmlVersion.Html20) != 0)  				{  					return HtmlVersion.Html20;  				}  				break;    			case HtmlVersion.Html32:   				if ((this.versions & HtmlVersion.Html32) != 0)  				{  					return HtmlVersion.Html32;  				}  				break; /* to replace old version by new */    			case HtmlVersion.Html40Strict:   				if ((this.versions & HtmlVersion.Html40Strict) != 0)  				{  					return HtmlVersion.Html40Strict;  				}  				break;  				  			case HtmlVersion.Html40Loose:   				if ((this.versions & HtmlVersion.Html40Loose) != 0)  				{  					return HtmlVersion.Html40Loose;  				}  				break; /* to replace old version by new */    			case HtmlVersion.Frames:  				if ((this.versions & HtmlVersion.Frames) != 0)  				{  					return HtmlVersion.Frames;  				}  				break;  			}
Missing Default,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,FixDocType,The following switch statement is missing a default case: switch (this.doctype)  					{  					case HtmlVersion.Unknown:  						return false;    					case HtmlVersion.Html20:  						if ((this.versions & HtmlVersion.Html20) != 0)  						{  							return true;  						}  						break; /* to replace old version by new */  						  						  					case HtmlVersion.Html32:  						if ((this.versions & HtmlVersion.Html32) != 0)  						{  							return true;  						}  						break; /* to replace old version by new */  						  						  					case HtmlVersion.Html40Strict:  						if ((this.versions & HtmlVersion.Html40Strict) != 0)  						{  							return true;  						}  						break; /* to replace old version by new */  						  						  					case HtmlVersion.Html40Loose:  						if ((this.versions & HtmlVersion.Html40Loose) != 0)  						{  							return true;  						}  						break; /* to replace old version by new */  						  						  					case HtmlVersion.Frames:  						if ((this.versions & HtmlVersion.Frames) != 0)  						{  							return true;  						}  						break; /* to replace old version by new */  					}
Missing Default,TidyNet,Lexer,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\Lexer.cs,GetToken,The following switch statement is missing a default case: switch (state)  				{  				case LEX_CONTENT:   					map = MAP((char) c);  						  					/*  						Discard white space if appropriate. Its cheaper  						to do this here rather than in parser methods  						for elements that don't have mixed content.  						*/  					if (((map & WHITE) != 0) && (mode == IgnoreWhitespace) && lexsize == txtstart + 1)  					{  						--lexsize;  						waswhite = false;  						lines = input.curline;  						columns = input.curcol;  						continue;  					}  						  					if (c == '<')  					{  						state = LEX_GT;  						continue;  					}  						  					if ((map & WHITE) != 0)  					{  						/* was previous char white? */  						if (waswhite)  						{  							if (mode != Preformatted && mode != IgnoreMarkup)  							{  								--lexsize;  								lines = input.curline;  								columns = input.curcol;  							}  						}  							/* prev char wasn't white */  						else  						{  							waswhite = true;  							lastc = c;  								  							if (mode != Preformatted && mode != IgnoreMarkup && c != ' ')  							{  								ChangeChar((byte) ' ');  							}  						}  							  						continue;  					}  					else if (c == '&' && mode != IgnoreMarkup)  					{  						ParseEntity(mode);  					}  						  					/* this is needed to avoid trimming trailing whitespace */  					if (mode == IgnoreWhitespace)  						mode = MixedContent;  						  					waswhite = false;  					continue;  					  					  				case LEX_GT:   					if (c == '/')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  						map = MAP((char) c);  							  						if ((map & LETTER) != 0)  						{  							lexsize -= 3;  							txtend = lexsize;  							input.UngetChar(c);  							state = LEX_ENDTAG;  							lexbuf[lexsize] = (byte) '\x0000'; /* debug */  							input.curcol -= 2;  								  							/* if some text before the </ return it now */  							if (txtend > txtstart)  							{  								/* trim space char before end tag */  								if (mode == IgnoreWhitespace && lexbuf[lexsize - 1] == (byte) ' ')  								{  									lexsize -= 1;  									txtend = lexsize;  								}  									  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							continue; /* no text so keep going */  						}  							  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					if (mode == IgnoreMarkup)  					{  						/* otherwise treat as CDATA */  						waswhite = false;  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						look out for comments' doctype or marked sections  						this isn't quite right' but its getting there ...  						*/  					if (c == '!')  					{  						c = input.ReadChar();  						if (c == '-')  						{  							c = input.ReadChar();  							if (c == '-')  							{  								state = LEX_COMMENT; /* comment */  								lexsize -= 2;  								txtend = lexsize;  									  								/* if some text before < return it now */  								if (txtend > txtstart)  								{  									token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  									return token;  								}  									  								txtstart = lexsize;  								continue;  							}  								  							Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  						}  						else if (c == 'd' || c == 'D')  						{  							state = LEX_DOCTYPE; /* doctype */  							lexsize -= 2;  							txtend = lexsize;  							mode = IgnoreWhitespace;  								  							/* skip until white space or '>' */  								  							for (; ; )  							{  								c = input.ReadChar();  									  								if (c == StreamIn.EndOfStream || c == '>')  								{  									input.UngetChar(c);  									break;  								}  									  								map = MAP((char) c);  								if ((map & WHITE) == 0)  								{  									continue;  								}  									  								/* and skip to end of whitespace */  									  								for (; ; )  								{  									c = input.ReadChar();  										  									if (c == StreamIn.EndOfStream || c == '>')  									{  										input.UngetChar(c);  										break;  									}  										  									map = MAP((char) c);  										  									if ((map & WHITE) != 0)  									{  										continue;  									}  										  									input.UngetChar(c);  									break;  								}  									  								break;  							}  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  						else if (c == '[')  						{  							/* Word 2000 embeds <![if ...]> ... <![endif]> sequences */  							lexsize -= 2;  							state = LEX_SECTION;  							txtend = lexsize;  								  							/* if some text before < return it now */  							if (txtend > txtstart)  							{  								token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  								return token;  							}  								  							txtstart = lexsize;  							continue;  						}  							  						/* otherwise swallow chars up to and including next '>' */  						while (true)  						{  							c = input.ReadChar();  							if (c == '>')  							{  								break;  							}  							if (c == - 1)  							{  								input.UngetChar(c);  								break;  							}  						}  							  						lexsize -= 2;  						lexbuf[lexsize] = (byte) '\x0000';  						state = LEX_CONTENT;  						continue;  					}  						  					/*  						processing instructions  						*/  						  					if (c == '?')  					{  						lexsize -= 2;  						state = LEX_PROCINSTR;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Microsoft ASP's e.g. <% ... server-code ... %> */  					if (c == '%')  					{  						lexsize -= 2;  						state = LEX_ASP;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					/* Netscapes JSTE e.g. <# ... server-code ... #> */  					if (c == '#')  					{  						lexsize -= 2;  						state = LEX_JSTE;  						txtend = lexsize;  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						txtstart = lexsize;  						continue;  					}  						  					map = MAP((char) c);  						  					/* check for start tag */  					if ((map & LETTER) != 0)  					{  						input.UngetChar(c); /* push back letter */  						lexsize -= 2; /* discard "<" + letter */  						txtend = lexsize;  						state = LEX_STARTTAG; /* ready to read tag name */  							  						/* if some text before < return it now */  						if (txtend > txtstart)  						{  							token = NewNode(Node.TextNode' lexbuf' txtstart' txtend);  							return token;  						}  							  						continue; /* no text so keep going */  					}  						  					/* otherwise treat as CDATA */  					state = LEX_CONTENT;  					waswhite = false;  					continue;  					  					  				case LEX_ENDTAG:   					txtstart = lexsize - 1;  					input.curcol += 2;  					c = ParseTagName();  					token = NewNode(Node.EndTag' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  					lexsize = txtstart;  					txtend = txtstart;  						  					/* skip to '>' */  					while (c != '>')  					{  						c = input.ReadChar();  						if (c == StreamIn.EndOfStream)  						{  							break;  						}  					}  						  					if (c == StreamIn.EndOfStream)  					{  						input.UngetChar(c);  						continue;  					}  						  					state = LEX_CONTENT;  					waswhite = false;  					return token; /* the endtag token */  					  					  				case LEX_STARTTAG:   					txtstart = lexsize - 1; /* set txtstart to first letter */  					c = ParseTagName();  					isempty.Val = false;  					attributes = null;  					token = NewNode((isempty.Val ? Node.StartEndTag : Node.StartTag)' lexbuf' txtstart' txtend' GetString(lexbuf' txtstart' txtend - txtstart));  						  					/* parse attributes' consuming closing ">" */  					if (c != '>')  					{  						if (c == '/')  						{  							input.UngetChar(c);  						}  							  						attributes = ParseAttrs(isempty);  					}  						  					if (isempty.Val)  					{  						token.Type = Node.StartEndTag;  					}  						  					token.Attributes = attributes;  					lexsize = txtstart;  					txtend = txtstart;  						  					/* swallow newline following start tag */  					/* special check needed for CRLF sequence */  					/* this doesn't apply to empty elements */  						  					if (ExpectsContent(token) || token.Tag == Options.tt.TagBr)  					{  						c = input.ReadChar();  						if (c == '\r')  						{  							c = input.ReadChar();  								  							if (c != '\n')  							{  								input.UngetChar(c);  							}  						}  						else if (c != '\n' && c != '\f')  						{  							input.UngetChar(c);  						}  							  						waswhite = true; /* to swallow leading whitespace */  					}  					else  					{  						waswhite = false;  					}  						  					state = LEX_CONTENT;  						  					if (token.Tag == null)  					{  						Report.Error(this' null' token' Report.UNKNOWN_ELEMENT);  					}  					else if (!Options.XmlTags)  					{  						versions &= token.Tag.Versions;  							  						if ((token.Tag.Versions & HtmlVersion.Proprietary) != 0)  						{  							if (!Options.MakeClean && (token.Tag == Options.tt.TagNobr || token.Tag == Options.tt.TagWbr))  							{  								Report.Warning(this' null' token' Report.PROPRIETARY_ELEMENT);  							}  						}  							  						if (token.Tag.CheckAttribs != null)  						{  							token.CheckUniqueAttributes(this);  							token.Tag.CheckAttribs.Check(this' this.token);  						}  						else  						{  							token.CheckAttributes(this);  						}  					}  					return token; /* return start tag */    				case LEX_COMMENT:   					if (c != '-')  					{  						continue;  					}  						  					c = input.ReadChar();  					AddCharToLexer(c);  					if (c != '-')  					{  						continue;  					}  						  					while (true)  					{  						c = input.ReadChar();  							  						if (c == '>')  						{  							if (badcomment != 0)  							{  								Report.Warning(this' null' null' Report.MALFORMED_COMMENT);  							}  								  							txtend = lexsize - 2; // AQ 8Jul2000  							lexbuf[lexsize] = (byte) '\x0000';  							state = LEX_CONTENT;  							waswhite = false;  							token = NewNode(Node.CommentTag' lexbuf' txtstart' txtend);  								  							/* now look for a line break */  								  							c = input.ReadChar();  								  							if (c == '\r')  							{  								c = input.ReadChar();  									  								if (c != '\n')  								{  									token.Linebreak = true;  								}  							}  								  							if (c == '\n')  							{  								token.Linebreak = true;  							}  							else  							{  								input.UngetChar(c);  							}  								  							return token;  						}  							  						/* note position of first such error in the comment */  						if (badcomment == 0)  						{  							lines = input.curline;  							columns = input.curcol - 3;  						}  							  						badcomment++;  						if (Options.FixComments)  						{  							lexbuf[lexsize - 2] = (byte) '=';  						}  							  						AddCharToLexer(c);  							  						/* if '-' then look for '>' to end the comment */  						if (c != '-')  						{  							break;  						}  					}  						  					/* otherwise continue to look for --> */  					lexbuf[lexsize - 2] = (byte) '=';  					continue;  					  					  				case LEX_DOCTYPE:   					map = MAP((char) c);  						  					if ((map & WHITE) != 0)  					{  						if (waswhite)  						{  							lexsize -= 1;  						}  							  						waswhite = true;  					}  					else  					{  						waswhite = false;  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.DocTypeTag' lexbuf' txtstart' txtend);  					/* make a note of the version named by the doctype */  					doctype = FindGivenVersion(token);  					return token;  					  					  				case LEX_PROCINSTR:   						  					if (lexsize - txtstart == 3)  					{  						if ((GetString(lexbuf' txtstart' 3)).Equals("php"))  						{  							state = LEX_PHP;  							continue;  						}  					}  						  					if (Options.XmlPIs)  					{  						/* insist on ?> as terminator */  						if (c != '?')  						{  							continue;  						}  							  						/* now look for '>' */  						c = input.ReadChar();  							  						if (c == StreamIn.EndOfStream)  						{  							Report.Warning(this' null' null' Report.UNEXPECTED_END_OF_FILE);  							input.UngetChar(c);  							continue;  						}  							  						AddCharToLexer(c);  					}  						  					if (c != '>')  					{  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.ProcInsTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_ASP:   					if (c != '%')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();    					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.AspTag' lexbuf' txtstart' txtend);  					return this.token;    				case LEX_JSTE:   					if (c != '#')  					{  						continue;  					}  	  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.JsteTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_PHP:   					if (c != '?')  					{  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.PhpTag' lexbuf' txtstart' txtend);  					return token;  					  					  				case LEX_SECTION:   					if (c == '[')  					{  						if (lexsize == (txtstart + 6) && (GetString(lexbuf' txtstart' 6)).Equals("CDATA["))  						{  							state = LEX_CDATA;  							lexsize -= 6;  							continue;  						}  					}  						  					if (c != ']')  					{  						continue;  					}    					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.SectionTag' lexbuf' txtstart' txtend);  					return token;    				case LEX_CDATA:   					if (c != ']')  					{  						continue;  					}    					/* now look for ']' */  					c = input.ReadChar();  					if (c != ']')  					{  						input.UngetChar(c);  						continue;  					}  						  					/* now look for '>' */  					c = input.ReadChar();  					if (c != '>')  					{  						input.UngetChar(c);  						continue;  					}  						  					lexsize -= 1;  					txtend = lexsize;  					lexbuf[lexsize] = (byte) '\x0000';  					state = LEX_CONTENT;  					waswhite = false;  					token = NewNode(Node.CDATATag' lexbuf' txtstart' txtend);  					return token;  				}
Missing Default,TidyNet,OutImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\OutImpl.cs,Outc,The following switch statement is missing a default case: switch (State)  						{  						case StreamIn.FSM_ESC:   							if (c == '$')  							{  								State = StreamIn.FSM_ESCD;  							}  							else if (c == '(')  							{  								State = StreamIn.FSM_ESCP;  							}  							else  							{  								State = StreamIn.FSM_ASCII;  							}  							break;  							  						case StreamIn.FSM_ESCD:   							if (c == '(')  							{  								State = StreamIn.FSM_ESCDP;  							}  							else  							{  								State = StreamIn.FSM_NONASCII;  							}  							break;    						case StreamIn.FSM_ESCDP:   							State = StreamIn.FSM_NONASCII;  							break;    						case StreamIn.FSM_ESCP:   							State = StreamIn.FSM_ASCII;  							break;    						case StreamIn.FSM_NONASCII:   							c &= 0x7F;  							break;  						}
Missing Default,TidyNet,PPrint,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\PPrint.cs,PrintChar,The following switch statement is missing a default case: switch (c)  					{  					case 0x2013:   					case 0x2014:   						c = '-';  						break;    					case 0x2018:   					case 0x2019:   					case 0x201A:   						c = '\'';  						break;    					case 0x201C:   					case 0x201D:   					case 0x201E:   						c = '"';  						break;  					}
Missing Default,TidyNet,StreamInImpl,D:\research\architectureSmells\repos\mlocati_betterpoeditor\src\TidyNet\tidy\StreamInImpl.cs,ReadCharFromStream,The following switch statement is missing a default case: switch (state)  					{  					case FSM_ESC:   						if (c == '$')  						{  							state = FSM_ESCD;  						}  						else if (c == '(')  						{  							state = FSM_ESCP;  						}  						else  						{  							state = FSM_ASCII;  						}  						break;  						  						  					case FSM_ESCD:   						if (c == '(')  						{  							state = FSM_ESCDP;  						}  						else  						{  							state = FSM_NONASCII;  						}  						break;  						  						  					case FSM_ESCDP:   						state = FSM_NONASCII;  						break;    					case FSM_ESCP:   						state = FSM_ASCII;  						break;    					case FSM_NONASCII:   						c |= 0x80;  						break;  					}
